[
    {
        "id": 1,
        "timestamp_start": 2.7,
        "timestamp_end": 48.26,
        "slide_description": "Como Engenheiro de Computação Sênior, analisei o slide apresentado, que se trata principalmente de uma tela de conferência online exibindo o plano de ensino ou cronograma de uma disciplina de Arquitetura de Computadores.\n\n**Conteúdo Visual e Texto Transcrito:**\n\nA imagem exibe a interface de uma plataforma de conferência web (\"ConferênciaWeb\") com um título \"Sala de Aula de OAC\" (provavelmente Organização e Arquitetura de Computadores) e um contador de tempo \"00:33\". À esquerda, há uma barra lateral de chat com mensagens e a lista de \"USUÁRIOS (7)\".\n\n**Conteúdo do Chat:**\nAs mensagens visíveis no chat incluem:\n*   \"Bem vindos à sala de aula de OAC!\"\n*   \"Esta sessão está sendo gravada.\"\n*   \"Para mais informações, clique aqui.\"\n*   \"Novo na plataforma? Experimente o tour!\"\n*   \"Luiz Carlos Da Silva Ne... 13:53 boa tarde\"\n*   \"Eduardo Ferreira Marq... 14:00 OAC - Organização Anonima de criminosos\" (Este último parece ser um comentário informal ou piada, dada a sigla OAC).\n\n**Documento Principal (Plano de Ensino/Cronograma):**\nO foco principal é um documento do Microsoft Word intitulado \"OAC_A_Plano_2021-2_v0.docx\". Este documento contém uma tabela detalhando o cronograma da disciplina, com datas e tópicos/atividades. O conteúdo da tabela, transcrevendo fielmente, é o seguinte:\n\n*   **Títulos das Colunas (Implícito/Parcial):** As colunas parecem ser para números de semanas/aulas, datas e os tópicos ou atividades correspondentes.\n*   **Linhas e Conteúdo:**\n    *   **(Linha acima da 8):** `Lab 1B: Software - Compilador C`\n    *   **(Linha acima da 8, coluna direita):** `Lab 2: Hardware - Verilog - ULA (T7)`\n    *   **Linha 8:**\n        *   `14/3`\n        *   `16/3`\n        *   `1ª Prova (P1)`\n        *   `12) Processador Uniciclo: Unidade Operativa (C.4) (T8)`\n    *   **Linha 9:**\n        *   `21/3`\n        *   `23/3`\n        *   `13) Processador Uniciclo: Unidade de Controle (C.4) (L1)`\n        *   `Lab 3: Processador Uniciclo(T9) (L2)`\n    *   **Linha 10:**\n        *   `28/3`\n        *   `30/3`\n        *   `14) Processador Multiciclo: Unidade Operativa (C.4)`\n        *   `15) Processador Multiciclo: Unidade de Controle (C.4) (T10)`\n    *   **Linha 11:**\n        *   `4/4`\n        *   `6/4`\n        *   `Lab 4: Processador Multiciclo`\n        *   `16) Processador Pipeline: Conceitos (C.4) (T11)`\n    *   **Linha 12:**\n        *   `11/4`\n        *   `13/4`\n        *   `17) Pipeline: Unidade Operativa e Controle (C.4)`\n        *   `Lab 5: Processador Pipeline(T12) (L3)`\n    *   **Linha 13:**\n        *   `18/4`\n        *   `20/4`\n        *   `18) Exceção e Interrupção (C.4)`\n        *   `19) Memória: Hierarquia (C.5) (T13) (L4)`\n    *   **Linha 14:**\n        *   `25/4`\n        *   `27/4`\n        *   `19.1) Memória: Cache (C.5)`\n        *   `2ª Prova (P2) (T14) (L5)`\n    *   **Linha 15:**\n        *   `2/5`\n        *   `4/5`\n        *   `Prova Substitutiva`\n        *   `Apresentação dos Projetos (PR) (T15)`\n    *   **Linhas 16 e 17:** Vazias.\n*   **Inferior do Documento:** `Avaliação:` (parcialmente visível).\n\n**Diagramas:**\nNão há diagramas visuais (Datapath, Pipeline, Hierarquia de Memória) apresentados na imagem. O slide contém apenas uma descrição textual dos tópicos da disciplina. No entanto, os tópicos listados na tabela *referenciam* conceitos fundamentais em Arquitetura de Computadores que tipicamente envolvem diagramas, como:\n*   **Processador Uniciclo:** Implica a discussão de um datapath (caminho de dados) e unidade de controle que executa uma instrução por ciclo de clock.\n*   **Processador Multiciclo:** Remete a um datapath e unidade de controle que executa instruções em múltiplos ciclos, reusando componentes funcionais.\n*   **Processador Pipeline:** Envolve a explicação de estágios de pipeline (IF, ID, EX, MEM, WB) para aumentar o throughput, e desafios como hazards de dados e controle.\n*   **Exceção e Interrupção:** Trata do mecanismo pelo qual o processador lida com eventos anômalos ou externos, alterando o fluxo normal de execução.\n*   **Memória: Hierarquia e Cache:** Abrange os diferentes níveis de memória (registradores, cache L1/L2/L3, RAM, disco) e o princípio de localidade para otimizar o acesso, com foco na organização e operação da memória cache (hits, misses, políticas de escrita).\n\n**Contexto e Relevância para RAG:**\nEste slide é rico em termos técnicos específicos da Arquitetura de Computadores, indicando um plano de estudos detalhado. Os termos como \"Processador Uniciclo\", \"Multiciclo\", \"Pipeline\", \"Unidade Operativa\", \"Unidade de Controle\", \"Verilog\", \"ULA\", \"Exceção e Interrupção\", \"Memória: Hierarquia\", \"Cache\", \"Compilador C\" são cruciais para um sistema RAG que busque informações sobre o currículo ou tópicos abordados em cursos de OAC. As menções a \"C.4\", \"C.5\", \"T7\", \"T8\", etc., podem se referir a capítulos de um livro-texto (e.g., Patterson & Hennessy) ou a slides/aulas específicas.",
        "transcription": "Faltou o \"semestre\", mas tudo bem. Pode ser. Dá para fazer várias dessas com OAC. Mas vamos lá. Então, vamos lá para mais uma aulinha de OAC. Agora começou o *pipeline*. Hoje, então, é dia 11 de abril. 11 de abril, nós temos que ver. Na realidade, isso aqui é a implementação do *pipeline*. Como se constrói a unidade operativa e o controle. Então, mas a gente tem uma partezinha de conceitos que a gente não terminou na aula passada e a gente vai rever, então. Quer dizer, vamos terminar a aula passada primeiro.",
        "video_source": "OAC_2022-04-11.mp4"
    },
    {
        "id": 2,
        "timestamp_start": 48.26,
        "timestamp_end": 65.68,
        "slide_description": "Como Engenheiro de Computação Sênior, analisei o slide fornecido, que é na verdade uma captura de tela da interface de um sistema de conferência web/aula online. A análise focará em extrair e descrever o conteúdo para um sistema de busca semântica (RAG), priorizando informações contextuais e textuais.\n\n---\n\n**Análise de Conteúdo para Sistema de Busca Semântica (RAG):**\n\nA imagem representa a interface de uma sessão de aula online em andamento, hospedada na plataforma \"ConferênciaWeb\", acessada via navegador Chrome. O contexto geral é uma \"Sala de Aula de OAC\", onde \"OAC\" é uma sigla recorrente, fortemente sugerindo \"Organização e Arquitetura de Computadores\", uma disciplina fundamental em Engenharia de Computação.\n\n**1. Conteúdo Textual Transcrito:**\n\n*   **Título da Aba do Navegador:** \"ConferênciaWeb - Sala de Aula de OAC\"\n*   **Endereço URL da Sessão:** `live-idc53.mconf.rnp.br/html5client/join?sessionToken=9k0f6r6wy9qhjjl`\n*   **Título da Sala de Aula:** \"Sala de Aula de OAC\"\n*   **Status da Sessão:** A sessão está sendo gravada, conforme indicado por um ícone de gravação (círculo vermelho) e um contador de tempo \"00:59\", significando que a gravação tem 59 segundos de duração no momento da captura.\n*   **Identificação do Usuário:** O usuário visualizando a tela é \"Marcus Vinicius Lam...\", identificado como \"(Você)\". Este usuário é provavelmente o instrutor ou um participante ativo, com o microfone aparentemente ativo.\n*   **Painel de Chat Público (\"Bate-papo público\"):**\n    *   **Mensagens do Sistema/Boas-vindas:**\n        *   \"Bem vindos à sala de aula de OAC!\" (Confirma a sigla OAC como contexto da aula).\n        *   \"Esta sessão está sendo gravada.\"\n        *   \"Para mais informações, clique aqui.\" (Elemento interativo/link).\n        *   \"Novo na plataforma? Experimente o tour!\" (Elemento interativo/link).\n    *   **Mensagens de Usuários:**\n        *   **Luiz Carlos Da Silva Ne... (13:53):** \"boa tarde\" (Saudação padrão).\n        *   **Eduardo Ferreira Marq... (14:00):** \"OAC - Organização Anonima de criminosos\" (Comentário sarcástico ou humorístico, que joga com a sigla OAC e sublinha o tema da aula, mesmo que de forma irreverente. Para um RAG, isso contextualiza a informalidade e a familiaridade dos alunos com a sigla).\n    *   **Campo de Entrada de Mensagem:** \"Enviar mensagem para Bat...\" (Indicando que é um campo de texto para o bate-papo).\n*   **Painel de Navegação Lateral (Esquerda):**\n    *   **Seção \"MENSAGENS\":** Contém submenus para \"Perguntas\" e \"Bate-papo públic...\" (indicando \"Bate-papo público\").\n    *   **Seção \"NOTAS\":** Contém submenu para \"Notas compartil...\" (indicando \"Notas compartilhadas\").\n    *   **Lista de Usuários:** \"USUÁRIOS (7)\" (indicando 7 participantes na sala). Os nomes parciais visíveis são: \"Marcus Vin... (Você)\", \"Luiz Carlos Da Sil...\", \"Eduardo Ferreira ...\", \"Harrisson Freitas ...\", \"Michel Luis Duwe\", \"Victor Hugo Da S...\", \"Victor Hugo Rodr...\". Ícones associados aos usuários indicam o status do microfone (ativo/mutado) e, em alguns casos (como \"Eduardo Ferreira ...\"), um problema de conexão ou áudio (ícone vermelho de erro).\n\n**2. Descrição de Diagramas, Estruturas e Fluxo de Dados:**\n\nA área principal de conteúdo da aula, que normalmente exibiria slides, vídeos, ou um quadro branco virtual, está completamente vazia (apresenta-se como uma tela escura uniforme). Não há diagramas visíveis (sejam de Datapath, Pipeline, Hierarquia de Memória), blocos de código (Assembly, C, Verilog), esquemas, gráficos, tabelas ou qualquer outro material didático técnico sendo exibido neste momento. A ausência de conteúdo visual técnico direto sugere que a captura pode ter ocorrido antes do início da apresentação, durante um intervalo, ou que a câmera/tela do apresentador não estava ativa.\n\n**3. Elementos de UI Ignorados:**\n\nForam intencionalmente ignorados elementos genéricos da interface do navegador Chrome (botões de navegação, barra de favoritos, ícones de extensões, imagem de perfil do usuário logado no navegador), bem como controles universais da plataforma de conferência que não veiculam conteúdo específico da aula (como os botões de controle de microfone, fone de ouvido, câmera, compartilhamento de tela, e levantar a mão na barra inferior, ou os ícones de engrenagem para configurações, e o logo \"ConferênciaWeb\" como marca da plataforma). Estes são considerados elementos de infraestrutura da ferramenta e não de conteúdo didático da aula em si.\n\n---\n\n**Conclusão para RAG:**\n\nEste slide fornece um forte contexto de uma aula de \"Organização e Arquitetura de Computadores\" (OAC) via plataforma de EAD. Embora careça de conteúdo visual técnico direto (diagramas, código), é rico em metadados da sessão (gravação ativa, lista de participantes) e interações de chat que podem ser cruciais para compreender o ambiente de aprendizado, a participação dos alunos e até mesmo o tom da aula. A frase \"OAC - Organização Anonima de criminosos\" é um ponto de dados interessante que, apesar de ser uma piada, reforça a sigla \"OAC\" e mostra a familiaridade e o engajamento (ainda que informal) dos alunos com o tema. A ausência de conteúdo visual técnico deve ser explicitamente notificada no RAG.",
        "transcription": "A última coisa que nós vimos foi previsão de desvios. Espero que todo mundo tenha brincado lá na prática.",
        "video_source": "OAC_2022-04-11.mp4"
    },
    {
        "id": 3,
        "timestamp_start": 65.68,
        "timestamp_end": 1488.33,
        "slide_description": "Como um Engenheiro de Computação Sênior, analisei o slide e o contexto fornecido, extraindo o seguinte conteúdo técnico para um sistema de busca semântica:\n\nO slide apresenta o tópico \"Acelerando máquinas: Superescalar\" como parte da disciplina \"UnB – CIC0099 – Organização e Arquitetura de Computadores\", ministrada pelo Prof. Marcus Vinícius Lamar, do Departamento de Ciência da Computação da Universidade de Brasília.\n\n**Conteúdo Textual Principal:**\n\n*   **Título:** Acelerando máquinas: Superescalar\n*   **Definição:** \"A estrutura superescalar contém múltiplas unidades funcionais que são capazes de fazer a mesma tarefa.\"\n*   **Funcionalidade:** \"Isto permite ao processador executar várias instruções concorrentemente, pelo roteamento das instruções às unidades de execução disponíveis.\"\n*   **Exemplo de Concorrência:** \"Ex.: Tipo-R/I + lw/sw\" (Sugere a execução paralela de instruções do tipo Registrador/Imediato e instruções de Load/Store).\n\n**Diagrama de Datapath (Arquitetura Superescalar Dual-Issue Implícita):**\n\nO diagrama ilustra uma arquitetura de pipeline com modificações para suportar execução superescalar, especificamente parecendo ser um datapath dual-issue, capaz de iniciar a execução de duas instruções por ciclo.\n\n1.  **Estágio de Busca de Instruções (Instruction Fetch - IF):**\n    *   Um Program Counter (PC) aponta para o endereço da instrução.\n    *   Um bloco `Instruction memory` recebe o endereço e parece buscar múltiplas instruções simultaneamente, ou pelo menos fornecer a capacidade para isso, como indicado por duas saídas de instrução ou dois caminhos de instrução distintos que são processados em paralelo. O endereço base `1C09000` é mostrado, possivelmente um ponto de entrada ou segmento de código.\n    *   Um multiplexador (`MUX`) seleciona o próximo endereço do PC, que pode ser `PC+4` para a próxima instrução sequencial ou um endereço de desvio/salto (não completamente visível, mas inferível por um MUX antes do PC).\n    *   Há caminhos distintos para calcular `PC+4` para cada uma das duas instruções potenciais.\n\n2.  **Estágio de Decodificação e Busca de Registradores (Instruction Decode/Register Fetch - ID/RF):**\n    *   Um banco de `Registers` (arquivo de registradores) é o coração deste estágio, com múltiplos portos de leitura e escrita para suportar o acesso concorrente por duas instruções.\n    *   Múltiplos multiplexadores direcionam os operandos dos registradores ou valores imediatos (após expansão de sinal, não visível explicitamente, mas implícita na ligação aos ALUs) para as unidades de execução.\n    *   As instruções decodificadas extraem os campos de operando e os endereços de escrita/leitura.\n\n3.  **Estágio de Execução (Execute - EX):**\n    *   **Duas Unidades Lógico-Aritméticas (ALU)** são claramente visíveis e operam em paralelo. Cada `ALU` recebe dois operandos (de registradores ou imediatos via multiplexadores) e um código de operação, produzindo um resultado.\n    *   Isto é crucial para a capacidade superescalar, permitindo que duas operações de execução (como Tipo-R ou Tipo-I) ocorram simultaneamente.\n\n4.  **Estágio de Acesso à Memória (Memory Access - MEM):**\n    *   Uma unidade `Data memory` está presente, responsável por operações de leitura (`lw`) e escrita (`sw`).\n    *   Recebe um `Address` (geralmente do resultado de uma ALU) e `Write data` (do arquivo de registradores ou resultado de outra unidade), e fornece `Read data`.\n    *   A presença de uma ALU dedicada para cálculo de endereço de memória é implícita, e o fluxo para `Data memory` é mostrado a partir de uma das ALUs.\n\n5.  **Estágio de Write Back (WB):**\n    *   Múltiplos multiplexadores selecionam qual valor será escrito de volta no arquivo de `Registers`: o resultado de uma `ALU`, o dado lido da `Data memory`, ou `PC+4` (para instruções como `jal`).\n    *   O endereço de escrita no banco de registradores é também multiplexado, selecionando o registrador de destino (`rd` ou `rt`) da instrução apropriada.\n\n**Características Superescalares Evidentes no Diagrama:**\n\n*   **Busca Dupla de Instruções:** A capacidade de buscar ou processar duas instruções de forma simultânea a partir da `Instruction memory`.\n*   **Unidades de Execução Múltiplas:** A presença de duas `ALU`s independentes para processamento paralelo de operações aritméticas e lógicas.\n*   **Caminhos de Dados Paralelos:** A arquitetura mostra duplicação de componentes e caminhos de dados para permitir que duas instruções progridam através dos estágios do pipeline em paralelo, um para operações computacionais (Tipo-R/I) e outro para acessos à memória (lw/sw).\n*   **Portas Múltiplas no Arquivo de Registradores:** Embora não explicitamente detalhado, o diagrama implica que o banco de `Registers` deve ter múltiplos portos de leitura e escrita para suportar as necessidades de dados das unidades funcionais paralelas.\n\nO diagrama representa um processador superescalar que tenta explorar o paralelismo no nível de instrução (Instruction-Level Parallelism - ILP) através da emissão de múltiplas instruções por ciclo para unidades funcionais distintas.\n\n**Conteúdo do Chat (Bate-papo público):**\n\nO chat contém uma série de mensagens de estudantes, indicando interação durante a aula:\n\n*   **Marcello Brandao Sca...:** `3`, `ops`, `1/3`, `3`, `entendi, mas eu tenho dúvidas futuras`, `você tá mandando duas instruções ao mesmo tempo?`, `Então você manda PC e PC+4 e depois vai ser PC+8 e PC+12 e assim por diante?`, `ok`.\n*   **João Alberto Travasso...:** `3`.\n\nAs perguntas de Marcello são diretamente relevantes ao tema superescalar, questionando a execução simultânea de duas instruções e o avanço do Program Counter em múltiplos de 4 (PC+4, PC+8, PC+12), o que é consistente com a busca e processamento de duas instruções MIPS (32-bit, 4 bytes cada) por vez.\n\n**Conclusão:**\n\nO slide e o diagrama descrevem e visualizam os princípios fundamentais de uma arquitetura de processador superescalar, focando na capacidade de executar múltiplas instruções concorrentemente através de unidades funcionais paralelas e um datapath dual-issue, exemplificando a execução combinada de instruções Tipo-R/I e lw/sw. O chat demonstra a interação dos alunos com o conceito.",
        "transcription": "Para ver essa previsão de desvios sendo eficiente. Então, vamos lá. O nosso objetivo aqui é sempre conseguir o maior desempenho possível. Certo? OAC é a busca por desempenho. Então, como é que eu posso acelerar as máquinas que utilizam pipeline? Então, primeiro vamos entender esse diagraminha aqui. Que nada mais é do que o nosso pipeline de 5 estágios e de diversas instruções, sem *hazards* nenhum. Esse aqui é o pipeline ideal. Certo? Cada um desses aqui significa ciclo de clock. Então, ciclo de clock 1, ciclo de clock 2, ciclo de clock 3 e assim vai. Então, como que a gente pode acelerar mais ainda o nosso pipeline? Então, a nossa ideia aqui é implementar múltiplas instruções em um ciclo de clock. Em um ciclo desse clock aqui. Certo? Aqui cada instrução é terminada em um ciclo de clock. Então, aqui eu tenho CPI igual a 1. Será que a gente consegue acelerar mais ainda isso? Então, nós vamos ver duas técnicas aqui: uma estrutura *superpipeline* e a outra estrutura *superescalar*. Bom, o que é *superpipeline*? O *superpipeline* é a gente pegar os nossos estágios de pipeline, seriam esses 5 aqui, e subdividir eles em unidades menores. Certo? Então... Se eu aumento... Se eu pego esse estágio e divido em 2, agora eu fico com 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 estágios. Certo? Logo, a nossa aceleração ideal passa de 5 para 10. Quer dizer, eu estou com um pipeline duas vezes melhor que o de 5. E a aceleração seria 10 vezes melhor do que a uniciclo padrão. Certo? Então, eu vou continuar. O nosso... Nós temos aqui agora um clock externo, que seria o clock original do nosso pipeline. Então, este aqui é o nosso clock externo. E, internamente ao processador, a gente duplica este clock, fazendo então com que cada estágiozinho agora deste nosso pipeline subdividido, também continua agindo em ciclo de clock. Certo? Então, na prática, o que a gente está fazendo é aumentar o número de estágios e aumentar a frequência de operação, de modo que a gente pode fazer uma comparação do nosso clock original com essa nova estrutura aqui, subdividida e com o clock o dobro, subdividido em dois, nesse caso aqui. Se eu subdividisse em três, seria o clock triplicado. Então, essa aqui é a solução que a Intel utilizou até o Pentium 4. Daí veio o Pentium 4 e eles descobrem, opa, não consigo mais aumentar a frequência desse clock interno, porque a dissipação térmica começa a pegar fogo. Então, quanto maior a frequência, maior a dissipação térmica. E daí eles tiveram que buscar uma outra alternativa de tentar melhorar mais. Então, isso aqui foi bastante utilizado pela Intel. Então, como é que ficaria naquele nosso diagrama aqui? Aqui eu tinha uma instrução terminada em um ciclo de clock. Se eu triplicar a nossa frequência, dividindo cada estágio por três subestágios, então, significa que em um ciclo de clock externo, eu vou terminar... Três instruções. Essa, essa e essa. Aí já começa a terminar o próximo estágio. Certo? Então, em um ciclo de clock externo, eu tenho, então, três instruções sendo terminadas. Entenderam a ideia? Então, quanto é que vale o CPI desse novo pipeline aqui, onde eu peguei cada estágio e subdividi em três? Assim, né? Eu tenho que deixar de separar. Eu tenho que deixar de separar. Eu não mereço ser preguiçoso e subdividir esses aqui também. Mas qual seria o CPI? Quantos ciclos de clock por instrução é feito esse nosso processador? Tenho que ir para vocês pensarem aqui. Nesse aqui, eu tenho CPI igual a 1. Em um ciclo de clock, uma instrução é terminada. Essa aqui. Essa aqui é terminada no ciclo de clock. No ciclo de clock. Certo? E nessa aqui, onde três instruções são terminadas em um ciclo de clock, qual é o CPI? Olha lá, pessoal. Três, que significa que uma instrução demora três ciclos de clock, Marcelo. E isso, um terço. O que isso significa? Que para eu terminar uma instrução, eu preciso de um terço de ciclo de clock. Isso aí pode ficar parecendo meio estranho se a gente não souber que o ciclo interno, que é a frequência interna do processador, é três vezes maior. Que aqui eu tenho um ciclo, dois ciclos, três ciclos. Certo? Aí realmente fica estranho. Então, ao invés de CPI, que é ciclos por instrução, que ficaria um terço de ciclo, a gente costuma usar IPC, que é justamente o contrário de CPI. Então, o que é o IPC? IPC é instruções por ciclo. Então, ao invés de ser ciclo por instrução, é instrução por ciclo. Quer dizer, quantas instruções eu consigo finalizar em um ciclo de clock. Nesse nosso caso aqui, quanto é que vale o IPC? Agora, pode botar o anterior, Marcelo. Três. Então, eu tenho três instruções sendo terminadas por ciclo de clock. Então, um é simplesmente um e o outro é o outro. Entendida a ideia do *superpipeline*? A gente pegar os estágios do pipeline e dividir eles mais ainda. Ok? Entendido isso, pessoal? Vamos lá. Eu quero que vocês se sintonizem aqui. Mais alguma dúvida? Tem dúvidas futuras. Essa é boa. Tudo bem. Mas em relação à ideia do *superpipeline*, está ok, né? É simplesmente aumentar o clock interno e subdividir os estágios do pipeline. Ok. Como é que a gente pode acelerar mais ainda? Quer dizer, como é que eu posso acelerar? Outra forma de acelerar. Uma é o *superpipeline*. A outra forma é o *superescalar*. Então, o que significa a estrutura *superescalar*? Significa que eu coloco múltiplas unidades funcionais para fazer a mesma tarefa. Quer dizer, aqui, por exemplo, eu permito que a minha memória, certo? Que ela consiga ler de dois endereços diferentes. Que o meu banco de registradores agora consegue ler, além de RS1 e RS2, que seriam esses pretos, consegue ler mais um RS1 linha e um RS2 linha, gerando essas saídas aqui. E escrever em dois registradores ao mesmo tempo. Certo? Então, eu consegui aumentar a capacidade. Não é a capacidade de armazenamento, mas de acesso aos registradores. Então, agora eu consigo ler quatro registradores e gravar em dois. Certo? Ter duas ALUs. Eu posso fazer duas contas diferentes. E uma das coisas que é mais comum de acontecer é eu conseguir executar essas instruções aqui ao mesmo tempo. Uma tipo R ou tipo I, certo? Com o *load* e *store*. Os dois sendo executados ao mesmo tempo. Por quê? Eu leio duas instruções, uma é tipo R, por exemplo, e a outra é o *load*. Então, aqui ele vai ler os registradores do tipo R, e aqui vai ler os registradores para o *load*. Aqui ele vai calcular o tipo I, e aqui ele vai calcular o endereço do *load*. Então, notem que isso aqui pode ser simplesmente um somador. E já está fazendo uma grande diferença. E aqui ele vai calcular o endereço que interessa à memória de dados. E aqui é o B, que se por acaso eu quiser escrever, eu vou escrever esse dado na memória de dados. Certo? Então, assim eu consigo executar uma tipo R, ou tipo I, tanto faz, e um *load* ou um *store* ao mesmo tempo. Certo? Tipo R ou *load* e *store* ao mesmo tempo. Então, isso que significa *superescalar*: eu começar a replicar. Replicar unidades, né? Melhorar o acesso aos meus recursos, de modo a permitir executar várias operações ao mesmo tempo. Certo? O *hazard* aumenta. E aqui também pode ser que eu não possa fazer essas instruções em paralelo. Por exemplo, se o *load* requerer o endereço que o tipo R está calculando. Então, vai ter um *hazard* aqui. Daí, a nossa unidade vai ter que prever isso. Vai ter que detectar esse tipo de coisa. Beleza? Então, a probabilidade de acontecer *hazard* de dados, principalmente aqui, é muito grande. Ok? Mas essa é a ideia, Marcelo. De tentar executar duas instruções ao mesmo tempo. Para isso, eu preciso duplicar os acessos ou duplicar o número das unidades funcionais. Entendido? Então, *superescalar*. Então, no nosso diagraminha, vamos supor que eu tenha três réplicas azuis, três acessos ao banco de registradores, três acessos à memória. E as instruções sejam independentes, quer dizer, sem *hazards*. Então, o que acontece dentro de um ciclo de clock? Um ciclo de clock normal, esse aqui. Vai acontecer que se eu tenho três réplicas das unidades funcionais, eu vou poder determinar três instruções em um ciclo de clock. Certo? Ciclo de clock principal lá da máquina. Todo mundo entendeu isso aqui? Se não tiver *hazard*, se tiver unidades funcionais, por exemplo, três ao mesmo tempo, em um ciclo de clock, eu termino três instruções. Tranquilo? Ótimo. Então, o *threading*, que é o processador lógico, trabalha com a comunicação do banco de registradores e aproveita o tanto eficiente das unidades das bolhas do pipeline. Então, vocês veem aqueles processadores. Quantos processadores tem o computador, o PC de vocês? Quantos físicos e quantos lógicos? Olhem aí e me digam, quantos processadores tem o PC de vocês? Eu não caio mais nessa. Piada *threading* é essa. Mas vai lá no gerenciador de tarefas que mostra aqui, né? Então, no meu caso aqui, eu tenho seis núcleos físicos e processadores lógicos, doze. O que isso significa? Que cada núcleo físico consegue executar duas tarefas independentes, para não ter *hazards* entre eles, ao mesmo tempo. Certo? E de onde é que vem esse ao mesmo tempo? Vem justamente do *superpipeline*, quer dizer, do *superescalar*, que é de praxe implementado pelo menos duas unidades. Três aqui, como está mostrado aqui, não é tão praxe assim. Duas unidades, sim. E o uso eficiente das bolhas. Quer dizer, enquanto uma *thread* está executando e teve que parar numa bolha, a outra não precisa. A outra pode continuar. Isso quatro núcleos lógicos. Entendeu? Então, é daqui que vem o *Hyper-Threading*. Por que *threads* diferentes? Para não ter *hazards* entre eles. Certo? Se um está fazendo um baluz, caramba! Jura? Um *thread* de segunda geração... Meu Deus do céu... Ah, é de quarta geração. Pô, bom, e sete de quarta geração tem mais, né? Não, tem mais que isso. Certo? Então, quando vocês olharem processadores lógicos, significa que eu estou usando esses recursos assim, de *superescalar*, e usar os tempos de bolha, para fazer outras tarefas também. Entendeu? Então, o que é melhor? Um processador com quatro núcleos físicos e quatro *threads*, ou um processador de dois núcleos físicos e quatro *threads*? O que vocês acham? Vamos lá. O que é melhor? Um processador com quatro núcleos físicos e quatro *threads*, quer dizer, só tem uma *thread* em cada núcleo, ou um processador de dois núcleos físicos e quatro *threads*? Qual vai ser mais eficiente? Quatro por quatro? Não entendi. O primeiro, né? Porque cada *thread* vai ocupar exatamente um núcleo. Este outro que tem dois núcleos, as outras *threads* vão ser utilizadas dessa forma, certo? Ou então, utilizando as bolhas. Então, não é tão eficiente assim. Ok? 4 núcleos, 4 *threads* é mais eficiente. Beleza. Então agora vocês já sabem discutir núcleo de *threads* com qualquer que seja. Certo? O que é o núcleo virtual, o que é o núcleo real. Beleza. E o que aconteceria se a gente implementasse as duas técnicas ao mesmo tempo? *Superpipeline* e *Superescalar*. Então aqui eu tenho que cada estágio do pipeline é dividido em 3. Aqui, por exemplo, notem que o IF é dividido em 3. Então todas elas são divididas em 3, com um clock 3 vezes maior do que esse clock aqui. E cada uma dessas... E tem 3 unidades replicadas também. Quer dizer, é a união deles. Com esse aqui, certo? Com esse aqui. Qual é a seriedade disso aqui? Qual é o IPC disso aqui? Do *superpipeline* mais *superescalar*. Isso, IPC de 9, porque é dentro de um ciclo de clock. Eu quero 3 mais 3 mais 3, 9. Certo? Ou então, um IPC de 9 ou uma CPI de 1/9. Certo? Que seria desse ciclo de clock. Certo? Que seria desse ciclo de clock. Certo? Que seria desse ciclo de clock. Certo pessoal? Então, isso aqui a Intel que realmente utilizou, de repente, os 4. Só que não com 3, mas com 2. E o IPC deles é até 32. Quer dizer, o pipeline é dividido em 32 etapas. Hoje em dia já não é mais tanta etapa, porque eles viram que não era mais tão eficiente e gerava muito calor. Então é até aqui ó, conclusão. Todos os processadores modernos possuem pipelines muito complexos. O 4.6 era os 5 estágios. CISC e puro *escalar*, quer dizer, não tinha *superescalar*, não tinha unidades a mais. O Pentium começou com 5 estágios e com 2 ALUs de inteiro. Então, ele já conseguia fazer 2 contas ao mesmo tempo. Pentium 2 foi 10 estágios mais *superescalar*. Então, nesse caso aqui, a gente vai começar a ver outra forma de implementar as instruções que eles utilizavam. Esses 10 estágios de pipeline não eram a nível de instrução, mas a nível de microinstruções. Então, se vocês lembrarem lá do Multiciclo, que a gente tinha um microprograma, eram aquelas microinstruções que eram *pipelineizadas*, que são *pipelineizadas*. Então, para apresentar uma instrução, tem que fazer vários passos. E esses passos são *pipelineizados*. Certo? Então, a nível de microinstruções. Conseguiram pegar a ideia aqui? Entenderam isso aqui? Se eu perguntasse para vocês, vocês responderiam se vocês saberiam? Exato! Porque não precisa ser 10 instruções. Ok? O Pentium 3, 10 estágios também. Pentium 4, 20. Daí vem o Pentium D, que é a derivação do Pentium 4. 31 estágios. Tá? 10 estágios. Quer dizer, fizeram um *superpipeline* com 31 estágios. Maior a frequência, maior o número de bolhas, maior o consumo. Porque teve que aumentar a frequência interna do processador. Isso aqui gastava muito. E eles foram de volta lá para o Pentium M. E criaram então o Core 2, que era de 14 estágios. Certo? Só que agora já começava a ter *dual core*. E *quad core* aqui. Devido a essa redução do número de estágios, perdi aqui em desempenho. Mas consome bem menos aqui. Aí, para não perder desempenho, replicaram o núcleo de processamento. Até aqui era tudo um único núcleo de processamento. Um único *core*. Aqui já foi *dual*, depois *quad*. Core i3, i5 e i7, pelo menos até o que eu saiba. Eu não sei em relação à décima segunda geração. São de 16 estágios. Quer dizer, aumentou um pouquinho. A não ser de outubro, que eram os 3 mil estágios. Certo? Então aqui é a quantidade de estágios que o Pentium tem hoje em dia. Core PC. O Pentium utiliza tabela de históricos para a previsão dos desvios. Que eles chamam de *buffer* de previsão. Certo? Então eles têm uma tabela com todos os *branches*. E vão gravando a cada vez que o *branch* é tomado ou não tomado. Para depois prever. Quando ele passar de novo por aquele *branch*. Desvio condicional. Se ele deve ser tomado ou não tomado. E escalonamento de instruções. Quer dizer, qual a ordem das instruções. Ou melhor, do ponto de vista do processador. Que instruções eu devo executar agora. Justamente a execução fora de ordem. Historicamente era tarefa do compilador. Era ele que fazia isso. E hoje em dia. O *hardware* já faz isso. Só que daí gera falha de segurança. Se vocês procurarem por essas duas falhas aqui: *Downspect* e *Meltdown*. Que ocorreram nesses anos. Vocês vão entender. O que é que eu estou falando. Devido a falha de segurança. Ok? Então essa aqui é a nossa conclusão do pipeline. *Single Instruction Multiple Data*. Isso aí pode ser em qualquer processador. Entendeu? Porque por exemplo. O que é um SIMD? *Single Instruction Multiple Data*. Vamos supor que eu tenho um registrador de 32 bits. E nesse registrador de 32 bits. Ao invés de eu ter um número de 32 bits. Eu tenho 4 números de 1 byte. Então eu tenho 4 números de 1 byte. E quero somar esses 4 números. Com outros 4 números de 1 byte. Então seria tipo uma operação vetorial. Tá? Então a Intel já faz isso. Desde que não tenha o *carry* de 1 byte para o outro. Entendeu Luiz Carlos? Então é um ADD especial. Onde o *carry* de 1 byte para o outro não é feito. Aí tu tem um SIMD. *Single Instruction Multiple Data*. Claro que depois isso aí está sendo aprimorado. Hoje em dia já temos registradores de 512 bits. Mas justamente para a gente contar o tamanho desse vetor. Tá? E usar palavras maiores. Ok.",
        "video_source": "OAC_2022-04-11.mp4"
    },
    {
        "id": 4,
        "timestamp_start": 1488.33,
        "timestamp_end": 1495.5,
        "slide_description": "Este slide, intitulado \"Conclusão\", faz parte de uma aula de \"Organização e Arquitetura de Computadores\" (UnB – CIC0099) ministrada pelo Professor Marcus Vinicius Lamar, do Departamento de Ciência da Computação da Universidade de Brasília. O conteúdo foca na evolução e complexidade dos pipelines em processadores modernos, escalonamento de instruções e menção a falhas de segurança recentes.\n\nO slide apresenta os seguintes pontos técnicos:\n\n1.  **Complexidade dos Pipelines Modernos:**\n    *   Afirma que \"Todos processadores modernos possuem pipeline complexos\".\n    *   Detalha a evolução dos estágios de pipeline em processadores Intel (e alguns outros) ao longo do tempo:\n        *   **80486:** Mencionado com 5 estágios (arquitetura CISC, puramente escalar).\n        *   **Pentium:** Evolui para 5 estágios, adicionando 2 Unidades Lógicas Aritméticas (ULAs) inteiras, sugerindo maior capacidade de execução paralela para operações inteiras.\n        *   **Pentium II:** Aumenta para 10 estágios e introduz a capacidade super-escalar, indicando a habilidade de executar múltiplas instruções em paralelo. Destaca que seu núcleo é \"RISC\" e opera a \"nível de micro instruções\", implicando a tradução de instruções CISC para micro-operações mais simples para execução no pipeline.\n        *   **Pentium III:** Mantém 10 estágios, semelhante ao Pentium II.\n        *   **Pentium IV:** Um salto significativo para 20 estágios, buscando maiores frequências de clock através de pipelines mais profundos.\n        *   **Pentium D:** Chega a impressionantes 31 estágios. É explicitado que isso resultou em \"Maior frequência, maior num. Bolhas, maior consumo\", indicando que a profundidade extrema do pipeline levou a penalidades significativas de desvio e aumento no consumo de energia.\n        *   **Core2:** Reduz para 14 estágios, com a notação \"(porém dual/quad core real)\", enfatizando a transição para multi-core como principal estratégia de paralelismo, em vez de pipelines excessivamente profundos.\n        *   **Core i3,i5,i7,i9:** Mantêm uma contagem de 16 estágios, sugerindo um ponto de equilíbrio encontrado para a complexidade do pipeline, complementado pela arquitetura multi-core.\n\n2.  **Previsão de Desvios (Branch Prediction):**\n    *   Menciona que processadores como \"PowerPC e Pentium\" utilizam \"tabela de histórico de desvios (buffer de previsão)\". Isso se refere à técnica fundamental de previsão de branches para evitar \"bolhas\" (stalls) no pipeline, minimizando o impacto de desvios condicionais na performance.\n\n3.  **Escalonamento de Instruções (Instruction Scheduling):**\n    *   Aborda a questão fundamental \"Que instrução executar agora?\".\n    *   Historicamente, essa tarefa era predominantemente realizada pelo compilador (\"tarefa do compilador\"), que reordenava instruções para otimizar o uso do pipeline.\n    *   \"Hoje em dia: o hardware do processador já realiza\", indicando que os processadores modernos incorporam lógica avançada (como execução fora de ordem, renomeação de registradores) para escalonar instruções dinamicamente em tempo de execução, explorando paralelismo a nível de instrução (ILP).\n\n4.  **Falhas de Segurança:**\n    *   Conclui mencionando \"Problemas: Meltdown e Spectre falhas de segurança (2017/2018)\". Estas são vulnerabilidades críticas que exploram aspectos da execução especulativa e previsão de desvios, revelando como otimizações de performance em hardware podem ter implicações de segurança.\n\n**Discussões Relacionadas no Chat (semântica para busca):**\n\n*   Um comentário de Luiz Carlos Da Silva N. (\"fatorando fica super(pipeline+escalar)\") reflete sobre a combinação de pipeline e execução escalar, que culmina nas arquiteturas super-escalares.\n*   Marcello Brandao Sca. pergunta se \"a pipeline é só da micro ismtruções?\", questionando o nível de abstração em que os pipelines operam, o que é diretamente respondido pela descrição do Pentium II que atua a \"nível de micro instruções\".\n*   Outra pergunta de Luiz Carlos Da Silva N. (\"prof, eu estava pensando, em qual categoria se encaixa o SIMD?\") busca classificar as instruções SIMD (Single Instruction, Multiple Data), que são um tipo de paralelismo a nível de instrução e dados, frequentemente implementado em processadores com pipelines complexos para acelerar operações em vetores.\n\nNão há diagramas (Datapath, Pipeline, Hierarquia de Memória) visíveis no slide.",
        "transcription": "Então vamos para a aula de hoje.",
        "video_source": "OAC_2022-04-11.mp4"
    },
    {
        "id": 5,
        "timestamp_start": 1495.5,
        "timestamp_end": 1499.67,
        "slide_description": "Como um Engenheiro de Computação Sênior, analisei o slide e o contexto anotado da aula de Arquitetura de Computadores. A seguir, extraio e descrevo o conteúdo visual para um sistema de busca semântica (RAG), focando nas informações técnicas.\n\n---\n\n**Transcrições e Descrição do Conteúdo:**\n\nA imagem exibe uma interface de conferência web (\"ConferênciaWeb - Sala de Aula de OAC\") em um ponto onde a apresentação de slides parece ter sido concluída, ou está aguardando ação do apresentador.\n\n**1. Conteúdo do Slide (Tela Principal):**\n*   **Título/Cabeçalho da Universidade:** Parcialmente visível no canto superior direito da área de apresentação, encontra-se:\n    *   \"Universidade de Brasília\"\n    *   \"Departamento de Ciência da Computação\"\n    *   \"CIC0000 - Organização e Arquitetura de Computadores\"\n    *   \"Prof. Marcus Vinícius Lamar\" (identificando o professor responsável pela disciplina).\n*   **Status da Apresentação:** No centro superior da área de apresentação, o texto indica: \"Fim da apresentação de slides. Clique para sair.\"\n*   **Diálogo do Microsoft PowerPoint:** Uma caixa de diálogo do Microsoft PowerPoint está centralizada na área preta da apresentação, com o título \"Microsoft PowerPoint\". A pergunta apresentada é: \"Quer manter suas anotações à tinta?\". Duas opções de interação são visíveis: \"Manter\" e \"Descartar\". Isso sugere que o professor utilizou anotações em tinta digital durante a apresentação.\n\n**2. Conteúdo do Chat (\"Bate-papo público\"):**\nO painel de chat lateral esquerdo contém uma série de mensagens de alunos, que fornecem informações contextuais ricas sobre os tópicos discutidos na aula:\n\n*   **Eduardo Ferreira Marqu... (14:17):** \"o 1\" (Contexto desconhecido, pode ser uma resposta ou identificador).\n*   **Marcello Brandao Sca... (14:17):** \"4 nucleos e 4 threads\" (Discussão sobre arquiteturas multicore e multithreading, conceitos fundamentais em paralelismo e concorrência de CPUs).\n*   **Marcello Brandao Sca... (14:18):** \"aí o pc pega fogo\" (Comentário informal que pode se referir a alta carga de trabalho, aquecimento ou complexidade de gerenciamento em sistemas com muitos núcleos/threads).\n*   **Luiz Carlos Da Silva N... (14:18):** \"fatorando fica super(pipeline+escalar)\" (Refere-se a otimizações de desempenho que combinam técnicas de pipeline de instruções com arquiteturas superscalares, que executam múltiplas instruções simultaneamente em estágios de pipeline independentes ou paralelos).\n*   **Marcello Brandao Sca... (14:18):** \"IPC 9 CPI 1/9\" (Métricas de desempenho de processadores: IPC - Instructions Per Cycle (Instruções por Ciclo) e CPI - Cycles Per Instruction (Ciclos por Instrução). Um IPC de 9 ou CPI de 1/9 é um valor extremamente alto, provavelmente hipotético ou idealizado, usado para ilustrar o potencial máximo de paralelismo em uma arquitetura (e.g., uma arquitetura superscalar com muitos canais de execução paralelos, ou uma discussão teórica sobre o limite de instrucões por ciclo)).\n*   **Eduardo Ferreira Marq... (14:18):** \"9?\" (Expressa surpresa ou questionamento sobre o valor de IPC/CPI apresentado, dado que é um valor incomumente alto para CPUs comerciais).\n*   **Marcello Brandao Sca... (14:21):** \"a pipeline é só da micro isnstruções?\" (Questionamento sobre a abrangência do conceito de pipeline, especificamente se ele se aplica apenas a micro-instruções (µops) ou também a instruções de nível ISA (Instruction Set Architecture)). Isso indica uma discussão sobre a diferença entre a arquitetura do conjunto de instruções e a microarquitetura interna do processador.\n*   **Luiz Carlos Da Silva N... (14:23):** \"prof, eu estava pensando, em qual categoria se encaixa o SIMD?\" (Pergunta crucial sobre a classificação de SIMD (Single Instruction, Multiple Data) no contexto de taxonomias de arquitetura, como a de Flynn (SISD, SIMD, MISD, MIMD). SIMD é uma técnica de paralelismo de dados, onde uma única instrução opera simultaneamente em múltiplos operandos de dados, comum em processadores vetoriais e extensões multimídia).\n*   **Luiz Carlos Da Silva N... (14:24):** \"saquei\" (Confirmação de compreensão).\n\n**3. Ausência de Diagramas/Código Direto:**\nNão há diagramas explícitos de Datapath, Pipeline, Hierarquia de Memória ou trechos de código (Assembly, C, Verilog) visíveis diretamente na tela de apresentação. No entanto, as discussões no chat (\"pipeline\", \"superscalar\", \"SIMD\", \"multicore\", \"multithreading\", \"micro instruções\", \"IPC/CPI\") implicam fortemente que esses conceitos foram abordados em profundidade durante a aula.\n\n---\n\n**Conclusão para RAG:**\nEste slide e seu contexto de chat indicam uma aula avançada de Arquitetura de Computadores, focada em tópicos de desempenho e paralelismo em processadores modernos. Os conceitos-chave incluem:\n*   **Arquiteturas de Processadores:** Multicore, multithreading.\n*   **Otimização de Desempenho:** Pipelining de instruções, arquiteturas superscalares, micro-instruções.\n*   **Métricas de Desempenho:** IPC (Instructions Per Cycle), CPI (Cycles Per Instruction).\n*   **Paralelismo de Dados:** SIMD (Single Instruction, Multiple Data).\n*   **Taxonomias de Arquitetura:** Classificação de estilos de arquitetura (implícito na pergunta sobre SIMD).\n\nA aula é ministrada pelo Prof. Marcus Vinícius Lamar no Departamento de Ciência da Computação da Universidade de Brasília. O sistema de busca semântica deve ser capaz de associar esta captura a discussões detalhadas sobre esses tópicos em arquitetura de computadores.",
        "transcription": "Vamos lá.",
        "video_source": "OAC_2022-04-11.mp4"
    },
    {
        "id": 6,
        "timestamp_start": 1499.67,
        "timestamp_end": 1500.67,
        "slide_description": "Como Engenheiro de Computação Sênior, analiso o slide e o conteúdo anotado, que parecem ser de uma aula de Arquitetura de Computadores, para extrair informações para um sistema de busca semântica (RAG).\n\n**Descrição Geral:**\nA imagem apresenta uma tela de conferência online, com o conteúdo principal sendo um documento do Microsoft Word intitulado \"OAC_A_Plano_2021-2_v0.docx\", que detalha o plano de ensino e cronograma da disciplina de Arquitetura de Computadores (OAC). Há também uma barra lateral de bate-papo com discussões técnicas relevantes. O documento principal é uma tabela com semanas, datas, tópicos de aula e laboratórios, e informações sobre avaliações.\n\n---\n\n**1. Transcrição Fiel de Texto, Títulos e Código Visível:**\n\n**Documento Principal (Tabela do Microsoft Word):**\n\n*   **Título do Documento:** \"OAC_A_Plano_2021-2_v0.docx\"\n*   **Cabeçalhos (parcialmente visíveis):**\n    *   \"Lab 1B: Software – Compilador C\"\n    *   \"Lab 2: Hardware – Verilog – ULA (T7)\"\n*   **Conteúdo da Tabela (Linhas 8 a 15, com numeração de itens de curso/lab):**\n    *   **Linha 8:** \"14/3\", \"16/3\", \"1ª Prova (P1)\"\n    *   **Linha 9:** \"21/3\", \"23/3\", \"13) Processador Uniciclo: Unidade de Controle (C.4) (L1)\", \"Lab 3: Processador Uniciclo (T9) (L2)\"\n    *   **Linha 10:** \"28/3\", \"30/3\", \"14) Processador Multiciclo: Unidade Operativa (C.4)\", \"15) Processador Multiciclo: Unidade de Controle (C.4) (T10)\"\n    *   **Linha 11:** \"4/4\", \"6/4\", \"Lab 4: Processador Multiciclo\", \"16) Processador Pipeline: Conceitos (C.4) (T11)\"\n    *   **Linha 12:** \"11/4\", \"13/4\", \"17) Pipeline: Unidade Operativa e Controle (C.4)\", \"Lab 5: Processador Pipeline (T12) (L3)\"\n    *   **Linha 13:** \"18/4\", \"20/4\", \"18) Exceção e Interrupção (C.4)\", \"19) Memória: Hierarquia (C.5) (T13) (L4)\"\n    *   **Linha 14:** \"25/4\", \"27/4\", \"19.1) Memória: Cache (C.5)\", \"2ª Prova (P2) (T14) (L5)\"\n    *   **Linha 15:** \"2/5\", \"4/5\", \"Prova Substitutiva\", \"Apresentação dos Projetos (PR) (T15)\"\n*   **Seção abaixo da Tabela:** \"Avaliação:\"\n\n**Chat Lateral (Bate-papo público):**\n\n*   **Marcello Brandao Sca... 14:17:** \"4 nucleos e 4 threads\"\n*   **Marcello Brandao Sca... 14:18:** \"aí o pc pega fogo\"\n*   **Luiz Carlos Da Silva N... 14:18:** \"fatorando fica super(pipeline+escalar)\"\n*   **Marcello Brandao Sca... 14:19:** \"IPC 9 CPI 1/9\"\n*   **Marcello Brandao Sca... 14:21:** \"a pipeline é só da micro isnstruções?\"\n*   **Luiz Carlos Da Silva N... 14:23:** \"prof, eu estava pensando, em qual categoria se encaixa o SIMD?\"\n*   **Luiz Carlos Da Silva N... 14:24:** \"saquei\"\n\n---\n\n**2. Descrição de Diagramas (Estrutura e Fluxo de Dados):**\n\nNão há diagramas visuais de datapath, pipeline, ou hierarquia de memória na imagem. O conteúdo visual principal é uma tabela que descreve o cronograma da disciplina. As referências \"C.4\", \"C.5\", \"T7\", \"T9\", \"T10\", \"T11\", \"T12\", \"T13\", \"T14\", \"T15\", \"L1\", \"L2\", \"L3\", \"L4\", \"L5\" provavelmente indicam capítulos do material didático, tópicos teóricos e laboratórios, respectivamente.\n\n---\n\n**Informações Técnicas e Contexto Semântico para RAG:**\n\nO slide é um cronograma detalhado de uma disciplina de Arquitetura de Computadores, cobrindo tópicos fundamentais da organização de processadores e sistemas de memória. A sequência dos tópicos reflete uma progressão didática comum na área, iniciando com implementações mais simples de processadores e avançando para complexidades como paralelismo e hierarquia de memória.\n\n**Tópicos Abordados (Cronograma da Aula):**\n\n1.  **Laboratórios de Introdução:**\n    *   **Lab 1B: Software – Compilador C:** Foco em aspectos de software e compilação, provavelmente preparando o terreno para entender como o código de alto nível interage com a arquitetura.\n    *   **Lab 2: Hardware – Verilog – ULA (T7):** Introdução ao design de hardware usando Verilog, especificamente a Unidade Lógica e Aritmética (ULA), um componente central da CPU.\n2.  **Processadores de Ciclo Único (Uniciclo):**\n    *   **Conceitos:** Unidade de Controle (C.4) e Unidade Operativa (C.4) de um processador Uniciclo (L1).\n    *   **Lab 3: Processador Uniciclo (T9) (L2):** Implementação prática ou estudo aprofundado de processadores Uniciclo.\n3.  **Processadores Multiciclo:**\n    *   **Conceitos:** Transição para processadores Multiciclo, abordando a Unidade Operativa (C.4) e a Unidade de Controle (C.4) em diferentes estágios de execução (T10).\n    *   **Lab 4: Processador Multiciclo:** Foco prático no design ou análise de processadores Multiciclo.\n4.  **Processadores Pipelined (Pipeline):**\n    *   **Conceitos:** Abordagem de conceitos de pipeline (C.4) (T11) para melhorar o throughput do processador. Inclui Unidade Operativa e Controle (C.4).\n    *   **Lab 5: Processador Pipeline (T12) (L3):** Atividade prática sobre processadores pipelined.\n5.  **Exceção e Interrupção:**\n    *   **Tratamento:** Mecanismos de Exceção e Interrupção (C.4) para lidar com eventos inesperados ou assíncronos durante a execução do programa.\n6.  **Hierarquia de Memória:**\n    *   **Estrutura:** Conceitos de Hierarquia de Memória (C.5) (T13) (L4), abordando os diferentes níveis de memória e suas características.\n    *   **Cache:** Detalhamento da Memória Cache (C.5) (T14) (L5), fundamental para otimização de desempenho.\n7.  **Avaliações:**\n    *   Duas provas (P1, P2) e uma prova substitutiva.\n    *   Apresentação de Projetos (PR) (T15), indicando um componente prático significativo na avaliação final.\n\n**Discussões Relevantes no Chat (Temas de Arquitetura Avançada):**\n\n*   **Paralelismo/Multithreading:** \"4 nucleos e 4 threads\" é uma discussão sobre a arquitetura de processadores modernos e a capacidade de execução paralela.\n*   **Otimização de Desempenho:** \"fatorando fica super(pipeline+escalar)\" e \"IPC 9 CPI 1/9\" referem-se a técnicas de otimização de desempenho (pipeline, execução escalar) e métricas de desempenho (Instructions Per Cycle - IPC, Cycles Per Instruction - CPI), que são essenciais para avaliar a eficiência de uma arquitetura. Um IPC de 9 e CPI de 1/9 (aproximadamente 0.11) indica um processador de altíssimo desempenho, capaz de executar muitas instruções por ciclo.\n*   **Microinstruções e Pipeline:** A pergunta \"a pipeline é só da micro isnstruções?\" explora a relação entre o conceito de pipeline e a granularidade da execução das instruções (microinstruções vs. instruções de alto nível ISA).\n*   **Paralelismo de Dados (SIMD):** A pergunta \"prof, eu estava pensando, em qual categoria se encaixa o SIMD?\" (Single Instruction, Multiple Data) demonstra interesse em arquiteturas que processam múltiplos dados com uma única instrução, comum em processadores gráficos (GPUs) e extensões de processadores gerais para computação vetorial.\n\nEste conjunto de informações permite que um sistema RAG identifique não apenas os tópicos programáticos da disciplina, mas também as discussões de aprofundamento e questões que surgem em tempo real, indicando os pontos de interesse e desafios conceituais para os alunos.",
        "transcription": "A aula de hoje.",
        "video_source": "OAC_2022-04-11.mp4"
    },
    {
        "id": 7,
        "timestamp_start": 1500.67,
        "timestamp_end": 1511.56,
        "slide_description": "Como Engenheiro de Computação Sênior, analiso o artefato visual fornecido, que representa uma captura de tela de uma sessão online de uma aula de Arquitetura de Computadores (identificada pelo título \"Sala de Aula de OAC\" – presumivelmente Organização e Arquitetura de Computadores). O objetivo é extrair e descrever o conteúdo para um sistema de busca semântica (RAG).\n\n**1. Transcrição Fiel de Texto e Títulos:**\n\n*   **Barra do Navegador (Superior):**\n    *   Título da aba: \"ConferênciaWeb - Sala de Au...\"\n    *   URL visível: `live-idc53.mconf.rnp.br/html5client/join?sessionToken=9k0f6r6wy9qhjsl`\n*   **Barra Lateral Esquerda (Plataforma ConferênciaWeb):**\n    *   Identificador: \"ConferênciaWeb\"\n    *   **MENSAGENS**\n        *   \"Perguntas\"\n        *   \"Bate-papo público\" (selecionado)\n    *   **NOTAS**\n        *   \"Notas compartilh...\"\n    *   **USUÁRIOS (9)**\n        *   \"Marcus Vinicius... (Você)\"\n        *   \"Luiz Carlos Da Silva N...\"\n        *   \"Eduardo Ferreira ...\"\n        *   \"Gabriel Kenji And...\"\n        *   \"Marcello Brandao...\"\n        *   \"Maycon Vinnycu...\"\n        *   \"Michel Luis Duwe\"\n        *   \"Victor Hugo Da S...\"\n        *   \"Victor Hugo Rodr...\"\n*   **Conteúdo do Bate-papo Público:**\n    *   Título: \"Bate-papo público\"\n    *   Mensagens (cronologicamente, de cima para baixo):\n        *   **Eduardo Ferreira Marq... 14:17:** \"o 1\"\n        *   **Marcello Brandao Sca... 14:17:** \"4 nucleos e 4 threads\"\n        *   **Marcello Brandao Sca... 14:18:** \"aí o pc pega fogo\"\n        *   **Luiz Carlos Da Silva N... 14:18:** \"fatorando fica super(pipeline+escalar)\"\n        *   **Marcello Brandao Sca... 14:18:** \"IPC 9 CPI 1/9\"\n        *   **Eduardo Ferreira Marq... 14:18:** \"9?\"\n        *   **Marcello Brandao Sca... 14:21:** \"a pipeline é só da micro isntruções?\" (Nota: \"isntruções\" é um erro de digitação, provavelmente intencionado como \"instruções\")\n        *   **Luiz Carlos Da Silva N... 14:23:** \"prof. eu estava pensando, em qual categoria se encaixa o SIMD?\"\n        *   **Luiz Carlos Da Silva N... 14:24:** \"saquei\"\n    *   Campo de entrada: \"Enviar mensagem para Bat...\"\n*   **Área Principal da Aula (Canto Superior Direito):**\n    *   Identificador do apresentador: \"Marcus Vinicius Lam...\"\n    *   Título da sala: \"Sala de Aula de OAC\"\n    *   Contador de tempo/gravação: \"25:10\" (com indicador de gravação ativo em vermelho)\n\n**2. Descrição de Diagramas e Fluxo de Dados:**\n\nA área principal do slide, destinada à apresentação de conteúdo visual, é inteiramente escura e vazia. **Não há diagramas visíveis** de Datapath, Pipeline, Hierarquia de Memória, nem qualquer código (Assembly, C, Verilog) ou outro conteúdo técnico gráfico nesta parte do slide. A apresentação do material didático, se existindo, não está sendo exibida no momento da captura.\n\n**3. Conteúdo Técnico Implícito e Semântico (a partir do bate-papo):**\n\nEmbora não haja conteúdo visual explícito na área do slide, as mensagens do bate-papo público fornecem um contexto rico e denso em informações técnicas relevantes para a Arquitetura de Computadores:\n\n*   **Paralelismo de Hardware:** A discussão sobre \"4 nucleos e 4 threads\" indica tópicos como processadores multicore, multithreading (simultâneo ou não), e a sua relação com o desempenho computacional.\n*   **Desempenho e Gerenciamento Térmico:** A frase \"aí o pc pega fogo\" sugere uma discussão sobre o balanço entre desempenho e o consumo de energia/dissipação térmica em arquiteturas de alto desempenho.\n*   **Otimização de Desempenho:** A menção \"fatorando fica super(pipeline+escalar)\" aponta para técnicas de otimização de execução de instruções, como pipelining (processamento em estágios de instruções) e arquiteturas escalares (capacidade de iniciar mais de uma instrução por ciclo, geralmente em um pipeline).\n*   **Métricas de Desempenho:** \"IPC 9 CPI 1/9\" são métricas cruciais em arquitetura de computadores:\n    *   **IPC (Instructions Per Cycle):** Número médio de instruções executadas por ciclo de clock. Um IPC de 9 seria excepcionalmente alto, sugerindo talvez um valor teórico ou uma condição muito específica.\n    *   **CPI (Cycles Per Instruction):** Número médio de ciclos de clock necessários para executar uma instrução. CPI de 1/9 é equivalente a IPC de 9. A discussão sobre \"9?\" pelo outro aluno sugere questionamento ou surpresa sobre este valor.\n*   **Pipelining e Níveis de Abstração:** A pergunta \"a pipeline é só da micro isntruções?\" indica uma reflexão sobre a granularidade do pipelining – se ele opera apenas no nível de microinstruções (hardware interno do processador) ou também no nível das instruções de máquina (ISA - Instruction Set Architecture). Isso toca na distinção entre microarquitetura e arquitetura do conjunto de instruções.\n*   **Categorização de Arquiteturas:** A questão \"em qual categoria se encaixa o SIMD?\" (Single Instruction, Multiple Data) demonstra um interesse na classificação de arquiteturas paralelas, como a taxonomia de Flynn, e a aplicação de SIMD em computação vetorial ou processamento de dados em massa (por exemplo, em GPUs ou extensões de instrução como SSE, AVX).\n\nEm suma, enquanto o slide em si não apresenta conteúdo visual, o contexto da aula de Arquitetura de Computadores é fortemente reforçado e detalhado pelas conversas no bate-papo, abordando tópicos fundamentais como paralelismo, desempenho, métricas de execução, otimização de pipelines e classificações de modelos de computação.",
        "transcription": "Vamos lá. Unidade Operativa e Unidade de Controle. Então, vamos primeiro.",
        "video_source": "OAC_2022-04-11.mp4"
    },
    {
        "id": 8,
        "timestamp_start": 1511.56,
        "timestamp_end": 3048.06,
        "slide_description": "Este slide, parte de uma aula de Arquitetura de Computadores da UnB (Universidade de Brasília, disciplina CIC0099 - Organização e Arquitetura de Computadores, ministrada pelo Prof. Marcus Vinicius Lamar), apresenta um diagrama detalhado de um *datapath pipeline* de cinco estágios, com o título \"Busca de instrução\" e focado no exemplo de uma instrução \"Load\".\n\n**1. Transcrição de Texto e Rótulos Visíveis:**\n\n*   **Cabeçalho do Slide:** \"UnB – CIC0099 – Organização e Arquitetura de Computadores\", \"Universidade de Brasília\", \"Departamento de Ciência da Computação\", \"CIC0099 - Organização e Arquitetura de Computadores\", \"Prof. Marcus Vinicius Lamar\".\n*   **Título do Slide:** \"Busca de instrução\", \"Ex:: Load\".\n*   **Componentes do Diagrama e Rótulos:**\n    *   `PC` (Program Counter)\n    *   `Instruction memory`\n    *   `Address` (entrada da memória de instrução e de dados)\n    *   `Instruction` (saída da memória de instrução)\n    *   `IF/ID` (Registrador de Pipeline: Instruction Fetch / Instruction Decode)\n    *   `Read register 1`, `Read register 2` (entradas para o banco de registradores)\n    *   `Write register` (entrada para o banco de registradores)\n    *   `Write data` (entrada para o banco de registradores e para a memória de dados)\n    *   `Registers` (banco de registradores)\n    *   `Read data 1`, `Read data 2` (saídas do banco de registradores)\n    *   `Imm Gen` (Immediate Generator)\n    *   `ID/EX` (Registrador de Pipeline: Instruction Decode / Execute)\n    *   `Shift left 1` (unidade de shift)\n    *   `Add` (unidade de soma, há duas: uma para PC+4 e outra para cálculo de endereço de desvio/salto)\n    *   `Add result` (saída de um dos somadores)\n    *   `ALU` (Arithmetic Logic Unit)\n    *   `Zero` (flag de saída da ALU)\n    *   `ALU result` (saída da ALU)\n    *   `EX/MEM` (Registrador de Pipeline: Execute / Memory Access)\n    *   `Data memory`\n    *   `Read data` (saída da memória de dados)\n    *   `MEM/WB` (Registrador de Pipeline: Memory Access / Write Back)\n    *   `Mux` (três multiplexadores: um no estágio IF, um no estágio EX, um no estágio WB)\n    *   Números `32` (indicando largura de dados em bits)\n    *   Número `4` (indicando incremento do PC)\n*   **Conteúdo do Chat (perguntas relevantes):**\n    *   \"esses registradores sempre estão escrevendo? n precisam de controle?\" (pergunta de Marcello Brandao Sca..., com marcação de tempo 14:37)\n\n**2. Descrição da Estrutura e Fluxo de Dados do Diagrama (Datapath Pipeline):**\n\nO diagrama representa um *datapath* de CPU em pipeline de cinco estágios, otimizado para a execução de instruções, como demonstrado pelo exemplo de uma instrução \"Load\". Cada estágio é separado por um registrador de pipeline que armazena e propaga o estado e os dados relevantes para o próximo estágio.\n\n*   **Estágio IF (Instruction Fetch - Busca de Instrução):**\n    *   Um `PC (Program Counter)` aponta para o endereço da instrução corrente.\n    *   A `Instruction memory` lê a instrução correspondente ao endereço do `PC`.\n    *   Um `Adder` incrementa o `PC` em 4 (`PC + 4`) para apontar para a próxima instrução sequencial.\n    *   Um `MUX` seleciona entre `PC + 4` e um possível endereço de desvio/salto (controlado por lógica externa não detalhada) para atualizar o `PC`.\n    *   O registrador `IF/ID` armazena a `Instruction` buscada e o `PC + 4` para o estágio seguinte.\n\n*   **Estágio ID (Instruction Decode / Register Fetch - Decodificação de Instrução / Busca de Registradores):**\n    *   Recebe a `Instruction` e `PC + 4` do registrador `IF/ID`.\n    *   A `Instruction` é decodificada para identificar os registradores-fonte (`Read register 1`, `Read register 2`) e o registrador de destino (`Write register`).\n    *   A unidade `Registers` (banco de registradores) lê os valores de `Read data 1` e `Read data 2` dos registradores-fonte.\n    *   A unidade `Imm Gen (Immediate Generator)` estende o campo imediato da instrução para 32 bits.\n    *   O registrador `ID/EX` passa `Read data 1`, `Read data 2`, a saída do `Imm Gen` e informações do registrador de destino para o estágio de execução.\n\n*   **Estágio EX (Execute - Execução):**\n    *   Recebe dados do registrador `ID/EX`.\n    *   Um `Shift left 1` opera sobre o valor imediato (comum para cálculo de endereços de desvio).\n    *   Um `Adder` calcula um endereço de desvio (somando `PC + 4` com o imediato shiftado), produzindo `Add result`.\n    *   Um `MUX` escolhe o segundo operando da `ALU`: ou `Read data 2` (para operações de registradores) ou a saída do `Imm Gen` (para operações com imediato, como endereçamento de Load/Store).\n    *   A `ALU (Arithmetic Logic Unit)` executa a operação especificada pela instrução (e.g., adição para cálculo de endereço, para instruções Load/Store). Toma `Read data 1` como primeiro operando e a saída do `MUX` como segundo. Gera o `ALU result` e um flag `Zero`.\n    *   O registrador `EX/MEM` transfere o `ALU result`, `Read data 2` (necessário para instruções Store) e as informações do registrador de destino para o estágio de memória.\n\n*   **Estágio MEM (Memory Access - Acesso à Memória):**\n    *   Recebe dados do registrador `EX/MEM`.\n    *   A `Data memory` realiza operações de leitura ou escrita.\n        *   Para uma instrução `Load`, o `ALU result` (calculado no estágio EX como o endereço efetivo) é usado como `Address` para a memória.\n        *   A `Data memory` retorna o valor lido como `Read data`.\n        *   (Para uma instrução `Store`, o `Read data 2` seria usado como `Write data` para a memória).\n    *   O registrador `MEM/WB` passa o `Read data` (da memória de dados), o `ALU result` (do estágio EX) e as informações do registrador de destino para o estágio de escrita de volta.\n\n*   **Estágio WB (Write Back - Escrita de Resultado):**\n    *   Recebe dados do registrador `MEM/WB`.\n    *   Um `MUX` final seleciona qual valor será escrito de volta no banco de registradores: `Read data` (para uma instrução `Load`) ou `ALU result` (para uma instrução R-type, como ADD).\n    *   O valor selecionado (`Write data`) é enviado de volta ao banco de `Registers` (no estágio ID) e escrito no registrador de destino especificado por `Write register`. Um sinal de controle `RegWrite` (não explicitamente mostrado no datapath mas implícito) é necessário para habilitar a escrita.\n\n**Fluxo de Dados para uma Instrução \"Load\":**\n1.  **IF:** A instrução `Load` é buscada da `Instruction memory`.\n2.  **ID:** A instrução `Load` é decodificada. O valor do registrador base é lido em `Read data 1`, e o campo imediato (offset) é estendido por `Imm Gen`.\n3.  **EX:** A `ALU` calcula o endereço de memória efetivo, somando `Read data 1` e a saída do `Imm Gen`. O resultado é o `ALU result`.\n4.  **MEM:** A `Data memory` usa o `ALU result` como `Address` e lê o dado armazenado naquele endereço, resultando em `Read data`.\n5.  **WB:** O `MUX` seleciona o `Read data` vindo da `Data memory`, e este valor é escrito de volta no registrador de destino especificado na instrução `Load`, dentro do banco de `Registers`.\n\nA pergunta do chat sobre a necessidade de controle para a escrita nos registradores (`\"esses registradores sempre estão escrevendo? n precisam de controle?\"`) é pertinente, pois o diagrama mostra as entradas de escrita (`Write register`, `Write data`) mas omite explicitamente o sinal de controle `RegWrite`, que é fundamental para a funcionalidade correta do pipeline. A largura de 32 bits dos dados e do imediato é consistente com uma arquitetura MIPS de 32 bits.",
        "transcription": "Vamos implementar um pipeline normalzinho, de cinco estágios, lá do Patterson. Tá? O estágio IF (Instruction Fetch), ID (Instruction Decode). Agora vocês vão poder entender por que que aqui é chamado Instruction Decode. Aí, leitura do banco de registradores. EX, que é de Execution. MEM, que é acesso à memória de dados, a memória de dados, tanto para escrita quanto para leitura. E WB, que é o Write Back. Certo? O que que a gente tem que controlar em cada um desses estágios? Então, observando aqui o nosso caminho de dados do uniciclo. Por que? Quem que é mais parecido com o pipeline? O uniciclo ou o multiciclo? Essa é uma pergunta extremamente profunda que agora vocês têm condições de responder. Qual processador é mais parecido com o pipeline? O uniciclo ou o multiciclo? Calma lá, que é todo mundo respondendo aí. Tá certo? Multiciclo? Não. Multiciclo. Então, a gente só tem que investir, né? Qual processador é mais parecido com o pipeline? Uniciclo ou multiciclo? Calma lá, que é todo mundo respondendo aí. Tá certo? A gente só tem que investir, né? Multiciclo. Então, vamos lá. Calma lá, eu já tenho ferramentas para discutir isso com vocês. No multiciclo, então, vamos pensar: qual era uma das vantagens do multiciclo? Exatamente, o Eduardo acerta, o Marcelo acerta, como nunca o Eduardo acerta. Então, vamos lá. No multiciclo, não fica triste, no multiciclo. Qual era a grande vantagem do multiciclo? Poder usar uma arquitetura Harvard, desculpa, uma arquitetura Von Neumann. Eu tenho uma única memória que eu vou ler dados e ler instruções, certo? Se eu consigo pipelineizar essa memória Von Neumann, vai acontecer aquele problema, né, que a gente viu lá no início, né, de dar hazard estrutural. Porque, ao mesmo tempo, eu vou querer ler instruções e, ao mesmo tempo, eu vou querer, por exemplo, ler dados. E a memória atual não consegue fazer isso, né? Então, o multiciclo veio para tentar melhorar o uniciclo. Mas o pipeline, ele é muito mais parecido com o uniciclo, certo? Porque a unidade funcional é utilizada apenas uma vez em um ciclo de clock, que seria no caso o uniciclo da instrução. Isso é o uniciclo. Então, suponho, acho que sim. Vocês já fizeram um controle, já fizeram tudo isso aqui, analisamos tudo. Bom, o que eu vou querer fazer? Eu vou querer pegar esse caminho de dados aqui e dividir ele em cinco etapas. Quais são essas etapas? Então, está aqui. A primeira etapa vai ser a de busca da instrução. Então, qual é a unidade funcional? A memória de instruções. Então, notem, o que eu peguei foi pegar esse somador aqui e botar para um estágio de leitura da memória. Portando o meu multiplexador aqui, colocando ele para cá e passando para cá também esse multiplexador. Esse multiplexador também estou passando aqui para frente, que é esse aqui. Depois eu tenho o estágio de ID (Instruction Decode), leitura de registradores, que é uma unidade funcional de registradores. Então, esse segundo estágio está aqui. E se eu sei a instrução, eu sei também o imediato dessa instrução. Depois, o próximo estágio é o estágio de execução e cálculo de endereço. Então, eu vou fazer esse cálculo aqui e a ULA. Eu vou colocar, então, esses elementos funcionais em um estágio que está aqui. Aqui não está mostrando o controle, tá pessoal? Então, aqui está o cálculo do endereço do branch e do JAL. E aqui, então, a nossa ULA. Certo? A saída desse somador aqui vem para esse multiplexador, que é esse aqui. A saída desse somador vai para esse multiplexador. O quarto estágio é o estágio de acesso à memória, que está aqui. Certo? A nossa memória. E a gente já vai ver por que isso aqui está vindo até aqui e depois voltar. E o Write Back. Qual é a unidade funcional do Write Back? Qual é a unidade funcional que eu uso na escrita do resultado? Não, qual é a unidade funcional? Aqui é a memória de dados. Aqui é a ULA e o somador. Aqui vão ser os registradores. Aqui é a memória de instruções e esse somador de PC mais 4. Qual é a unidade funcional usada aqui? O que esse estágio deve fazer, pessoal? Deve escrever o resultado. E deve escrever o resultado onde? Onde que esse aqui escreve o resultado? No banco de registradores. Então, a unidade funcional aqui também é o banco de registradores. Certo? Nós já vimos que esse estágio usar o banco de registradores e esse estágio também usar o banco de registradores não é um hazard estrutural. Porque a gente projetou o banco de registradores para fazer isso: ler dois registradores e escrever em terceiro, certo? Dentro de um somador. Então, esse é o somador funcional aqui, também é o banco de registradores. Certo? Então, assim a gente dividiu o nosso uniciclo em cinco estágios. Notem que a filosofia aqui é diferente da filosofia do multiciclo. No multiciclo, eu tinha que cada estado fazia uma tarefa para completar a instrução. Aqui não, a gente só pegou o uniciclo e dividimos ele. É o mesmo circuito do uniciclo. Por isso que eu digo que o uniciclo é o mesmo circuito do uniciclo. Eu disse para vocês: se vocês fizeram o laboratório 3 bem feito, o restante dos laboratórios seriam muito mais fáceis. Ok? Então, está aqui. Então, o fluxo de dados é sempre esquerda para a direita, certo? Com exceção desses dois aqui, que aqui eu obtenho esse resultado que eu vou aplicar ele aqui na entrada. Aqui eu obtenho o resultado que eu vou usar ele aqui. Certo? O restante dos dados, ele flui da direita para a esquerda. Ok? Beleza. E como é que eu separo estágios? A gente viu no uniciclo que para eu separar em estágios, basta eu colocar registradores temporários. O resultado de um ciclo vai ser armazenado no registrador temporário para ser utilizado no outro ciclo. Essa foi a filosofia do uniciclo, até que a gente colocou os registradores IF/ID, ID/EX, EX/MEM, MEM/WB. Certo? Aqui, então, já que a gente vai ter que pegar os resultados nesse ciclo e usar no ciclo seguinte, nós vamos ter que acrescentar registradores aqui. Certo? Então, esses aqui, sempre entre uma etapa e a outra etapa, vou ter que botar um registrador. Uma etapa, outra etapa, um registrador, e assim por diante. Então, no nosso caso, nosso pipeline de cinco estágios, eu vou precisar de quatro registradores de pipeline. Então, esse aqui é o registrador IF/ID, que fica entre os estágios IF e o estágio ID. Certo? Esse aqui é o registrador ID/EX, que fica entre os estágios ID e EX. Esse aqui é o registrador EX/MEM, que fica entre o estágio EX e o estágio MEM. E esse aqui é o MEM/WB, que fica entre o estágio MEM e o estágio WB. Certo? Então, eu vou ter que botar um registrador aqui. E o que cada um desses registradores vai ter que armazenar? Aquilo que for necessário passar para o estágio seguinte. Então, no registrador IF/ID, o que eu preciso passar para o estágio seguinte? Eu preciso passar o PC, porque ele vai ser utilizado aqui depois. Certo? Então, eu tenho que passar o PC para o próximo estágio, e depois para o próximo estágio, para que ele seja utilizado aqui. Eu preciso armazenar a instrução também, porque a instrução é a que eu vou usar para a instrução, é a que vai vir no segundo estágio, para ela ser segmentada em seus campos. Então, esse registrador IF/ID tem quantos bits? Registrador IF/ID, quantos bits? Quantos bits tem aqui? 32. Quantos bits tem aqui? 32. Moral da história: o registrador IF/ID é um registrador de 64 bits com dois campos: o PC e a instrução. Certo? Mas é o único registrador de 64 bits. Ok? Ah, por que eu não uso registradores separados? Porque o controle vai ficar mais difícil. É melhor eu ter um único registrador que eu sei exatamente quanto que esses registradores vão ser escritos na subida do clock. Esses registradores vão armazenar esses números, todos eles. Esse registrador vai armazenar esses números na subida do clock, de um mesmo ciclo de clock, né? Eu tenho um ciclo de clock que vai acionar a escrita nesse, nesse, nesse e nesse. Ok? No registrador ID/EX. Então, ele precisou ter 32 bits para o PC, 32 para a leitura do Reg1, 32 para a leitura do Reg2 e 32 para o imediato. Bom, esse registrador ID/EX vai ter quantos bits? Isso mesmo, 128. Foi rápido, estou lendo a mente do Marcelo, do Eduardo. Certo? 128 bits. O registrador EX/MEM vai ter 32 bits aqui do endereço, vai ter 32 bits aqui do resultado da ULA e 32 bits do registrador B, que é ele que tem que ser escrito na memória. E mais 1 bit desse sinal de zero. Certo? Por quê? Porque a gente está colocando que somente nesse estágio aqui é que eu vou selecionar, naquele multiplexador aqui, qual é o endereço do branch e do JAL. Certo? Então, 97 bits, exato. E esse registrador que vai ter 32 bits do endereço da memória, mais 32 bits do resultado da ULA. Certo? Então, vai ter 64 bits. Então, são esses 4 registradores. O funcionamento é que todos eles funcionam na mesma borda de subida. Vem uma borda de subida, todos eles são atualizados. Calma que daí nós vamos ver quando vai precisar de controle. Enquanto todos eles estão sendo atualizados sempre na borda de subida. Ok? Depois complica um pouquinho o circuito. Beleza. Então, praticamente está pronto aqui o nosso caminho de dados do pipeline. Certo? É isso aí. É um uniciclo dividido em cinco estágios. Então, por exemplo, quero executar o Load. Então, primeiro, para a execução do Load. Sempre quando tiver verde, é porque a unidade está sendo utilizada. Hachurado quer dizer verde. No lado direito está sendo lido e verde do lado esquerdo está sendo escrito. Certo? Então, para um Load, eu vou ler a instrução da memória, que eu não sei que é um Load ainda. E vou, quando vier a subida do clock, gravar nesse registrador. E já vou calcular PC mais 4 e disponibilizar ele aqui na entrada. Embora disponibilizar ele na entrada não. Somente aqui eu vou saber quando que eu vou usar esse multiplexador. Certo? Eu vou pegar o PC e passar para frente. Então, vem a borda de subida do clock. Esses dados são escritos no IF/ID. Ok. Vem o estágio ID. O estágio ID faz o que? Ele pega a instrução e lê do banco de registradores. Então, notem que aqui está sendo utilizado a leitura do banco de registradores, o cálculo do imediato. Ao final desse ciclo, vira a borda de subida, esse aqui vai ser escrito. É um Load, lembre-se que a instrução é um Load. Ok. Cálculo de endereço, execução. Então, aqui a ULA vai calcular o endereço do Load. Está aqui. E essa somadora aqui, a princípio, não vai estar calculando nada. Ou melhor, vai estar calculando, vai estar gastando energia, mas a gente não vai usar esse resultado. Porque é um Load, e esse aqui é o endereço do JAL. Então, do Load, esse aqui não deveria estar sendo utilizado. Certo? Então, eu vou calcular o endereço aqui. Ao final, todos esses dados vão ser armazenados no EX/MEM. Depois acessa a memória. É um Load. Então, eu vou ler os dados. Eu que não tinha... Vou ler os dados do registrador EX/MEM. Vou endereçar a memória e vou ler dessa memória. Ao final do ciclo, eu vou gravar esses dois dados aqui no registrador MEM/WB. Desses dois dados, o que me interessa é somente esse. Então, no quinto estágio, eu vou selecionar esse aqui para escrever no banco de registradores. Então, no quinto estágio, ele fica estranho assim porque ele utiliza essa parte de escrita do banco de registradores. Certo? Enquanto lá no segundo estágio, é utilizada a parte de leitura do banco de registradores. Entendido, pessoal? Só que isso aqui tem um bug. Vamos ver se vocês conseguem enxergar um bug. O bug está justamente nesse estágio. Pensem um pouquinho. Realmente, acertou, Eduardo. Está ali o bug. Qual é o bug que tem aqui? Nesse quinto estágio, eu vou estar escrevendo no banco de registradores, certo? Certo. Em qual registrador eu estou escrevendo no banco de registradores? Em qual registrador eu estou escrevendo? Em todos? Meu Deus do céu, não. No RD. Mas o RD de qual? Da instrução. Então, onde que está vindo esse RD aqui? Está vindo dessa instrução que tiver aqui, que eu nem sei. O Load está aqui. Eu queria escrever no RD do Load. Certo? No RD dessa instrução. Entendido isso? Porque aqui o RD está vindo dessa instrução. E eu nem sei que instrução está nesse estágio agora. Só um Load, Load mais um, Load mais dois, Load mais três. Na terceira instrução depois do Load, eu não sei qual é esse RD. Notaram que eu estou escrevendo no registrador errado? Tem que dar Flush? Não, a gente tem que corrigir esse bug. Já quer dar Flush em tudo. Corrigindo o bug, quando que eu tenho o valor de RD correto? Ah, o valor de RD correto é daqui, nesse estágio. Quando o Load está nesse estágio, aí eu sei o valor de RD correto, que é o RD do Load. Então, o que eu vou ter que fazer com esse aqui? O que eu vou ter que fazer com esse registrador aqui? Vou ter que passar ele para frente para ser utilizado nesse estágio aqui. Quando o Load chegar nesse estágio, eu tenho que ter aqui qual é o RD que eu vou escrever. Certo? Então, corrigindo o bug, fica assim: eu tenho o registrador RD, está aqui. Ao invés de entrar ele direto no registrador aqui, vou passar ele para frente, aqui. Esse aqui é o registrador RD, meu Deus. Esse aqui é o registrador RD. Vou passar ele para frente. E quando chegar nesse estágio é que eu vou usar o valor dele aqui. Porque esse é o estágio de Write Back. Certo? Qualquer instrução que tiver que escrever no banco de registradores, vai ser escrita nesse estágio. Certo? É assim. Então, eu estou escrevendo no registrador RD da instrução que está nesse estágio. Entenderam isso aqui? Eu preciso passar esse RD para frente, para frente, para frente, até eu poder utilizar ele aqui. Ótimo. Não, aqui não dá problema. Porque eu não tenho outro registrador RD aqui. Eu não tenho outro registrador RD aqui. Eu não tenho outro registrador RD aqui. O RD está sendo definido apenas pela instrução que tiver no estágio WB. Eu não vou entrar outro RD aqui, porque não faz sentido. O RD não. O RD só é utilizado no Write Back. Quando eu tiver que escrever no banco de registradores, é que eu tenho que saber qual é o RD. A gente vai passando para a frente, então. Não seria mais fácil armazenar ele em uma coisa intermediária? Não, mas a coisa intermediária são esses registradores aqui. Mas você não está armazenando de novo, armazenando de novo, armazenando de novo? Sim, a gente está passando o registrador RD, estágio a estágio, até que, quando a instrução chegar no Write Back, é ele que vai ser utilizado. Ou seja, coloca só em um. Aí dá problema, né? Dá problema. Ah, tá. E aí? Gastando energia? Gastando energia, mas é a solução melhor que tem. Não. Isso aí é pior. Poderia deixar ele travado? Até poderia, só que ia complicar o controle. Porque a gente não tem um RD travado em um uniciclo. No uniciclo, eu não tenho. O RD armazena, armazena, um registrador que tem que ser destravado. Então, assim não. Assim eu deixo ele exatamente igual a um uniciclo. Ok, moçada? Então, vamos lá. Vamos colocar os sinais de controle agora. Então, quais são os sinais de controle? Primeiro, eu tenho que controlar a ULA, né? Então, aqui eu tenho que ter o ALUOp. Então, eu preciso passar para frente o Funct, né? Os 10 bits. Os 10 bits de Funct, né? Que podem ser resumidos a esses 4 aqui. Certo? Para poder entrar na unidade de controle da ULA. Então, o meu ALUOp tem que ser utilizado. Assim eu defino qual é a instrução que a ULA vai fazer. A ALUSource, que me diz qual é o... Da onde que vem o segundo argumento da ULA. Se vem do banco de registradores ou se vem do imediato. Então, quem nota que agora... Não, deixa assim. Ou se vem do imediato. Vamos ver o que é mais aqui. Tem o RegWrite aqui. Que diz se esse banco de registradores deve ser escrito ou não. E, nesse estágio, eu tenho o MemWrite, o MemRead, escreve Mem, aquele sinalzinho que diz se é um branch ou não é um branch. E essa porta AND que vai controlar esse multiplexador aqui. Exatamente essa ideia. É o uniciclo. Exatamente essa ideia do uniciclo aqui. Eu tenho que ter esse sinal de branch. Ok? Então, eu tenho que... Ah, faltou os últimos. E, por último, eu preciso ter... Completar, quer dizer, controlar esse MemToReg. Certo? Que vai me dizer o que tem que ser escrito no banco de registradores. Se é a saída da memória ou a saída da ULA. Então, note que os controles do pipeline são exatamente os mesmos. São exatamente os controles do uniciclo. Notaram isso? São os mesmos sinais de controle do uniciclo. Só que aplicados em tempos diferentes ao caminho de dados. O que isso significa, professor? Então, vamos analisar o que tem que ser controlado em cada estágio. No estágio IF, o que eu preciso controlar? No estágio IF, nada. Para fazer a leitura aqui do PC, eu não preciso fazer nada. No estágio ID, o que eu preciso controlar? Esse sinalzinho azul no estágio ID. RegWrite? Ok. O RegWrite é aplicado aqui. Mas quem controla se deve ou não escrever no banco de registradores é o estágio WB. É nesse estágio aqui que eu vou saber se eu devo ou não escrever no banco de registradores. O que é escrito no banco de registradores ocorre nesse quinto estágio. O que é escrito no banco de registradores é o RegWrite. Ok? Então, no estágio ID, eu não preciso controlar nada também. Exato. No estágio EX, bom, no estágio EX, eu preciso controlar o ALUOp, o ALUSource. No estágio de MEM, eu preciso controlar o MemRead, o MemWrite e o Branch. Esses três. E no estágio WB, eu preciso controlar o MemToReg e o RegWrite. Tá? Tem que ser controlado aqui. Certo? Então, esse aqui é o que dá a análise que a gente acabou de fazer. Beleza. Como é que eu controlo isso? A gente já projetou o controle do uniciclo. Vocês lembram disso? O controle do uniciclo é essa tabelinha verdade aqui. Certo? Lembram dessa tabelinha verdade que vocês têm que estar implementando no processador uniciclo de vocês. Ótimo. Só que, em um uniciclo, vamos voltar lá.",
        "video_source": "OAC_2022-04-11.mp4"
    },
    {
        "id": 9,
        "timestamp_start": 3052.18,
        "timestamp_end": 6827.16,
        "slide_description": "Como Engenheiro de Computação Sênior, analiso o slide da aula de Arquitetura de Computadores. O conteúdo principal é um diagrama de pipeline desenrolado que ilustra uma situação de *hazard* de dados (conflito de dados) do tipo Load-Use, onde o *forwarding* (encaminhamento de dados) não é suficiente para evitar um *stall* (bolha/parada), exigindo a inserção de uma instrução NOP.\n\n**1. Transcrição de Texto:**\n\n*   **Título do Slide:** \"Quando forward não é possível\"\n*   **Informações da Aula/Universidade:**\n    *   \"UnB – CIC0099 – Organização e Arquitetura de Computadores\"\n    *   \"Universidade de Brasília\"\n    *   \"Departamento de Ciência da Computação\"\n    *   \"Prof. Marcus Vinicius Lamar\"\n*   **Linha do Tempo (Clock Cycles):** \"Time (in clock cycles)\" e \"CC 1\", \"CC 2\", \"CC 3\", \"CC 4\", \"CC 5\", \"CC 6\", \"CC 7\", \"CC 8\", \"CC 9\", \"CC 10\"\n*   **Ordem de Execução do Programa (Instruções):** \"Program execution order (in instructions)\"\n    *   `lw x2, 20(x1)`\n    *   `and becomes nop`\n    *   `and x4, x2, x5`\n    *   `or x8, x2, x6`\n    *   `add x9, x4, x2`\n*   **Anotações no Diagrama:** \"bubble\" (associado à instrução `and becomes nop`).\n\n**2. Descrição do Diagrama (Pipeline e Fluxo de Dados):**\n\nO diagrama representa um pipeline de 5 estágios, com a execução de cinco instruções escalonadas ao longo de dez ciclos de clock (CC 1 a CC 10). Os estágios do pipeline são visualmente representados por blocos:\n*   **IM (Instruction Memory):** Estágio de busca de instrução (IF - Instruction Fetch).\n*   **Reg (Registers):** Bloco que representa o acesso ao banco de registradores (leitura para o estágio ID - Instruction Decode, e escrita para o estágio WB - Write Back).\n*   **Trapézio cinza (ALU):** Estágio de execução (EX - Execute), onde operações aritméticas e lógicas são realizadas.\n*   **DM (Data Memory):** Estágio de acesso à memória de dados (MEM - Memory Access), usado por instruções de Load/Store.\n\n**Fluxo de Instruções e Conflitos de Dados:**\n\n1.  **`lw x2, 20(x1)` (Load Word):**\n    *   Inicia em CC 1 (IM) e completa a escrita no registrador `x2` em CC 5 (Reg/WB).\n    *   O valor carregado da memória de dados (`DM`) fica disponível ao final de CC 4.\n\n2.  **`and becomes nop` (NOP inserido):**\n    *   Esta linha de execução representa uma instrução NOP (No Operation) que foi inserida no pipeline para resolver um conflito de dados.\n    *   Ela ocupa os ciclos CC 2 (IM) a CC 6 (Reg/WB), efetivamente atrasando as instruções subsequentes.\n    *   A anotação \"bubble\" está posicionada sobre seu estágio `Reg` em CC 3, indicando que o *hazard* foi detectado neste ponto, exigindo a inserção da bolha.\n\n3.  **`and x4, x2, x5` (Logical AND):**\n    *   Esta instrução necessita do valor de `x2`, produzido pela `lw x2, 20(x1)`.\n    *   Ela inicia em CC 3 (IM) e tenta ler `x2` em seu estágio `Reg` (ID) em CC 4.\n    *   **Hazard Load-Use:** O valor de `x2` é produzido pela `lw` no final do estágio `DM` (CC 4). No entanto, `and x4, x2, x5` precisa de `x2` no início do seu estágio `Reg` (ID) em CC 4 para que possa ser usado no estágio `ALU` (EX) em CC 5. Mesmo com *forwarding* do estágio `DM` da `lw`, a latência de 1 ciclo impede que o dado esteja disponível a tempo no *mesmo* ciclo de clock em que é necessário na fase ID.\n    *   A solução ilustrada é a inserção da `nop` (`and becomes nop`), que atrasa a `and x4, x2, x5` por um ciclo. Assim, `and x4, x2, x5` efetivamente usa `x2` via *forwarding* do estágio `DM` da `lw` (final de CC 4) para o início do seu estágio `ALU` (EX) em CC 5. O diagrama mostra uma seta azul do `DM` da `lw` (CC 4) para o `Reg` da `and x4, x2, x5` (CC 4), representando a dependência e a necessidade de `x2`.\n    *   A instrução escreve o resultado em `x4` no final de CC 7 (Reg/WB).\n\n4.  **`or x8, x2, x6` (Logical OR):**\n    *   Também necessita de `x2` (da `lw x2, 20(x1)`).\n    *   Inicia em CC 4 (IM) e lê `x2` em seu estágio `Reg` (ID) em CC 5.\n    *   **Forwarding:** O valor de `x2` da `lw` (disponível do `DM` em CC 4) pode ser encaminhado para o estágio `ALU` (EX) da instrução `or` em CC 6 (lendo em ID CC 5). Uma seta azul indica este *forwarding* do `DM` da `lw` (CC 4) para o `Reg` da `or` (CC 5). O resultado é escrito em `x8` no final de CC 8 (Reg/WB).\n\n5.  **`add x9, x4, x2` (Arithmetic ADD):**\n    *   Necessita de `x4` (da `and x4, x2, x5`) e `x2` (da `lw x2, 20(x1)`).\n    *   Inicia em CC 5 (IM) e lê `x4` e `x2` em seu estágio `Reg` (ID) em CC 6.\n    *   **Forwarding `x4`:** O valor de `x4` da `and x4, x2, x5` é produzido no estágio `ALU` (EX) em CC 5. Este valor pode ser encaminhado do `ALU` da `and` (CC 5) para o estágio `ALU` (EX) da `add` em CC 7 (lendo em ID CC 6). Uma seta azul indica este *forwarding* do `ALU` da `and` (CC 5) para o `Reg` da `add` (CC 6).\n    *   **Forwarding `x2`:** O valor de `x2` da `lw x2, 20(x1)` é produzido no estágio `DM` (MEM) em CC 4. Este valor pode ser encaminhado do `DM` da `lw` (CC 4) para o estágio `ALU` (EX) da `add` em CC 7 (lendo em ID CC 6). Uma seta azul indica este *forwarding* do `DM` da `lw` (CC 4) para o `Reg` da `add` (CC 6).\n    *   O resultado é escrito em `x9` no final de CC 9 (Reg/WB).\n\n**Conclusão:**\nO slide demonstra graficamente um cenário de *pipeline* de processadores onde uma dependência de dados entre uma instrução de carga (`lw`) e uma instrução que utiliza imediatamente o resultado carregado (`and x4, x2, x5`) não pode ser resolvida apenas com *forwarding*. Para essa dependência de \"load-use\", é necessário inserir um ciclo de *stall* (representado pela `and becomes nop`) para garantir a disponibilidade dos dados no momento correto, permitindo que as instruções subsequentes continuem seu fluxo de execução, inclusive utilizando *forwarding* para outras dependências.",
        "transcription": "Aqui, no ciclo único, no ciclo único, sabem que eu sei qual é a instrução? Ele já gera todos os sinais. Certo? E todos os sinais vão ser aplicados ao datapath. No pipeline, não. No pipeline, ele vai gerar todos os sinais quando? Quando ele souber qual é a instrução. Isso acontece no estágio ID, de decodificação da instrução. Então, por isso que esse estágio é chamado de ID. Porque é ele que a gente vai pegar e saber qual é a instrução. Esse aqui é o estágio IF, que vai entrar para trás. Estágio ID. E vamos gerar todos os sinais de controle. No ciclo único, esses sinais de controle entravam direto no caminho de dados. Aqui, não. Aqui, agora, como essa instrução aqui vai começar a andar no pipeline, os controles têm que ser aplicados a cada estágio que ela passar. Então, aqui eu decodifiquei as instruções e eu vou precisar passar esses controles para frente. Porque nem no estágio IF, nem no estágio ID eu não preciso controlar nada. Então, eu vou escrever todos eles no registrador de pipeline. No estágio WB eu tenho que controlar o MemToReg e o RegWrite. Esses dois aqui. Por isso que tem dois aqui. No estágio de memória tem que controlar o Branch, o MemRead e o MemWrite. E no estágio de execução tem que controlar o ALUOp e o ALUSrc. Então, eu vou escrever todos eles no registrador de pipeline. Quando vier o ciclo de clock, esses controles são escritos aqui e essa instrução que está aqui vem para cá. Então, essa aqui é o estágio EX. Então, os sinais de controle do estágio EX são aplicados às unidades funcionais que tem aqui. Certo? Porque a instrução que eu estou fazendo está aqui agora. Ok. Vem o sinal de clock. Os estágios são armazenados aqui e esses outros controles que são de estágio seguinte são passados pelo registrador de pipeline. Quando a instrução está nesse estágio MEM, esses três sinais de controle do estágio MEM são aplicados a esse caminho de dados daqui. A leitura da memória é feita, etc. Quando vier o sinal de clock, os resultados desse estágio são gravados no registrador de pipeline e eu tenho que passar para frente o controle do Write Back. Quando a instrução estiver aqui, eu vou usar esses controles nesse caminho de dados. Notaram que o controle do pipeline é o mesmo controle do ciclo único, só que ao invés de aplicar tudo de uma vez no pipeline, não. Ele vai aplicando os devidos sinais de controle quando a instrução vai passando pelos estágios. Entendido, pessoal? Entendida essa filosofia de que eu preciso pegar esse sinal de controle e ir passando? Certo? Então, aqui significa esses sinais estão sendo aplicados ao caminho de dados que tem aqui. Esses sinais estão sendo aplicados ao caminho de dados que tem aqui. Esses sinais estão sendo aplicados ao caminho de dados que tem aqui. Exatamente, o controle é adequado. Aqui eu decodifiquei a instrução. Quer dizer, gerei todos os sinais de controle, só que só vão ser utilizados no seu estágio adequado. Ok? Por isso, chamava estágio de decodificação aqui. Dúvidas? Entendido isso? Vamos lá. Dúvidas? Pergunta. Qual é o tamanho desse registrador aqui agora? Exatamente, por causa do fundo que é branco. Tá? Qual é o tamanho desse registrador agora? O registrador `ID/EX`? 128. Por que 128? Porque eu tenho 32 mais 32 mais 32 mais 32. E mais os sinais de controle. 1, 2, 3, 4, 5, 6, 7, 8. Certo? Então, 128 mais 8. Entendido? Esse aqui são dois bits, né? E assim vai os outros. Aqui vai ser esse mais 1, 2, 3, 4, 5, 6, 5, 6, e esse aqui vai ser esse mais 1, 2. Ok. Então, está aqui agora o nosso caminho de dados com o controle. Então, nós temos aqui o nosso controle que vai gerar todos os sinais de controle, que vai ser armazenado em um registrador `ID/EX`. Os sinais do EX são vou controlar então o ALUSrc e o ALUOp. Certo? Passado pra frente, os sinais de memória vão controlar o Branch, vão controlar o MemWrite e o MemRead. Esses três sinais na área. E por último, o controle do Write Back. Que é o RegWrite e o MemToReg. Certo, pessoal? Então, dessa forma, nós padronizamos o nosso datapath de ciclo único. Então, vocês observem a saída do tempo. Eu vou colocar os registradores. Não. O controle é o mesmo. Não mudei a saída dos controles. O que eu estou fazendo é gravar todos os controles para usar no próximo estágio. Só que no próximo estágio eu só uso esses. Esses outros aqui eu vou ter que passar para frente para usar nesse estágio. E esse aqui eu vou ter que passar para frente para usar nesse caso. O caminho do controle, pode-se pensar assim, tá? Porque no ciclo único tu pegava tudo isso aqui e colocava tudo direto no caminho de dados. Agora não. É, por que que ele tem que ir no registrador? Porque quando essa instrução aqui tiver aqui, o controle que vai ser gerado é o dessa instrução que eu nem sei qual é. Certo? A minha instrução que eu quero é essa aqui. E aqui eu tenho o controle dela. Depois que essa instrução passar pra cá eu tenho aqui o controle dos estágios seguintes. Quando ela passar pra cá eu vou usar o último dos controles. Ok? Hazards!\n\nVamos agora deixar as coisas legais. Tá? Primeiro, vamos descobrir onde que tem hazards. Eu tenho essa sequência aqui: `SUB R_dest1, R_src1, R_src2`. `AND R_dest2, R_dest1, R_src3`. `OR R_dest3, R_dest1, R_src4`. `ADD R_dest4, R_dest2, R_dest1`. Certo? A minha pergunta é: tem hazards daqui pra cá? Daqui pra cá tem hazards? E do SUB para o AND? Tem. Ok? Como é que se resolve esse hazard através desse forwarding aqui, ó. Da saída da ULA. Certo? Quando eu já faço a subtração dos dois para a entrada da ULA. Quando eu vou calcular esse AND. Então, esse aqui eu resolvo esse hazard aqui. Ok. Do SUB para o OR tem hazards? Do SUB para o OR tem hazards? Tem. Também. Tá? Porque o SUB não levou as coisas do outro registrador do SUB, tá? Nesse estágio aqui, ó. Os resultados do SUB foram passados pra frente e agora vão ser gravados aqui, nesse registrador. Então, eu posso fazer um forwarding da saída desse registrador para a entrada da ULA. Que é onde, efetivamente, eu preciso do valor de `x2`. Tá? Na entrada da ULA. Aqui. Onde que eu tenho `x2` gravado. Então, eu calculo e gravou nesse registrador. A saída da ULA. A saída da ULA também é gravada no ciclo seguinte desse registrador. Então, quando eu precisar dele aqui na entrada da ULA, ele está gravado no registrador aqui. Que registrador é esse? Que registrador é esse aqui? Vamos lá, pessoal. Que registrador é esse aqui? `IF/ID` esse aqui? `ID/EX`. E ele aqui? `EX/MEM`. Esse aqui `MEM/WB`. São esses quatro registradores. Então, eu vou sair da saída do `MEM/WB` para a entrada da ULA dessa instrução. Esse aqui tem hazard em relação ao SUB. Então, vamos lá. O SUB só vai gravar no banco de registradores quando acabar esse ciclo. Então, quando acaba esse ciclo é que ele vai gravar o resultado no banco de registradores. Quando que eu preciso da leitura do banco de registradores aqui? Eu preciso que ele já esteja gravado aqui para poder ler o banco de registradores. Então, como esse aqui vai gravar só no final do ciclo, então tem um hazard sim aqui. Eu não tenho o valor `x2` gravado no banco de registradores. No início do ciclo, que é quando eu preciso entender esse hazard. Então, esse é um tipo de hazard que acontece internamente ao banco de registradores. Eu preciso do dado que vai ser gravado no final desse ciclo. É no final desse ciclo que o banco de registradores é utilizado. Mas eu preciso desses registradores no início do ciclo. Então, tem hazard aí sim, né? Escrever, ler ao mesmo tempo não dá. Então, o que nós vamos fazer? Para resolver esse problema aqui, e é por isso que esse aqui está hachurado do lado esquerdo e esse aqui está hachurado do lado direito, nós vamos fazer uma pequena mudança no nosso banco de registradores. Nosso banco de registradores agora, então vamos lá, aqui começa o ciclo e aqui termina o ciclo. Certo? Então, o banco de registradores seria escrito nessa borda de subida aqui. Certo? Onde o banco de registradores seria escrito. Para resolver esse hazard, vamos fazer a escrita do banco de registradores acontecer aqui, na borda de descida. Certo? Então, o que vai acontecer com esse estágio? Tem a borda de subida, tudo bem, na borda de descida esse resultado é gravado no banco de registradores. E a partir daqui, o registrador `X2` é escrito. Então, no início aqui, nesse meio ciclo inicial, o registrador está errado. Mas, no meio ciclo final, o `X2` está correto, porque ele foi gravado aqui na metade do ciclo. Certo? Então, eu vou ler o valor correto de `X2`. Então, para resolver esse hazard aqui do banco de registradores, basta a gente fazer que o banco de registradores seja escrito na metade, quer dizer, na borda de descida. Certo, pessoal? E com isso, a gente acaba com esse hazard daqui para cá. Todo mundo entendeu isso? Então, eu vou primeiro escrever na primeira metade do ciclo e ler na segunda metade do ciclo. E aí, ele já vai ler o valor correto, já que ele foi escrito aqui, nesse tempo aqui. Tranquilo? Então, essa aqui é a noção desse hazard de registrador, do banco de registradores para o banco de registradores. Esse aqui se resolve com forwarding, esse aqui se resolve com forwarding. E esse aqui a gente tem que fazer a escrita sendo na borda de descida. E desse STORE aqui para o `X2`, eu tenho hazard desse STORE para o `X2`? Tenho dependência desse para aquele ali? Não, por quê? Porque no final desse ciclo, ou melhor, no meio desse ciclo ele foi escrito. Então, no ciclo seguinte, esse aqui, não valeu o valor do `X2` direto para o banco de registradores. Então, ele foi escrito na metade desse ciclo aqui. No ciclo seguinte, ele já está escrito. Certo? Então, não tem o hazard daqui para lá. Então, hazards são só esses três aqui. Então, de repente, quer acabar com hazard, não saber como, acrescenta três bolhas. Daí, você sempre vai acabar com hazard, porque você vai estar alinhando esse estágio com esse estágio. Daí, nunca vai acontecer hazard. Quer dizer, alinhando o que eu digo, primeiro fazer esse estágio, para depois fazer esse estágio. Primeiro escreve para o registrador e depois lê. Só que isso é muito ineficiente como a gente viu na aula passada. Todo mundo entendeu? É, perde um pouco de desempenho. Não vale a pena fazer isso. E ficar acrescentando sempre três bolhas. Naquele exercício que eu deixei vocês fazerem, vocês deviam ter notado isso. Que a solução de corrigir hazard com bolhas NOPs não é eficiente. Ok, como é que se faz esses forwards aqui? Esse aqui e esse aqui. Primeiro, como vocês souberam que daqui para cá tem hazards? Me diz qual o algoritmo na cabeça de vocês usaram para saber que entre esse e esse nós temos um hazard aqui. Qual foi o algoritmo na cabeça de vocês para descobrir o que aconteceu que aqui tem hazards? Ah, vocês só olharam assim, ah, tem hazards. Certo? Não. Ah, porque eu sei não. Eu perguntei. E se tu armazena em um registrador, tá Marcelo? Quer dizer, se a instrução atual precisar do RD da instrução anterior, quer dizer, se `RS1` ou `RS2` da instrução atual for igual ao RD da instrução anterior, eu tenho hazards. Certo? Esse hazards aqui. Entendido? Branch. Não, não esquece branch. Branch não causa esse tipo de hazards. Não, mas coloque um `ADD RD anterior RS1 e RS2 atual`. Então, eu preciso testar se o `RS1` da instrução atual ou o `RS2` atual é igual ao RD da instrução anterior. É isso que eu tenho que verificar. Se for verdade, eu vou fazer esse forwarding aqui. Certo? Poderia ir para essa entrada da ULA, mas também poderia ir para essa outra entrada da ULA. Isso. Isso mesmo. Se o `X2` estivesse aqui e aqui fosse um `X5`, esse forwarding aqui iria para essa outra entrada da ULA. Certo? Se aqui fosse `X2` e aqui `X5`. Então, eu tenho que fazer ou preparar o forwarding para ele fazer um forwarding tanto para cá quanto para cá se for necessário. Certo? Então, está aqui. Vamos continuar analisando isso. Eu preciso de um forwarding. Que registrador é esse? Que registrador é esse? O `EX/MEM`. Certo? O `EX/MEM`. Então, eu preciso de um forwarding da saída do `EX/MEM` para a entrada da ULA. Da saída do `EX/MEM` para a entrada dessa ULA. Ok. Como é que souberam que daqui do OR para o SUB tem o hazard? Vamos usar a mesma coisa. `RS1` ou `RS2` da instrução atual é igual ao RD da instrução dois anteriores. Então, se houver, se isso for verdade, se o `RS1` for igual ao RD da instrução dois anteriores ou o `RS2` for igual ao RD da instrução dois anteriores, aí eu tenho que fazer esse forwarding aqui. Isso. Então, eu tenho que fazer esse forwarding aqui. Que registrador é o resultado que está no registrador `MEM/WB` para as entradas da ULA. Tanto essa quanto essa. Ok? Como é que aconteceu esse forwarding, esse hazard aqui? Eu preciso detectar ele? Daqui para cá? Eu preciso detectar esse hazard? Não. Porque eu já solucionei todos eles. Não, não mudei o RegWrite. Isso aí continua o mesmo. O hazard é gravado na borda de descida. Não tem nada a ver com o RegWrite. RegWrite tem mais a ver com se deve gravar ou não. Tá? Não quando deve gravar. Tá? Então, esse aqui a gente já solucionou quando a gente fez o registrador ser escrito na borda de descida. E esse aqui não tem hazard. Então, primeiro eu vou precisar de um multiplexador aqui na entrada, nas duas entradas da ULA. Quais são as entradas desse multiplexador? Primeiro, se por acaso não precisar de forwarding. Isso até três instruções, até duas instruções anteriores. Tá? Ou a instrução anterior ou a instrução dois anteriores. Então, primeiro multiplexador se eu não precisar de forwarding. Certo? Não. Tem que usar dois multiplexadores, Marcelo. Então, tu não consegue fazer desse modo. Eu vou ter que fazer um controle para o ForwardA, que é esse aqui, e um outro controle para o ForwardB, que é esse aqui. Então, nesse caso aqui, se não tiver hazard, ele tem que colocar aqueles dados do banco de registradores aqui para a ULA. Essa aqui é a primeira entrada. Mesma coisa se é um hazard que aconteceu desse estágio da saída da ULA anterior, que está gravado aqui no `EX/MEM`, para a entrada dos dois multiplexadores. Esse e esse. Certo? Então, eu tenho que verificar. Aconteceu o hazard da instrução seguinte? Sim. Então, tem que pegar esse dado aqui, que é a saída da instrução EX anterior, e colocar ele no nosso multiplexador e acionar o forwarding diretamente. Ou então é aquele que saiu da instrução dois anteriores. Onde é que está o resultado da ULA da instrução dois anteriores? Essa aqui é a instrução atual. Onde é que está o resultado da ULA da instrução dois anteriores? Se o da instrução anterior não for a instrução anterior, então eu vou ter que pegar esse dado aqui, certo? E fazer um forwarding pra cá. Só que a gente estava vendo ali as instruções tipo R. Pode acontecer de eu precisar de um forwarding em LOAD desse daqui para a entrada pra cá. Esse multiplexador aqui que vai ser ou o dado lido da memória ou o dado calculado pela ULA ser então entrado na entrada desses multiplexadores. Ok? E como é que eu controlo esses multiplexadores? Eu preciso saber o `RS1` e o `RS2` da instrução atual. São esses dois aqui. Então eu vou precisar do RD da instrução e da instrução dois anteriores. Então vou ter que passar o RD pra frente e pra frente. Para eu poder comparar se `RS1` e `RS2` é igual ao RD da instrução anterior que eu vou pegar daqui, ou se é igual à instrução dois anteriores que eu vou pegar daqui. Certo? Então o RD aqui eu vou ter que passar pra frente. E aqui agora vocês têm um conjunto de entradas para o multiplexador aqui, tem que entrar aqui, certo? E o Pakistanesqueceu. Ok? Entenderam como é que nós vamos fazer a unidade de forwarding? É um circuito combinacional, né, que... Não, não, não, não, não confunde as coisas. Nada de fazer um mux de 4 aqui. Tem que deixar isso aqui separado mesmo, tá? Não posso misturar esse mux aqui com o mux seguinte. Então eu teria que fazer um mux de todas as possíveis combinações. 8 desse aqui. Né, porque aqui tem 4. Eu teria que ter mais um mux de 2, então seria que ter um mux de 8. Não vale a pena. Ok? Então vocês saberiam projetar esse circuitinho aqui? É só montar a tabela verdade. Tá? Ou então... Não, deixa assim. É só montar a tabela verdade para vocês fazerem esse circuitinho. Beleza, então com isso a gente resolveu esse... Implementamos esse forward e esse forward. Tá? A saída do `EX/MEM`, o que está gravado no `EX/MEM` para a entrada da ULA e o que está gravado no `MEM/WB` para a entrada da ULA. Através desses dois multiplexadores aqui. Ok? Quando que o forward não é possível? Quando eu não posso usar o forward? É quando tem uma instrução LOAD seguida de uma instrução que precisa desse argumento `X2`. Certo? Então a gente viu que isso aqui não dá para implementar porque eu estaria prevendo o futuro, né? Porque o `X2` só vai estar pronto nesse instante de tempo e eu preciso dele nesse instante de tempo. Então não tem como. O que eu tenho que fazer? Inserir uma bolha. Certo? Inserindo uma bolha eu sei que agora o que tiver armazenado aqui, né? No registrador `MEM/WB` eu posso fazer um forward para a entrada da ULA aqui. Certo? Então como é que eu sei se eu preciso fazer esse caso? Então, aqui entrou o LOAD, o LOAD está sendo decodificado, o index está sendo calculado, aqui está indo na memória e aqui ele vai gravar na memória. Tá? Enquanto o AND aqui nesse estágio está sendo lido da memória, o AND, né? Que é a instrução seguinte. Lido da memória. No ciclo seguinte ele está sendo decodificado. Então é nesse estágio aqui, quando eu decodifiquei o meu AND, que eu sei quem é o `RS1` e `RS2`. Então, somente nesse estágio aqui que eu vou poder (é o pior caso é 3 bolhas, tá?) identificar que eu tenho esse tipo de hazard. Opa! O meu `X2` aqui, é igual ao meu `X2` da instrução anterior, nota, é igual ao `X2` da instrução anterior e a instrução anterior é um LOAD. Então é isso que eu tenho que detectar. Se o `RS1` ou o `RS2` da instrução atual, que é esse aqui, é igual ao RD da instrução anterior e a instrução anterior é um LOAD. Se isso acontecer, o que eu tenho que fazer? Eu tenho que não deixar essa instrução seguir, então eu preciso transformar ela em uma bolha, eu preciso dar um flush nessa instrução, não, não que seja, eu tenho que botar uma bolha aqui. Essa instrução que é o AND aqui, eu não posso deixar seguir. E eu tenho que reler essa instrução num ciclo seguinte. Certo? Então aqui eu tenho que manter o nosso `IM`, meu Deus do céu, claro que não. Eu vou ter que manter esse dado do `IM` aqui, certo? Para que ele possa então executar o AND de maneira normal, porque agora esse estágio e esse aqui estão, né, estão alinhados. Eu posso pegar a saída desse registrador e colocar aqui na entrada do AND. Entenderam isso? Então eu tenho que primeiro descartar essa instrução, e repetir a leitura dela aqui. Captaram essa ideia? Para que o AND possa ser executado normalmente. Certo, pessoal? E aí eu vou precisar desse forward aqui que por acaso ele não existe. Esse forward aqui. Certo, pessoal? Essa é a parte mais complicada de vocês, tá? Então se vocês não estiverem entendendo isso é... Tem que parar, sentar, avisar para conseguir entender. Então como é que eu vou fazer essa detecção desse hazard? Se o `RS1` ou o `RS2` da instrução atual for igual ao RD da instrução anterior, e a instrução anterior é um LOAD. Tá? Então como é que nós vamos fazer isso? Como é que eu sei que a instrução anterior é um LOAD? Eu veio nessa instrução aqui, que é um AND. Tá aqui, ó. Como que eu sei que a instrução anterior era um LOAD? Que a instrução anterior... Eu estou no estágio D. A instrução anterior está no estágio EX, certo? Aqui que eu estou decodificando o AND, e eu descubro. Opa! Aconteceu isso. Você tem que aguardar? Não, não precisa aguardar. Como é que eu sei que a instrução anterior era um LOAD? Nosso caso, foi a única instrução que lê memória. Foi a única instrução que lê da memória. LOAD. Moral da história. Se eu estou nesse estágio aqui, basta eu saber se o controle da instrução que tiver aqui... Esse aqui é o `ID/EX`, certo? `ID/EX` é esse aqui. Então, eu preciso saber se o controle da instrução que está aqui, o MemRead, é igual a 1. Tá? Se o MemRead dessa instrução aqui for igual a 1, é porque a instrução anterior era um LOAD. Certo? Vamos lá. Assim, ó. Então, nossa unidade de detecção desse tipo de hazard, tá? Vai ser o quê? Preciso do `RS1` e do `RS2` da instrução atual. Preciso do RD da instrução anterior. O LOAD está aqui. Aqui é o meu AND que eu estou decodificando. Certo? Então, se meu `RS1` e `RS2` atual for igual ao RD da instrução anterior. E a instrução anterior for LOAD. Quer dizer, basta eu pegar desse controlezinho aqui o MemRead. Certo? Aquele sinal que vai ser aplicado nesse estágio. Então, pegando o MemRead aqui, eu sei que a instrução que está aqui é um LOAD. Certo? Entendido isso? Porque a única vez que o MemRead vai ser ativado é se a instrução for um LOAD. Certo? Então, eu vou ter que fazer aqui uma unidadezinha combinacional, que tem `RS1`, `RS2` e esse MemRead aqui. E mais o RD anterior. Se um desses aqui for igual e o LOAD for, tiver aqui, o MemRead tiver ativado, o que que eu tenho que fazer? Eu preciso matar essa instrução. Certo? Eu preciso matar essa instrução. Como é que eu mato essa instrução? Eu mato a instrução. Se a instrução não escrever em lugar nenhum, o quê que ela fez? Se uma instrução não escrever em lugar nenhum, o quê que ela fez? Não escrever nem na memória, nem salvar, nem fazer isso aí. Certo? Seria ele não escrever em lugar nenhum. Então, o quê que eu vou fazer aqui? Eu vou, ao invés de eu mandar pra frente o meu controle do AND, eu vou mandar pra frente um controle que é todo zero. Não, eu vou substituir o controle do AND, que seria o certo para fazer o AND, por um controle que seja tudo zero. Certo? Então, o quê que vai acontecer aqui? A ULA vai fazer o `ALUOp` 00. Está faltando aqui aquele multiplexadorzinho da ULA, tá, pessoal? Lembrem-se disso. Não vou escrever nada na memória, porque todo o controle está zerado. Não vou escrever nada no banco de registradores, porque o controle está zerado. Certo? Então, no momento que eu coloco todos os controles, a partir daqui pra frente, como zero, a minha instrução se transformou numa bolha. Certo? Ao passar para o estágio seguinte, é uma bolha, uma bolha, e pá, essa bolha vai migrando no pipeline. Entendeu? Não é botar um NOP. Tá? Tranquilo? Entendendo tudo isso? Então, primeira coisa que eu preciso fazer, colocar essa bolha. Então, eu faço isso, colocando todos os controles aqui em zero. Quando essa instrução, com todos os controles zero, passar pra cá, ela não vai fazer nada, não vai fazer nada, não vai fazer nada. É isso. Primeira coisa que eu quero que vocês entendam. Certo? Qual é a outra coisa que eu preciso fazer? Eu preciso ler de novo essa instrução. Certo? Quer dizer, notem o seguinte, quando o AND está aqui, esse M é qual? Qual é a instrução que está sendo lida aqui? Quando o AND está aqui ainda. O AND está aqui, está no estágio ID. Que instrução está sendo lida aqui? Não, quero saber a instrução mesmo. Vocês têm condições de me dizer qual é a instrução. Não. Qual é a instrução seguinte ao AND? É o OR. Certo? Então, quando a gente tem o LOAD, aqui está o AND, aqui está o OR. Tá? Então, o que que tem que acontecer? Esse OR aqui, eu vou ter que matar essa instrução. Não posso deixar o OR ir pra frente. E eu vou ter que ter do mesmo endereço que eu estava antes. Certo? Então, vamos lá. Então, o que que eu preciso fazer? Além de botar uma bolha aqui no pipeline. Eu preciso detectar que aconteceu o hazard. Então, o que que eu preciso fazer? Parar a escrita no `IF/ID`. Certo? E parar a escrita no PC. Certo? Se eu parar a escrita no `IF/ID`, parar a escrita no PC, eu não vou entrar nem para o endereço seguinte. E a instrução que eu li aqui, não vai ser gravada aqui, que é o OR. Exatamente. Eu vou ter que controlar agora o `PC Write` aqui. O `Escreve PC`. Porque eu não posso mudar esse PC. Certo? E não posso deixar gravar essa instrução aqui e aqui também. Certo? Então, eu vou congelar essa unidade de modo que o OR não vai ser lido. O que vai ser lido de novo é o AND, que está aqui. Entenderam? Então, quando se descobre que aconteceu esse hazard, essa unidade aqui vai ter que congelar a escrita no `IF/ID`. Vai ter que congelar a escrita no PC. De modo que o AND não seja na subida do clock. Esse AND não seja atualizado. Ok? Certo? Então, eu repito aqui a leitura do AND. Porque aqui deveria ser o OR. Mas como esse estágio travou tudo para não ser escrito, então não vou ler aqui o OR. Eu vou ler o AND novamente. Ah, é. Assim é lá a lista de chamada e nós temos que usar o FATIM. Vocês receberam o convite de participar do lançamento do FATIM? Por e-mail? O resto do pessoal, o resto do povo, recebeu? Não. Foi hoje. Hoje de manhã que ele mandou. Ok? Então, me digam aí se receberam. Ok? Resolvido então esse FORWARD. Beleza. Então, detecção de hazards. Comparar os índices do registrador. ... (trecho omitido pela transcrição original) ... vai escrever, tá? Então, flush, descarta a instrução do pipeline, foi isso que a gente fez aqui, tinha um flush no AND que estava aqui, certo? E ele morreu. Stall, stall significa parar o pipeline, foi o que a gente fez aqui, a gente parou o pipeline, tá? Parou o início do pipeline. Então, se vocês tiverem dúvidas em relação a como se cria aquele controlezinho, né? Usando o circuito combinacional, né? Escreva em Verilog, tá? Em Verilog, isso aqui são os controles, ForwardA, ForwardB, certo? Os nossos dois casos de hazards. Então, se a instrução anterior escreve no registrador zero, certo? Quer dizer, se a instrução seguinte, a instrução anterior, escreve no registrador zero, eu não posso fazer o forwarding. Por quê? O que que aconteceria aqui, ó? Isso aqui, ó. `ADD x0, xT1, xT2`. `ADD xT3, x0, xT4`. Se eu não tivesse essa linha aqui, o que que iria acontecer? Qual o valor de `xT3`? Qual seria o valor de `xT3`? Vamos ver se vocês entenderam bem o pipeline. Tem essas duas linhas. `RS1`, `RS2`, é igual ao RD anterior? É. Então, eu vou fazer o forwarding, certo? Eu vou pegar o resultado da soma de `xT1` mais `xT2`, que está lá na saída da ULA, e vou fazer o forwarding para cá. Logo, qual vai ser o valor de `xT3`? Isso, `xT4` mais `xT1` mais `xT2`. É isso que eu queria? Não, né? Então, nunca se faz forwarding, tá? Quando o registrador de destino da instrução anterior for zero, tá? Porque a gente não escreve no zero. A gente faz o cálculo do valor intermediário, provavelmente vai dar diferente de zero. Mas é culpa de quem escreve no zero. É, culpa de quem escreve no zero, tá? Vai acontecer isso aqui. Certo? Então, aqui os nossos, como se faz isso em Verilog. Ok.\n\nEntão, outro hazard, né? Outro hazard que a gente viu que não é hazard de dados, é o hazard de controle, né? Que acontece nos desvios condicionais e incondicionais. Então, como que nós vamos fazer, então, o nosso controle do `xT3`? Certo? Controle do `xT3`. Bom, como que eu tenho essa sequência de instruções? Branch, `xT1`, `x0`, etc e tal, tá? Se eu estou prevendo o desvio como não tomado, qual é a instrução, qual é o endereço dessa instrução aqui? Esse aqui é o Branch. Esse aqui é o `Branch + 4`. Certo? O endereço da instrução que vai ter aqui é `Branch + 8`. A instrução que é aqui, `Branch + offset`. Certo? Então, se eu prever o Branch não tomado, essas instruções aqui vão estar sendo lidas. Por quê? Em que estágio a gente está avaliando o Branch? Aqui. Ah, vamos pegar um outro. É, em que estágio nós estamos avaliando se o Branch deve ser tomado ou não? A gente está usando aqui. É aqui que eu vou avaliar se o Branch deve ser tomado ou não, no estágio EX. Certo? Porque é aqui que a saída dessa porta AND, então é que vai me dizer como que eu devo controlar esse `ALUSrcA`. Entendeu? Então está sendo o Branch está sendo previsto no primeiro, segundo, terceiro, no quarto ciclo. Não é a instrução, não está colocando aqui. Então se está prevendo aqui o Branch, significa até o Branch verificar se foi verdadeiro ou falso. Já carregou uma, duas, três instruções. Certo? Porque é aqui que o Branch vai dizer verdadeiro ou falso o Branch. Certo? Para ele mandar para o endereço correto. Ele já colocou três instruções no pipeline. Certo? Então com isso eu teria que dar flush nessas três instruções aqui. Certo? Transformar essas três instruções em bolhas para então nesse próximo estágio eu saber qual é o endereço que eu devo realmente ir para que o PC vai ser atualizado. Entendeu? Porque aqui pode ser qualquer. Se foi o Branch que foi tomado, então ele foi lá no endereço 72. Claro que aqui eu preciso marcar três bolhas. Três bolhas. A gente já viu isso na aula passada também. Então qual seria um jeito de melhorar isso aqui? Então a gente pode otimizar isso para usar. Vamos ver. Verificar uma coisinha aqui. Como que eu posso melhorar isso? Bom, eu preciso que essa AND esteja nesse estágio. Eu não posso botar essa AND nesse estágio aqui. Eu já não tenho o comando de Branch e o zero disponível nesse estágio. Que conclusões precipitadas! Então eu posso adiantar a avaliação do Branch para cá, de maneira simples. É só pegar essa porta AND e botar. Porque eu tenho esse estágio e o Branch também está aqui. Tranquilo? Tranquilo pessoal? Entenderam isso? Ok, então com isso eu vou reduzindo o número de bolhas. Agora eu só preciso descartar dois. Se o Branch for avaliado no primeiro, segundo, terceiro estágio. Bom, será que eu não posso adiantar mais ainda o Branch? Quer dizer, fazer ele ser avaliado aqui, porque é aqui que eu já tenho o valor dos registradores do Branch. Basta comparar se esses dois registradores são iguais ou não. Certo? Então a forma que a gente vai resolver isso do Branch é isso aqui. Então o que nós temos que fazer para o Branch ser avaliado aqui? Eu vou precisar botar um comparador aqui e vai comparar o `RS1` com o `RS2`. Certo? E a saída desse comparador vai controlar qual é esse multiplexador aqui. Qual é o endereço que eu tenho que colocar aqui. Vai ser `PC + 4` ou se vai ser o endereço do Branch. Só que agora o endereço do Branch tem que ser calculado aqui também. Que é o PC que está aqui mais o imediato deslocado em 1 bit. Certo? Então aqui está o gerador imediato. Basta eu pegar o imediato deslocado em 1 bit e somar ao PC, que eu tenho o endereço que o Branch deve ir se ele for tomado. Certo? Então notem que o que a gente fez foi adiantar. Adiantar. Esse endereço que não precisa mais. Mas esse aqui, que é o cálculo do endereço do Branch, tem que ser adiantado para cá. Como o imediato é calculado aqui, não tem problema. Eu posso adiantar isso aqui para cá. Certo? E colocar aqui um comparador. Um circuito a mais que faz a comparação de dois registradores de 32 bits. Porque aqui eu já tenho o `RS1` e o `RS2`. Então, com isso o Branch vai ser avaliado em um circuito. Se eu considerar que eu estou prevendo o desvio como não tomado, aqui eu já estou lendo a instrução `PC + 4`. Porque a instrução PC é do Branch. A instrução `PC + 4` é essa aqui. Certo? Se por acaso o Branch errou, o que eu tenho que fazer? Não deixar, quer dizer, invalidar essa instrução que está aqui e dar um flush nela. Certo? Quer dizer, inserir uma bolha. Essa instrução toda que está aqui, já está pronta. Eu preciso que ela vire uma bolha. Certo? Certo, pessoal? Não pude olhar para a cara de vocês. Ainda bem que essa aula vai ser presencial, daí eu vou poder ver as caras de ponto de interrogação de todo mundo, como se fazia antes. Eu quero conhecer todos vocês. Então, o que a gente fez aqui? A gente fez o Branch. Se eu passar isso aqui para cá, eu faço o Branch ser avaliado na terceira etapa. Se eu pegar isso aqui e botar para cá, colocar aqui um comparador, eu posso fazer o Branch ser avaliado na segunda etapa. E sendo avaliado na segunda etapa, se eu estou prevendo como não tomado, estou lendo aqui a instrução `PC + 4`. Se o Branch me disser: \"Olha, o Branch deu verdadeiro\", eu tenho que transformar essa instrução em bolha e buscar novamente a instrução no endereço que foi calculado. Opa. No endereço que foi calculado aqui. Certo? Então agora eu vou ter que transformar essa instrução numa bolha. Como é que eu transformo essa instrução numa bolha? Uma instrução que não faça nada. Notem que o controle não é só gerar o controle, porque o controle está aqui. Eu tenho que transformar essa instrução aqui numa bolha. Quer dizer, aquilo que eu li da memória, eu quero que seja uma bolha. Opa, vamos lá. Eu quero que aquilo que eu li da memória se transforme numa bolha. Certo? Quer dizer, aqui tem que aparecer uma bolha. Como é que é o NOP? A instrução NOP é tudo zero? A instrução NOP significa tudo zero? Não. `ADDI x0, x0, 0`. Na realidade, o último `x0` ali é zero. `ADDI x0, x0, 0`. Esse é o que o que o hazard utiliza. Então eu vou ter que transformar a instrução que está aqui nessa instrução `ADDI x0, x0, 0`. Como que eu faço isso? Ao invés de escrever isso aqui, eu vou escrever os bits daquela instrução `ADDI x0, x0, 0`. Com isso eu transformei essa instrução numa bolha. Certo? E as coisas podem seguir normalmente. Certo? E daí no próximo PC, vai buscar o endereço correto. Entendeu? Então aí só quando a gente erra acontece isso. E aí a gente erra. E aí a gente erra. Quando a gente acerta, não. Pode passar direto. Se fosse a instrução aqui. Se essa instrução aqui, essa instrução fosse `SUB X1, X4, X8`. Se essa instrução aqui ao invés de ser `X10` fosse `X1`. O que aconteceria? Parem e pensem. O que aconteceria se fosse `X1`? Vamos lá. O que não está usando `X1` aqui para fazer a comparação? Não é o Branch de `X1` com `X3`? Então não tem o hazard do Branch para o SUB. Se aqui for `X1`. Então o que tem que acontecer? Esse comparador aqui não pode pegar o `X1` que está dentro do banco de registradores, porque está errado. Porque o que deve comparar com essa subtração? Certo? Onde é que está o registro dessa subtração? Está aqui. Certo? Aqui. Daí posso dar um forward daqui para cá. Assim como eu posso dar um forward daqui para cá. Certo? Então se houver esse hazard, eu vou precisar de unidades de forwarding aqui no Branch. Então a unidade de forwarding seria um multiplexador. Só que aqui no Branch agora. Certo? Que eu posso dar um forward daqui para cá ou daqui para cá. Certo, pessoal? Então aqui, aconteceria que aqui eu teria que ter uma unidadezinha de forwarding. E aqui também. Se aqui fosse `X1`. Entendido isso? Por que eu tenho que dar um forward no Branch? Ok. Esse valor aqui que eu preciso comparar aqui para dar certo, porque ele não prevê o futuro. É que o valor de `X1` só vai ser gravado no banco de registradores aqui. Então, aqui o `X1` está errado. Certo? Porque... Por que isso aqui? Ah sim. Daí. Então, o que que acontece com isso aqui? O Branch errou. Então o Branch segue. SUB segue. Acontece um bubble. Quer dizer, uma bolha aqui. Porque a gente colocou isso aqui no `ADDI x0, x0, 0`. Opa. E aqui continuando a próxima instrução. Quer dizer, lá do endereço do Branch, que seria esse LOAD aqui. E aqui continuando a próxima instrução. Quer dizer, lá do endereço do Branch, que seria esse LOAD aqui. Certo? Entendido isso? Beleza. Se fosse um JAL, o que aconteceria? Se ao invés de um Branch fosse um JAL. Tudo acaba em explosão. Então aqui ele vai ler o JAL. Aqui ele vai decodificar o JAL. E aqui ele já vai estar lendo a instrução seguinte ao JAL. Certo? Então, a menos que o programador seja muito bom e faça coisas do tipo JAL. Eu vou ter umas três provas junto com a sua. Pois é. Esse semestre ficou muito ruim. Ficou. Ficou bem curto esse semestre. E o próximo vai ser encurtado também, mas presencial. Que aí acho que vai ser pior ainda. Vocês vão ter que se deslocar até a UnB. Pegar chuva. Só se tem uma possibilidade. A Amy falou que talvez os professores vão ver na cara dos alunos que eles estão sofrendo. Aí vai diminuir um pouco. Ah não, isso sempre acontece. Por isso que o remoto é ruim. Eu não vejo a cara de ponto de interrogação. Vocês façam as mesmas coisas. Tem aqui uma reaçãozinha que você pode fazer. Se tu olhar meu nome. Olha lá. Eu vou parar a gravação aqui, pessoal. Então parei a gravação.",
        "video_source": "OAC_2022-04-11.mp4"
    },
    {
        "id": 10,
        "timestamp_start": 6827.16,
        "timestamp_end": 6827.52,
        "slide_description": "Como Engenheiro de Computação Sênior, realizei a análise do slide da aula de Arquitetura de Computadores. A seguir, detalho o conteúdo visual para um sistema de busca semântica (RAG):\n\nO slide é de uma aula da **Universidade de Brasília** (UnB), da disciplina **CIC0099 - Organização e Arquitetura de Computadores**, ministrada pelo **Prof. Marcus Vinícius Lamar**. O título principal da aula é \"**Hazard de Controle**\", com um subtítulo que especifica o contexto: \"**Hardware otimizado para 1 bolha**\". Este tema indica a discussão de técnicas de pipeline para mitigar hazards, especificamente de controle, com a introdução de uma \"bolha\" (nop de um ciclo) para resolvê-los.\n\nA seção superior do slide apresenta uma sequência de instruções que exemplifica um cenário de pipeline:\n1.  `and x12, x2, x5`\n2.  `beq x1, x3, 16`\n3.  `sub x1, x4, x8` (A instrução `sub` aparece com um `x1` riscado em vermelho, sugerindo uma possível dependência ou resultado de uma bolha/forwarding, ou uma instrução que seria afetada por um hazard).\n4.  `before<1>`\n5.  `before<2>`\nAbaixo dessa sequência, há uma anotação parcial: `Obs: nop/32b0`, que pode se referir a uma instrução `nop` ou um valor hexadecimal `32b0`.\n\nA parte inferior do slide exibe um **diagrama de datapath de um processador MIPS pipeline**, focado na resolução de hazards, especialmente os de controle e dados. O diagrama mostra as interconexões entre as unidades funcionais e os registradores de pipeline, embora as fases (IF, ID, EX, MEM, WB) não estejam todas explicitamente rotuladas nas divisões verticais pontilhadas, exceto por uma indicação clara de `MEM/WB`.\n\nComponentes e fluxo de dados visíveis no datapath:\n*   **Program Counter (PC):** Alimentando a `instruction memory` e sendo atualizado por um somador `PC + 4`.\n*   **Instruction Memory:** Onde as instruções são buscadas.\n*   **Register File:** Implícito pelas entradas e saídas de leitura e escrita de registradores.\n*   **ALU (Arithmetic Logic Unit):** Implícita pelas operações de dados.\n*   **Data Memory:** Representando a fase de acesso à memória (`MEM`).\n*   **Multiplexadores (MUX):** Diversos multiplexadores são visíveis, controlando a seleção de dados em várias etapas do pipeline, por exemplo, para a escrita no `Register File` ou para as entradas da ALU.\n*   **Forwarding Unit:** Claramente identificada, esta unidade é crucial para a resolução de **hazards de dados** (data hazards) através do encaminhamento (forwarding). Ela recebe sinais das etapas posteriores do pipeline (registros de pipeline `EX/MEM` e `MEM/WB` são fontes típicas de dados a serem encaminhados) e gera sinais de controle para os multiplexadores nas entradas da ALU.\n*   **Hazard Detection Unit:** Não está explicitamente rotulada, mas a presença da `Forwarding Unit` e o tópico da aula (`Hazard de Controle`) indicam que uma unidade de detecção de hazards (data e/ou controle) estaria presente e interagiria com estas.\n*   **Branch Target Address Calculation:** Há um caminho para o cálculo do endereço de salto, envolvendo um `Shift left 2` e um somador para `PC + 4` e o offset do branch.\n*   **Registradores de Pipeline:** Representados por barras verticais que armazenam o estado entre as fases do pipeline. Um exemplo é a conexão do `Data memory` a um multiplexador antes da etapa `MEM/WB`.\n*   **Sinais de Controle:** Entradas para multiplexadores e para unidades como `Reg Write` (escrita de registrador) são visíveis, indicando o controle microarquitetural.\n*   **Clock 3:** Marcado no canto inferior esquerdo, possivelmente indicando um ponto de observação ou um ciclo específico na execução pipeline.\n\nNa parte inferior do slide, uma questão instiga a análise de um cenário específico: \"**Como ficaria se fosse sub x1,x4,x8 ? Forward beq**\". Esta pergunta solicita a análise de um caso de hazard envolvendo a instrução `sub` (possivelmente data hazard ou dependência) e o comportamento do encaminhamento (forwarding) para uma instrução `beq` (branch equal), o que tipicamente levanta questões de hazard de controle e como o pipeline lida com a decisão de salto.\n\nEm resumo, o slide aborda a microarquitetura de pipelines, focando em \"Hazard de Controle\" e a otimização de hardware usando uma \"bolha\" para resolução de hazards, com um diagrama detalhado de datapath que inclui uma unidade de encaminhamento, ilustrando a complexidade e as soluções para manter a eficiência do pipeline em face de dependências de dados e controle.",
        "transcription": "Não, olha",
        "video_source": "OAC_2022-04-11.mp4"
    },
    {
        "id": 11,
        "timestamp_start": 6827.52,
        "timestamp_end": 6843.02,
        "slide_description": "Como um Engenheiro de Computação Sênior, analiso o slide e o conteúdo anotado da aula de Arquitetura de Computadores.\n\n**Conteúdo Textual Transcrito:**\n\n*   **Título Principal do Slide:** Hazard de Controle\n*   **Subtítulo/Tópico:** Hardware otimizado para 1 bolha\n*   **Instruções de Exemplo (Assembly/Pseudo-Assembly) Acima do Diagrama:**\n    *   `and x12, x2, x5`\n    *   `beq x1, x3, 16`\n    *   `sub x1, x4, x8`\n    *   `before<1>`\n    *   `before<2>`\n*   **Anotações e Observações Contextuais:**\n    *   Abaixo de `and x12, x2, x5`: `Obs.: nop<32'b0`\n    *   Abaixo de `Obs.: nop<32'b0`: `IF Flush`\n    *   Abaixo de `beq x1, x3, 16`: `Clock 3`\n*   **Pergunta/Discussão no Rodapé do Slide:** `Como ficaria se fosse sub x1,x4,x8 ? Forward beq`\n*   **Informações de Cabeçalho do Slide (Institucionais):**\n    *   `UnB – CIC0099 – Organização e Arquitetura de Computadores`\n    *   `Universidade de Brasília`\n    *   `Departamento de Ciência da Computação`\n    *   `CIC0099 - Organização e Arquitetura de Computadores`\n    *   `Prof. Marcus Vinícius Lamar`\n*   **Componentes do Diagrama (Texto Interno):**\n    *   `Hazard detection unit`\n    *   `Control`\n    *   `IF/ID` (Registrador de Pipeline)\n    *   `ID/EX` (Registrador de Pipeline)\n    *   `EX/MEM` (Registrador de Pipeline)\n    *   `MEM/WB` (Registrador de Pipeline)\n    *   `Instruction memory`\n    *   `Registers`\n    *   `Imm Gen` (Immediate Generator)\n    *   `ALU`\n    *   `Data memory`\n    *   `Forwarding unit`\n\n**Descrição do Diagrama (Datapath Pipelined com Resolução de Hazards):**\n\nO diagrama representa um datapath de um processador pipelined com cinco estágios clássicos: Instruction Fetch (IF), Instruction Decode/Register File Read (ID), Execute (EX), Memory Access (MEM) e Write Back (WB). Ele é projetado para demonstrar a detecção e resolução de hazards, tanto de controle quanto de dados, através de unidades de detecção de hazard e de encaminhamento (forwarding).\n\n**Estrutura e Fluxo de Dados:**\n\n1.  **Estágio IF (Instruction Fetch):**\n    *   O **Program Counter (PC)** armazena o endereço da instrução atual.\n    *   Um multiplexador (Mux) permite a seleção do próximo valor do PC, que pode ser o endereço sequencial `PC+4` ou um endereço de desvio/salto calculado (e.g., `x 72` como saída de um Mux com `44` e `4` como outras entradas/relacionadas ao cálculo de endereço).\n    *   A instrução é buscada na **Instruction memory**.\n    *   O PC incrementado (`PC+4`) e a instrução buscada são passados para o registrador de pipeline **IF/ID**.\n\n2.  **Estágio ID (Instruction Decode / Register File Read):**\n    *   O registrador **IF/ID** fornece a instrução e `PC+4`.\n    *   A unidade **Control** decodifica a instrução e gera todos os sinais de controle necessários para os demais estágios.\n    *   A unidade **Registers** (Banco de Registradores) lê os valores dos registradores de origem especificados na instrução (por exemplo, `x1`, `x3` para `beq`).\n    *   A unidade **Imm Gen** (Immediate Generator) estende o valor imediato da instrução.\n    *   A **Hazard detection unit** monitora os registradores de leitura (ID) e escrita (futura, via `ID/EX`). Ela é crucial para detectar hazards de controle (como `beq`). Se um hazard de controle for detectado e o desvio for tomado, ela pode sinalizar para o estágio IF para inserir uma \"bolha\" (`nop<32'b0`) no pipeline, indicado pela anotação `IF Flush`, parando a busca de novas instruções por um ciclo para limpar o pipeline.\n    *   Os operandos lidos, o valor imediato estendido, o PC incrementado e os sinais de controle são passados para o registrador **ID/EX**.\n\n3.  **Estágio EX (Execute):**\n    *   O registrador **ID/EX** fornece os dados e sinais de controle.\n    *   A **ALU** (Arithmetic Logic Unit) realiza a operação principal da instrução (aritmética, lógica, cálculo de endereço).\n    *   Duas multiplexadores controlam as entradas da ALU, permitindo que a **Forwarding unit** direcione dados de estágios posteriores (`EX/MEM` ou `MEM/WB`) para as entradas da ALU, resolvendo hazards de dados (RAW - Read After Write).\n    *   O cálculo do endereço de desvio para instruções `beq` também ocorre neste estágio, usando o resultado da ALU e o imediato estendido.\n    *   O resultado da ALU, o valor do segundo operando (para stores) e os sinais de controle relevantes são passados para o registrador **EX/MEM**.\n\n4.  **Estágio MEM (Memory Access):**\n    *   O registrador **EX/MEM** fornece o endereço de memória e, se for uma operação de store, o dado a ser escrito.\n    *   A **Data memory** realiza operações de leitura ou escrita conforme os sinais de controle.\n    *   O dado lido da memória (em caso de load) ou o resultado da ALU (para operações R-type ou endereço para store) é passado para o registrador **MEM/WB**.\n\n5.  **Estágio WB (Write Back):**\n    *   O registrador **MEM/WB** contém o dado a ser escrito de volta no banco de registradores e o identificador do registrador de destino.\n    *   Um multiplexador final seleciona entre o dado lido da **Data memory** ou o resultado da ALU para ser escrito de volta na unidade **Registers**.\n\n**Mecanismos de Resolução de Hazards:**\n\n*   **Hazard Detection Unit:** Conectada aos estágios IF e ID/EX. Detecta principalmente hazards de controle (e.g., branches) e decide se o pipeline deve ser paralisado ou se NOPs (`nop<32'b0`) devem ser inseridos (`IF Flush`) para evitar a busca e decodificação de instruções incorretas enquanto o resultado do branch é determinado.\n*   **Forwarding Unit:** Conectada aos estágios EX, MEM e WB. Ela compara os registradores de leitura das instruções no estágio EX com os registradores de escrita das instruções nos estágios MEM e WB. Se uma instrução no estágio EX precisa de um dado que está sendo produzido por uma instrução anterior nos estágios MEM ou WB, a unidade de encaminhamento direciona esse dado (o \"resultado\" mais recente) diretamente para as entradas da ALU, evitando um stall e mantendo o pipeline cheio.\n\n**Cenário Ilustrado:**\n\nA sequência `and x12, x2, x5`, `beq x1, x3, 16`, `sub x1, x4, x8` é usada para exemplificar.\n*   A instrução `beq x1, x3, 16` é um branch condicional que lê os registradores `x1` e `x3`.\n*   A instrução `sub x1, x4, x8` é uma instrução que escreve no registrador `x1`.\n*   A anotação `Clock 3` e a pergunta \"Como ficaria se fosse sub x1,x4,x8 ? Forward beq\" sugerem uma análise de como o `beq` lida com uma possível dependência de dados de `x1` (se `sub` estivesse à frente no pipeline e `beq` precisasse do novo valor de `x1`) e, crucialmente, o \"Forward beq\" refere-se ao encaminhamento dos *operandos* para a `beq`, não ao seu próprio resultado, uma vez que `beq` não produz um valor para um registrador de propósito geral.\n*   Se o `beq` determinar que o desvio deve ser tomado (por exemplo, no `Clock 3`), a `Hazard detection unit` acionaria o `IF Flush`, inserindo um `nop` no pipeline (indicado por `nop<32'b0`) para as instruções que seriam buscadas em seguida, evitando a execução especulativa de instruções erradas.",
        "transcription": "Parei a gravação ali. Não, agora eu tô vendo. Mas parei a gravação. Ih, não parei do outro lado, espera. Então, ficou gravado o vídeo. Que eu disponibilizo isso aí. Eu sou um arrasado. Agora é... Hã? Se tiver...",
        "video_source": "OAC_2022-04-11.mp4"
    },
    {
        "id": 12,
        "timestamp_start": 6843.02,
        "timestamp_end": 6844.62,
        "slide_description": "Como um Engenheiro de Computação Sênior, analiso o slide e o conteúdo anotado, focando na extração de informações para um sistema de busca semântica (RAG).\n\n---\n\n**1. Transcrição de Texto:**\n\n**Cabeçalho da Apresentação:**\n*   \"UnB - CIC0099 - Organização e Arquitetura de Computadores\"\n*   \"Universidade de Brasília\"\n*   \"Departamento de Ciência da Computação\"\n*   \"Prof. Marcus Vinicius Lamar\"\n\n**Título do Slide:**\n*   \"Hazard de Controle\"\n*   \"Hardware otimizado para 1 bolha\"\n\n**Instruções de Exemplo (Acima do Diagrama):**\n*   \"and x12, x2, x5\"\n*   \"beq x1, x3, 16\"\n*   \"sub x1, x4, x8\"\n*   \"before<1>\"\n*   \"before<2>\"\n\n**Anotação/Observação:**\n*   \"Obs.: nop/32'b0\"\n*   \"IF Flush\" (com seta apontando para a unidade de detecção de hazard)\n\n**Texto Inferior:**\n*   \"Clock 3\"\n*   \"Como ficaria se fosse sub x1,x4,x8 ? Forward beq\"\n\n**Anotações no Diagrama:**\n*   \"Hazard detection unit\"\n*   \"Control\"\n*   \"Instruction memory\"\n*   \"Registers\"\n*   \"Imme Gen\" (Immediate Generator)\n*   \"ALU\" (Arithmetic Logic Unit)\n*   \"Data memory\"\n*   \"Forwarding unit\"\n*   Rótulos de estágios do pipeline: \"IF/ID\", \"ID/EX\", \"EX/MEM\", \"MEM/WB\"\n*   Pequenos rótulos como \"MUX\", \"PC\", \"Shift left 2\".\n*   Valores numéricos de bits e offsets: \"4\", \"48\", \"44\", \"72\", \"32\", \"0\", \"16\", \"10\".\n\n---\n\n**2. Descrição do Diagrama (Datapath de Pipeline):**\n\nO diagrama apresenta um datapath de pipeline de cinco estágios, tipicamente encontrado em arquiteturas RISC (como MIPS ou RISC-V), com aprimoramentos para lidar com hazards de controle e de dados. Os estágios são delimitados por registradores de pipeline (barras cinzas verticais) e são rotulados como **IF/ID** (Instruction Fetch/Decode), **ID/EX** (Instruction Decode/Execute), **EX/MEM** (Execute/Memory), e **MEM/WB** (Memory/Write Back).\n\n**Estrutura e Fluxo de Dados:**\n\n1.  **Estágio IF (Instruction Fetch - Busca de Instrução):**\n    *   Um Program Counter (PC) (implícito) fornece o endereço à **Instruction Memory**.\n    *   Um somador incrementa o PC em 4 (PC+4) para buscar a próxima instrução sequencial.\n    *   Um Multiplexador (MUX) seleciona o próximo valor do PC, que pode ser PC+4 ou um endereço de desvio (calculado por \"Imme Gen\" e \"Shift left 2\").\n    *   A **Instruction Memory** busca instruções de 32 bits.\n    *   O registrador de pipeline **IF/ID** armazena a instrução buscada e o PC+4 para o próximo estágio.\n\n2.  **Estágio ID (Instruction Decode - Decodificação de Instrução):**\n    *   A instrução do registrador IF/ID é decodificada pela **Control Unit** e utilizada para ler o **Register File**.\n    *   O **Register File** lê os valores de dois registradores fonte (rs1 e rs2 da instrução).\n    *   A unidade **Imme Gen** gera e estende valores imediatos da instrução (ex: offset de branch).\n    *   A **Control Unit** gera sinais de controle para todos os estágios subsequentes, baseados no opcode da instrução. Ela interage com a **Hazard detection unit**.\n    *   A **Hazard detection unit** recebe informações da instrução atual (registradores fonte) e de estágios posteriores (registradores de destino e habilitação de escrita). Ela é crucial para a detecção de hazards de controle, gerando o sinal \"IF Flush\".\n    *   O registrador de pipeline **ID/EX** armazena valores de registradores lidos, o valor imediato, e os sinais de controle para o estágio EX.\n\n3.  **Estágio EX (Execute - Execução):**\n    *   A **ALU (Arithmetic Logic Unit)** realiza operações aritméticas e lógicas, além de cálculos de endereço para memória e avaliação de condições de branch.\n    *   Dois MUXes na entrada da ALU selecionam os operandos. Estes MUXes são controlados pela **Forwarding unit** para resolver hazards de dados, permitindo que os operandos venham do registrador ID/EX ou sejam encaminhados de estágios posteriores (EX/MEM ou MEM/WB).\n    *   A instrução `beq x1, x3, 16` estaria neste estágio, com `x1` e `x3` sendo comparados pela ALU.\n    *   A **Forwarding unit** monitora os registradores de destino das instruções nos estágios EX/MEM e MEM/WB, comparando-os com os registradores fonte da instrução no estágio ID/EX. Se uma dependência de dados (RAW hazard) for detectada, ela ativa os MUXes de encaminhamento.\n    *   O registrador de pipeline **EX/MEM** armazena o resultado da ALU, os dados a serem escritos na memória, e sinais de controle para o estágio MEM.\n\n4.  **Estágio MEM (Memory Access - Acesso à Memória):**\n    *   A **Data Memory** realiza operações de leitura (load) ou escrita (store) usando o resultado da ALU como endereço, controlado pelos sinais.\n    *   O registrador de pipeline **MEM/WB** armazena os dados lidos da memória (para loads), o resultado da ALU (para R-type), e sinais de controle para o estágio WB.\n\n5.  **Estágio WB (Write Back - Escrita de Volta):**\n    *   Um MUX seleciona os dados a serem escritos de volta no **Register File**: ou o resultado da ALU (vindo de EX/MEM) ou os dados lidos da memória (vindos de MEM/WB).\n    *   O **Register File** escreve o resultado final no registrador de destino.\n\n**Mecanismos de Hazard e Otimização:**\n\n*   **Hazard de Controle:** A frase \"Hazard de Controle\" e \"Hardware otimizado para 1 bolha\" indica que o foco principal é a penalidade de branch. Para uma instrução de branch como `beq x1, x3, 16`, se o branch é tomado, a instrução sequencialmente seguinte (`sub x1, x4, x8` neste exemplo) que foi previamente buscada precisa ser descartada.\n*   **\"IF Flush\":** O sinal \"IF Flush\", originado da **Hazard detection unit** e direcionado ao registrador de pipeline IF/ID, é responsável por invalidar a instrução buscada, efetivamente inserindo uma instrução NOP (bolha) no pipeline. Isso resulta em uma penalidade de 1 ciclo (\"1 bolha\") quando um branch é tomado, pois o pipeline é \"limpo\" e a instrução correta (do endereço alvo do branch) é buscada.\n*   **Forwarding (Encaminhamento):** A **Forwarding unit** e os MUXes de entrada da ALU resolvem hazards de dados (RAW - Read After Write) ao encaminhar resultados intermediários de estágios posteriores (EX, MEM) diretamente para as entradas da ALU do estágio EX, evitando stalls desnecessários.\n\n**Exemplo de Fluxo de Instruções no \"Clock 3\":**\n*   `and x12, x2, x5` está no estágio MEM (ou finalizando EX/MEM).\n*   `beq x1, x3, 16` está no estágio EX, onde a condição de branch é avaliada.\n*   `sub x1, x4, x8` está no estágio ID, sendo decodificada.\n\nA questão \"Como ficaria se fosse sub x1,x4,x8 ? Forward beq\" propõe um cenário hipotético de um hazard de dados (RAW) onde a instrução `beq` dependeria do registrador `x1` escrito pela instrução `sub` se `sub` viesse imediatamente antes de `beq` na ordem do programa. Isso exige que a `Forwarding unit` atue, encaminhando o valor de `x1` (produzido por `sub`) para a `beq` no estágio EX. Esta pergunta serve para ilustrar a interação entre a resolução de hazards de dados (via forwarding) e a resolução de hazards de controle (via flush/stalls).",
        "transcription": "UnB - CIC0099 - Organização e Arquitetura de Computadores\nUniversidade de Brasília\nDepartamento de Ciência da Computação\nProf. Marcus Vinicius Lamar\n\nHazard de Controle\nHardware otimizado para 1 bolha\n\nand x12, x2, x5\nbeq x1, x3, 16\nsub x1, x4, x8\nbefore<1>\nbefore<2>\n\nObs.: nop/32'b0\nIF Flush\n\nClock 3\nComo ficaria se fosse sub x1, x4, x8? Forwarding para beq?",
        "video_source": "OAC_2022-04-11.mp4"
    }
]