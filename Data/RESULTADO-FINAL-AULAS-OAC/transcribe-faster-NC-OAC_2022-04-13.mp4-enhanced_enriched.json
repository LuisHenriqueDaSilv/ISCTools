[
    {
        "id": 1,
        "timestamp_start": 3.25,
        "timestamp_end": 43.94,
        "slide_description": "O conteúdo visual analisado provém de uma tela de aula online, provavelmente de um curso de Arquitetura de Computadores (OAC - Organização e Arquitetura de Computadores), da Universidade de Brasília (CIC0099). O slide principal é um documento em formato Word, intitulado \"OAC_A_Plano_2021-2_v0.docx\", que apresenta o plano de ensino da disciplina.\n\n**Conteúdo Textual do Plano de Ensino:**\n\nO documento exibe uma tabela detalhando o cronograma e tópicos, com as seguintes entradas visíveis:\n\n*   **Coluna de Data (Duas subcolunas):**\n    *   Linha 8: 14/3 | 16/3\n    *   Linha 9: 21/3 | 23/3\n    *   Linha 10: 28/3 | 30/3\n    *   Linha 11: 4/4 | 6/4\n    *   Linha 12: 11/4 | 13/4\n    *   Linha 13: 18/4 | 20/4\n    *   Linha 14: 25/4 | 27/4\n    *   Linha 15: 2/5 | 4/5\n\n*   **Coluna de Tópicos/Atividades (Esquerda):**\n    *   Linha 8: 1ª Prova (P1)\n    *   Linha 9: 13) Processador Uniciclo: Unidade de Controle (C.4) (L1)\n    *   Linha 10: 14) Processador Multiciclo: Unidade Operativa (C.4)\n    *   Linha 11: Lab 4: Processador Multiciclo\n    *   Linha 12: 17) Pipeline: Unidade Operativa e Controle (C.4)\n    *   Linha 13: 18) Exceção e Interrupção (C.4)\n    *   Linha 14: 19.1) Memória: Cache (C.5)\n    *   Linha 15: Prova Substitutiva\n\n*   **Coluna de Tópicos/Atividades (Direita):**\n    *   Linha 8: 12) Processador Uniciclo: Unidade Operativa (C.4) (T8)\n    *   Linha 9: Lab 3: Processador Uniciclo(T9) (L2)\n    *   Linha 10: 15) Processador Multiciclo: Unidade de Controle (C.4) (T10)\n    *   Linha 11: 16) Processador Pipeline: Conceitos (C.4) (T11)\n    *   Linha 12: Lab 5: Processador Pipeline(T12) (L3)\n    *   Linha 13: 19) Memória: Hierarquia (C.5) (T13) (L4)\n    *   Linha 14: 2ª Prova (P2) (T14) (L5)\n    *   Linha 15: Apresentação dos Projetos (PR) (T15)\n\nAs referências \"C.4\" e \"C.5\" indicam capítulos de um livro-texto, provavelmente de Patterson & Hennessy. \"T\" e \"L\" seguidos de números provavelmente denotam sessões teóricas (T) e laboratórios (L), respectivamente.\n\n**Seção de Avaliação (Inferior do documento):**\n\n*   **Avaliação:**\n    *   P1: 1ª Prova: 14/03/2022\n    *   P2: 2ª Prova: 27/04/2022\n    *   Prova Substitutiva: 02/05/2022\n    *   É optativa e pode substituir qualquer uma das notas\n    *   Média dos Testes Semanais (parcialmente visível)\n    *   M - 1 (T15 L) (parcialmente visível, provavelmente parte de uma fórmula de cálculo de média final).\n\n**Conteúdo da Interface de Comunicação (Bate-papo público):**\n\n*   **Mensagens Gerais:**\n    *   \"Bem vindos à sala de aula de OAC!\"\n    *   \"Esta sessão está sendo gravada.\"\n    *   \"Para mais informações, clique aqui.\"\n    *   \"Novo na plataforma? Experimente o tour!\"\n*   **Interações de Alunos:**\n    *   \"Eduarda Costa de Men... 13:58 boa tarde\"\n    *   \"Harisson Freitas Magal... 13:58 Boa tarde\"\n\n**Professor:**\n\nUm professor, homem, com óculos e barba, está visível no canto inferior direito da tela, aparentemente observando o conteúdo compartilhado ou interagindo com a plataforma.\n\n**Ausência de Diagramas Explícitos:**\n\nEmbora o cronograma aborde temas como \"Processador Uniciclo\", \"Processador Multiciclo\", \"Pipeline\", \"Memória: Hierarquia\" e \"Memória: Cache\", que tipicamente envolveriam diagramas de datapath, pipeline ou hierarquia de memória para ilustrar suas estruturas e fluxo de dados, o slide atual é estritamente textual e não contém representações gráficas desses componentes. Os tópicos listados são descrições conceituais e de laboratório que antecedem ou acompanham a apresentação desses diagramas em aulas subsequentes.",
        "transcription": "Beleza, então, boa tarde, vamos lá para mais uma aula de OAC. Hoje é dia 13 de abril, então é para fazer nosso laboratório 5 de Pipeline. Hoje é para entregar o laboratório 3. Estamos prontos para isso, né? Falta só o videozinho para o nosso. Ótimo, tá chatinho. Beleza, só que ficou uma pequena parte da aula anterior que a gente não viu, que foi justamente a comparação entre o Uniciclo, o Multiciclo e o Pipeline.",
        "video_source": "OAC_2022-04-13.mp4"
    },
    {
        "id": 2,
        "timestamp_start": 43.94,
        "timestamp_end": 1384.73,
        "slide_description": "Como Engenheiro de Computação Sênior, analiso o slide apresentado em uma aula de Arquitetura de Computadores para extrair seu conteúdo para um sistema de busca semântica (RAG).\n\nO slide intitula-se \"Solução\". No canto superior direito, há uma identificação da disciplina: \"UnB - CIC0099 - Organização e Arquitetura de Computadores\", com o logo e nome da instituição \"Universidade de Brasília\", \"Departamento de Ciência da Computação\" e o nome do docente, \"Prof. Marcus Vinicius Lamar\".\n\nAo lado do título \"Solução\", observa-se uma anotação manuscrita em vermelho, que transcreve a fórmula de tempo total de execução: \"TXPEC = I x CPI x T\", onde 'TXPEC' provavelmente representa o tempo de execução total, 'I' o número de instruções, 'CPI' o Cycles Per Instruction (ciclos por instrução) e 'T' o tempo de ciclo de clock (ou `Tc`).\n\nO slide compara a performance de três arquiteturas distintas: Uniciclo, Multiciclo e Pipeline, através de cálculos de período de clock, CPI e tempo de execução médio da instrução.\n\n1.  **Uniciclo:**\n    *   É apresentado o cálculo do período de clock como a soma dos tempos de estágios individuais: \"200+50+100+200+50 = 600ps\".\n    *   O CPI (Cycles Per Instruction) é dado como \"CPI = 1\", característico de um processador uniciclo onde cada instrução completa sua execução em um único ciclo de clock.\n    *   O tempo de execução médio da instrução é calculado como \"600x1=600ps\", o que é o produto do período de clock pelo CPI.\n\n2.  **Multiciclo:**\n    *   O período de clock para esta arquitetura é especificado como \"200ps\", sugerindo uma granularidade de tempo de ciclo menor em comparação com o uniciclo, permitindo a execução de operações menores por ciclo.\n    *   O CPI é calculado através de uma média ponderada dos ciclos consumidos por diferentes tipos de instrução: \"0.25x5 + 0.1x4 + 0.11x3 + 0.02x3 + 0.52x4 = 4.12\". Os coeficientes (0.25, 0.1, 0.11, 0.02, 0.52) provavelmente representam a frequência de cada tipo de instrução, e os multiplicadores (5, 4, 3, 3, 4) o número de ciclos que cada tipo de instrução leva para ser executada nesta arquitetura.\n    *   O tempo de execução médio da instrução é calculado como \"200x4.12=824ps\", sendo o produto do período de clock pelo CPI médio.\n\n3.  **Pipeline:**\n    *   Assim como no multiciclo, o período de clock é \"200ps\", indicando que a arquitetura pipeline pode operar com a mesma frequência de clock dos estágios mais rápidos.\n    *   O CPI é calculado novamente por uma média ponderada, mas com valores de ciclos por instrução tipicamente menores devido à sobreposição das fases de instrução: \"0.25x1.5 + 0.1x1 + 0.11x1.25 + 0.02x2 + 0.52x1 = 1.17\". Os multiplicadores (1.5, 1, 1.25, 2, 1) agora refletem o CPI efetivo considerando os *hazards* e bolhas (stalls) no pipeline, resultando em um CPI próximo de 1 (ideal para pipeline).\n    *   O tempo de execução médio da instrução é \"200x1.17=234ps\", o que é significativamente menor do que as outras duas arquiteturas, demonstrando o ganho de performance do pipeline.\n\nNão há diagramas explícitos de Datapath, Pipeline ou Hierarquia de Memória visíveis neste slide, apenas cálculos textuais e numéricos que representam a análise de desempenho dessas arquiteturas. O conteúdo foca na quantificação da performance em termos de tempo de execução e CPI.",
        "transcription": "Então, só relembrando aqui. Nós vamos dividir o Uniciclo, que vocês têm pronto, certo? É isso que eu quero que vocês tenham noção, vocês têm pronto. Então, a gente começa em cinco estágios, certo, usando esses registradores de Pipeline, certo? E assim, então, a gente viu como tudo funciona, né? A instrução começa aqui nesse estágio, no ciclo de clock seguinte, ela passa para esse, no ciclo de clock seguinte, passa para esse, no ciclo de clock seguinte, e no último aqui ele escreve os resultados, né? Então, note que esses cinco ciclos não são aquelas cinco etapas, né? Então, a gente vai fazer cinco etapas do Multiciclo, nada a ver, certo? Então, todas as instruções aqui vão ter esses cinco ciclos, mesmo que tenha alguma etapa que não faça nada, tá? Ok, daí a gente viu que o controle do Pipeline é exatamente a tabela de controle do Uniciclo, né? Só que com sinais de controle sendo aplicados em cada estágio. Então, vimos como é que se fazia o Forwarding, né? Fazia bolhas, stalls, e vamos ver, então, aqui. Então, vamos fazer uma comparação simples do Uniciclo, Multiciclo e Pipeline para a gente ver se é realmente tão eficiente assim, tá? Então, a gente sabe que para definir o período de clock, a gente tem que saber os tempos de propagação, o tempo de leitura e escrita das memórias, para cada um dos elementos, né? Para a leitura e escrita das memórias e tempo de propagação dos outros elementos, tá? Inclusive dos multiplexadores, tá, para ter o dado mais certinho possível, tá? Setup time de todos os registradores, né? Pode ser considerado, assim também aqui a gente poderia considerar o setup time, tá, de todos os registradores do Pipeline e o setup time daqueles registradores auxiliares que a gente colocou no Multiciclo, certo? Esse aí seria a análise mais certinha, poderia ser. Mas para termos uma ideia, vamos considerar só esses três ciclos aqui, quer dizer, tempo de acesso à memória, tanto para leitura, quanto para escrita, e tanto a memória de instrução, quanto a memória de dados, 200 picosegundos. Operação com a ULA, 100 picosegundos. E acesso ao banco de registradores, tanto para leitura, quanto para escrita, de 50 picosegundos. Então, consideramos só esses três termos, o resto tudo considerado sem atrasos, para simplificar a nossa vida. E como a gente está trabalhando com processadores que dependem do workload, porque o Uniciclo não depende, todas as instruções têm sempre o mesmo tempo. Então, só preciso contar as instruções no Uniciclo. Já no Multiciclo e no Pipeline, não, cada instrução pode ter um tempo diferente. Então, a gente precisa saber qual é o workload que a gente está trabalhando. Então, o nosso workload vai ser 25% de loads, 10% de stores, 11% de branches, 2% de jumps e 52% de operações com a ULA, tipo R. E aí, a gente vai querer considerar o desempenho. Então, com isso aqui, a gente consegue comparar o Uniciclo com o Multiciclo. Mas, a gente tem o Pipeline. E o que atrapalha o Pipeline são hazards. Então, a gente precisa caracterizar no nosso workload qual é a influência desses hazards. Então, comparar o desempenho, considerando que para o Pipeline 50% dos loads é seguido de uma operação que requer o argumento. Quer dizer, é um load seguido de um tipo R onde o tipo R precisa do resultado do load. Ok? 25% dos desvios não são previstos erradamente. E que o atraso da previsão é de um ciclo de clock. Quer dizer, eu estou avaliando os desvios condicionais na segunda etapa, certo? Se ele errar, eu tenho que matar a instrução anterior, né? Seria, então, a inserção de uma bolha. Então, 25% dos desvios são previstos erradamente. E que a previsão errada, o custo é de um ciclo de clock. Os jumps utilizam dois ciclos de clock. Porque, obrigatoriamente, ele vai ser o jump, o JAL, o JALR, seguido de uma bolha. Então, os jumps precisam desses dois ciclos. Sempre é seguido de uma bolha. E ignorar todos os outros hazards que, por acaso, possam existir. Então, considerando só esses três hazards aqui. Então, hazard de dados e dois hazards de controle. Fala, Eduardo. Isso é para falar, né? Para falar, levanta a mão assim. Ah, essa é uma bolha? Eita, passou longe. Balão do pensamento. Ok, então vamos fazer os cálculos aqui. Eu quero saber qual desses processadores, qual dessas organizações, já que a ISA é a mesma, então a arquitetura do conjunto de instruções é a mesma, que é o MIPS. Certo? Então, eu quero saber qual dessas organizações é a mais... que possui melhor desempenho. Bom, a gente sabe que para medir o desempenho, a gente tem que medir o tempo de execução, certo? E o tempo de execução, a gente sabe que o tempo de execução é I vezes CPI vezes T. Beleza? Mas a gente não sabe, certo? O I. A gente não sabe quantas instruções tem. Então, o que nós vamos fazer? Vamos medir os tempos médios das instruções. Certo? Quando eu medir o tempo médio para execução de uma instrução, aí eu sabendo a TG, eu consigo calcular, né? E ver CPI. Tranquilo? Então, vamos lá. No Uniciclo, quem é que determina a frequência de clock? Como é que eu calculo a frequência de clock no Uniciclo? Isso. Não é o que seja o load, Marcelo. É a instrução mais demorada. E nessa nossa ISA, é o load, certo? Numa outra ISA, poderia ser outra instrução. A ponto flutuante é um que demora muito. Certo? E na nossa ISA, é o load. Então, o que o load tem que fazer? Ele tem que ser lido da memória. Então, essa aqui. Ele tem que ler o banco de registradores. Ele tem que calcular o endereço com a ULA. Ele tem que ler da memória, já que é um load. Ler da memória. E escrever no banco de registradores. Aquelas cinco etapas do load. Certo? Então, isso aqui te dá 600 picosegundos. Então, esse aqui tem que ser esse aqui, que não é o período de clock. O quê? Qual é o CPI do Uniciclo? No Uniciclo, sempre, uma instrução vai ser completada a cada ciclo de clock. Então, CPI igual a 1. Da onde eu tiro, então, que o tempo médio de execução vai ser 600 picosegundos vezes 1. Então, o tempo médio para a execução de uma instrução vai ser de 600 picosegundos. Certo? Porque todas as instruções têm 600 picosegundos e a CPI é 1. Tranquilo? Então, a gente vai comparar o tempo médio de uma instrução. Se eu soubesse o I, aí eu poderia calcular o tempo total mesmo de execução do meu workload. Ok, no Multiciclo. Então, no Multiciclo, quem é que determina o período de clock? Quem é que determina o período de clock? Isso, a etapa mais demorada. Então, se eu observar aqui a etapa mais demorada, vai ser o acesso à memória. Certo? Então, o acesso à memória que está definindo qual é o período do clock do Multiciclo. Tá? Então, o período de clock vai ser 200 picosegundos. Não, não somente isso. Qualquer outra instrução teria esse período de clock. Quer dizer, teria que ter esse período de clock. Porque todas as instruções precisam ser lidas da memória. Então, mesmo que não fosse um load, que não lesse da memória de dados, ele teria que ler da memória de instruções. Certo? Então, não é por causa do load, disso aqui. É porque a etapa mais lenta é a leitura da memória. Aqui pode ser memória de dados ou memória de instruções. Elas podem ter tempos diferentes também. Esquece multithread. Porque multithread tem que ter duas tarefas completamente independentes uma da outra. Tá? Então, não é isso que vai acontecer aqui. Depois a gente pode conversar sobre isso. Mas, no final, a gente vai ver para que o uso da memória cache é que vai reduzir esse negócio aqui. Então, o tempo de acesso à memória. Para isso se usa a memória cache. Ok? Ok. Então, uma vez que eu sei isso aqui, eu posso calcular a minha CPI média com base no meu workload. Esses aqui. Então, 25% de loads. 0,25 vezes 5 ciclos. O load demora 5 ciclos no nosso Multiciclo. 10% de stores. Então, 0,1 vezes 4 ciclos. Então, store só tem 4 ciclos. 11% de branches. Desvios condicionais. Então, 0,11 vezes 3. Mais 2% de jumps. Desvios incondicionais. Então, 0,02 vezes 3. E 52% de operações tipo R. Né? Operações da ULA. Então, 0,52 vezes 4. Então, fazendo isso, a gente chega que a gente tem um CPI médio do nosso workload de 4.12. Ok? Então, se eu multiplicar o CPI médio com o período, eu tenho tempo de execução médio de uma instrução. Certo? Então, 200 vezes 4.12. Isso te dá 824 picosegundos. Tem algo estranho aqui, pessoal? Tem algo estranho? Vocês enxergam algo estranho aqui? Um Multiciclo mais lento? Exatamente! Um Multiciclo deu mais lento do que um Uniciclo. Logo, nessa nossa configuração de arquitetura MIPS, o Multiciclo é mais lento que o Uniciclo. Logo, joga fora. É, o Patterson meio que tentou tirar o Multiciclo do livro dele, né? Mas viu que os conceitos de Multiciclos eram importantes para os alunos entenderem mais tarde. Multiciclos não gostam de load. Como é que eu poderia tornar isso aqui mais rápido? Tornar isso aqui mais rápido seria eu diminuir a quantidade de loads e stores. Diminuindo essa quantidade aqui, aí eu torno isso aqui mais rápido. Certo? Então, quanto menos loads e stores vocês, o usuário de um programa de vocês, quanto menos acesso à memória for utilizado, melhor. Beleza. Então, nesse caso aqui, ele perdeu. E no Pipeline? Qual seria o período de clock do Pipeline? Como é que eu determino o período de clock do Pipeline? É o tipo de resposta. Errado não está mesmo. Mas não é essa a resposta que eu quero. Isso é a mesma do Multiciclo. Porque eu vou no Pipeline, eu vou ter que identificar qual é a etapa do Pipeline que é mais lenta. Então, a gente vai ver que a etapa mais lenta vai ser o acesso à memória também. Seja no estágio IF (Instruction Fetch), onde eu tenho acesso à memória de instruções, ou no estágio MEM (Memory Access), que é o que tem acesso à memória de dados. Então, a etapa mais lenta também vai ser a de acesso à memória. Então, esse mesmo aqui. Então, a frequência do Multiciclo vai ser a mesma frequência do Pipeline. Ok? Já esse aqui, não. Ele é três vezes mais lento. A frequência do Uniciclo. Mesmo em três vezes mais tempo de frequência, ele é mais rápido que o Multiciclo. Logo, qual dos dois gasta menos energia? Qual dos dois esquenta menos ou esquenta mais? O Multiciclo. O Uniciclo esquenta mais. O porquê? Porque está usando uma frequência maior. O Uniciclo vai esquentar menos, porque eu tenho uma frequência menor. Certo? É mais friozinho, exatamente. E é mais rápido do que o Multiciclo também. Ok, vamos lá no Pipeline. Então, no Pipeline, agora, a gente vai ter que ver, além do workload, os hazards. Certo? Então, vamos lá. Eu tenho 25% de loads. E desses 25%, 50% é seguido de uma operação que requer o argumento. O que significa isso? Que 50% dos loads é seguido de uma operação que requer o argumento. Significa que em 50% dos loads, eu vou ter que botar uma bolha. Certo? Nos outros 50%, eu não preciso botar a bolha. Entendido isso, pessoal? Entendido isso aqui? Então, vamos lá. Então, nós vamos ter 0,25, que é de loads. Desses 0,25, qual é a CPI média de um load, então? Se metade precisa de um ciclo e a outra metade precisa de dois ciclos, qual é a CPI média? Metade usa um ciclo e a outra metade usa dois ciclos. Qual é a CPI média? Aqui dá 1,5, exatamente. Então, 25%, que é dos loads, vai ter uma CPI média de 1,5. Certo? Entendido por que 1,5? Ok. Então, seguindo. 10% de stores. Stores tem problema? Não, stores não tem problema. Então, 10%, qual é a CPI média de um store se ele não tem problema nenhum? CPI do Pipeline é 1. Então, 0,1 vezes 1. Ele precisa de um ciclo para terminar. 11% de branches. E aqui a gente tem um problema. Que 25% dos desvios são previstos erradamente. E o atraso da previsão é de um ciclo. Quer dizer, 25% dos branches eu preciso de dois ciclos. Os outros 75% eu só preciso de um ciclo. Certo? Então, 75% são previstos corretamente. Então, o branch só precisa de um ciclo. E 25% deles eu vou precisar de dois ciclos. Logo, qual é a CPI média? Então, a CPI média nesse caso, pessoal. Vamos lá, calculando. Como é que vocês descobriram que a CPI média do Marcelo eu descobri que a CPI média era 1 mais 2 sobre 2. 1 mais 2 sobre 2 é a mesma coisa que 0,5 vezes 1 mais 0,5 vezes 2. Certo? 1 mais 2 sobre 2. No nosso caso, não é 50% e 50%. É 25% e 75%. Logo, qual é a CPI média? Difícil, pessoal. Vamos de novo. É 25% dos branches precisa de dois. E 75% precisa de um. A quanto isso? Então, 25% precisa de dois ciclos. E 75% precisa de um ciclo. O que que tu achou que era 2? O do 0,75%. Isso que eu confundi. Achei que era 0,75 vezes 2. Não. 25% são previstos erradamente. Logo, os outros 75% são corretos. Então, 1,25. Certo? Então, 11% de branches. O que mais? 2% de jumps. E o jump precisa sempre de dois ciclos. Que é devido à bolha. Então, 0,02 vezes 2. Mais 52% de operação com a ULA. E, a ULA não gera nenhum hazard aqui. Então, 0,52 vezes 1. Já que não tem hazard, a instrução termina no ciclo de clock. Então, fazendo essa conta, tu encontra 1,17. Certo? Qual seria a CPI ideal do Pipeline? A CPI ótima do Pipeline. Qual é a CPI ótima de um Pipeline que não tem problema nenhum? 1. Então, a gente está perdendo aqui na CPI. Então, o tempo de execução médio de uma instrução vai ser 200 picosegundos vezes 1,17, que dá 234 picosegundos. Agora, então, vocês conseguem ver o ganho que a gente tem com o Pipeline. A gente conseguiu reduzir de 600 para 234. Qual é o fator de desempenho que a gente tem aqui? Quantas vezes o Pipeline é mais rápido que o Uniciclo? 2,5. 2,5. Certo? Então, é duas vezes e meio mais rápido que o Uniciclo. Certo? Considerando apenas isso aqui. Tá? E esse workload? Se eu mudar o workload, esse fator de desempenho também muda, porque vai mudar isso aqui, vai mudar isso aqui. Também depende do workload. O fator de desempenho depende do workload. Faz sentido isso para vocês? Ok.",
        "video_source": "OAC_2022-04-13.mp4"
    },
    {
        "id": 3,
        "timestamp_start": 1384.73,
        "timestamp_end": 1386.73,
        "slide_description": "Como Engenheiro de Computação Sênior, analiso o slide e o contexto anotado da aula de Arquitetura de Computadores para extrair e descrever o conteúdo visual para um sistema de busca semântica (RAG).\n\nA imagem exibe uma interface de conferência web de uma aula online. A área principal de exibição de slides está predominantemente escura, indicando o fim da apresentação formal do conteúdo. No canto superior direito desta área escura, há uma mensagem indicativa do estado da apresentação: \"Fim da apresentação de slides. Clique para sair.\".\n\nAinda na área de slides, no canto inferior direito, são visíveis informações institucionais e do curso, que transcrevo fielmente:\n*   \"Universidade de Brasília\"\n*   \"Departamento de Ciência da Computação\"\n*   \"CIC0009 - Organização e Arquitetura de Computadores\"\n*   \"Prof. Marcus Vinícius Lamar\"\n\nNão há diagramas (Datapath, Pipeline, Hierarquia de Memória), código (Assembly, C, Verilog) ou conteúdo técnico específico de arquitetura visível na área do slide, além dos metadados da disciplina. A área de apresentação está em um estado de transição ou de encerramento da exibição de slides.\n\nNa barra lateral esquerda da interface, encontra-se a seção de \"Bate-papo público\", onde uma interação textual entre os participantes e o professor é visível. As mensagens transcrevem uma discussão focada em cálculos numéricos:\n*   \"1,75\" (possivelmente um resultado ou valor inicial)\n*   \"kkkkk\"\n*   \"0.25*2 + 0.75*1\" (proposta de cálculo por Marcus Vinicius Lamar)\n*   \"ata, 1\"\n*   \"achei que era 2\"\n*   \"1,25\"\n*   \"1\"\n*   \"1 uai\"\n*   \"600/234\" (outra proposta de cálculo ou valor)\n*   \"2,5641025641\" (resultado do cálculo anterior)\n*   \"faz\"\n*   Há também a indicação \"Marcello Brandao Scartezini E Silva está digitando\", sinalizando atividade contínua no chat.\n\nA natureza dos cálculos no bate-papo sugere uma discussão interativa sobre valores ou ponderações, o que em Arquitetura de Computadores poderia estar relacionado a tópicos como cálculo de tempo médio de acesso à memória (AMAT), performance de pipelines com custos de estágios variados, ou avaliação de métricas de desempenho que envolvem pesos e probabilidades. No entanto, sem o contexto explícito do slide ou da fala do professor, a finalidade exata desses cálculos não pode ser determinada com precisão apenas pela imagem.\n\nA imagem também mostra o professor, Marcus Vinícius Lamar, em uma pequena janela de vídeo no canto inferior direito da tela, confirmando sua presença e participação na aula.",
        "transcription": "Então, essa é a nossa comparaçãozinha.",
        "video_source": "OAC_2022-04-13.mp4"
    },
    {
        "id": 4,
        "timestamp_start": 1386.73,
        "timestamp_end": 1424.71,
        "slide_description": "Atuando como um Engenheiro de Computação Sênior, procedo à análise e descrição do conteúdo do slide apresentado para um sistema de busca semântica.\n\nO slide faz parte de uma aula da disciplina \"UnB - CIC0099 - Organização e Arquitetura de Computadores\", ministrada pelo Prof. Marcus Vinicius Lamar, do Departamento de Ciência da Computação da Universidade de Brasília.\n\nO título principal do slide é \"Solução\", e em anotação manual visível, há a fórmula fundamental para o cálculo do tempo de execução de um programa: \"TEMPO = I x CPI x T\", onde 'I' representa o número de instruções, 'CPI' (Cycles Per Instruction) é o número médio de ciclos de clock por instrução, e 'T' é o período de clock.\n\nO slide apresenta uma comparação de métricas de desempenho para três arquiteturas distintas de processadores: Uniciclo, Multiciclo e Pipeline, calculando o período de clock, o CPI e o tempo de execução médio da instrução para cada uma.\n\n1.  **Arquitetura Uniciclo:**\n    *   **Período de clock:** Calculado como a soma dos tempos das etapas mais longas da instrução, resultando em \"200+50+100+200+50 = 600ps\". Este valor representa o tempo que um único ciclo de clock leva para ser concluído, acomodando a instrução mais longa.\n    *   **CPI:** Definido como \"CPI=1\", o que é característico de uma arquitetura uniciclo, onde cada instrução completa sua execução em um único ciclo de clock.\n    *   **Tempo de execução médio da instrução:** Calculado como o produto do período de clock pelo CPI, resultando em \"600x1=600ps\".\n\n2.  **Arquitetura Multiciclo:**\n    *   **Período de clock:** Estabelecido em \"200ps\", o que indica que, ao dividir as etapas de execução em ciclos menores, o período de clock pode ser reduzido significativamente em comparação com a arquitetura uniciclo.\n    *   **CPI:** Calculado como uma média ponderada dos CPIs de diferentes tipos de instruções (provavelmente Load/Store, ALU, Branch, etc.), onde os coeficientes (0.25, 0.1, 0.11, 0.02, 0.52) representam a frequência de cada tipo de instrução no programa e os multiplicadores (5, 4, 3, 3, 4) representam o número de ciclos de clock que cada tipo de instrução leva para ser executada. O resultado do cálculo é \"0.25x5+0.1x4+0.11x3+0.02x3+0.52x4 = 4.12\".\n    *   **Tempo de execução médio da instrução:** Calculado como \"200x4.12=824ps\". Nota-se que, apesar de um período de clock menor, o CPI elevado da arquitetura multiciclo (devido a múltiplas etapas por instrução) pode levar a um tempo de execução médio por instrução maior que o uniciclo em certos cenários.\n\n3.  **Arquitetura Pipeline:**\n    *   **Período de clock:** Mantido em \"200ps\", o mesmo valor da arquitetura multiciclo, pois o pipeline também subdivide as instruções em etapas que podem ser executadas em um único ciclo de clock.\n    *   **CPI:** Calculado como uma média ponderada similar à multiciclo, mas com multiplicadores (1.5, 1, 1.25, 2, 1) que refletem o CPI efetivo de cada tipo de instrução em um pipeline. Esses valores são tipicamente próximos de 1, mas podem ser ligeiramente maiores devido a *stalls* ou *hazards*. O resultado é \"0.25x1.5+0.1x1+0.11x1.25+0.02x2+0.52x1 = 1.17\". O CPI próximo de 1 é a principal vantagem do pipeline.\n    *   **Tempo de execução médio da instrução:** Calculado como \"200x1.17=234ps\". Este é o menor tempo de execução médio por instrução entre as três arquiteturas, demonstrando a superioridade do pipeline em termos de *throughput* e, consequentemente, desempenho para um conjunto de instruções.\n\nO chat lateral da conferência exibe algumas interações que complementam a discussão:\n*   Um participante, Marcus Vinicius Lamar (possivelmente o professor ou um aluno com o mesmo nome), postou \"0.25*2 + 0.75*1\", o que pode ser um cálculo auxiliar ou uma etapa anterior de discussão sobre CPI ponderado.\n*   Discussões sobre valores numéricos como \"1\", \"2\", \"1,25\" e \"1 uai\" indicam que os alunos estavam acompanhando e verificando os cálculos ou discutindo resultados intermediários.\n*   Uma mensagem \"600/234\" e seu resultado \"2,5641025641\" sugere uma comparação direta entre o tempo de execução do Uniciclo (600ps) e do Pipeline (234ps), indicando que o Pipeline é aproximadamente 2.56 vezes mais rápido.\n*   Comentários como \"ainda bem q n tem q fazer pipeline no deeds\" e \"o pc ia pegar fogo\" são observações informais que refletem a complexidade e os desafios de projeto de uma arquitetura pipelined, bem como a melhoria de desempenho que ela proporciona (evitando superaquecimento por carga de trabalho excessiva ou lentidão).\n\nEm resumo, o slide demonstra a aplicação da equação fundamental de desempenho de processadores para comparar quantitativamente a eficiência de diferentes implementações de CPU (Uniciclo, Multiciclo e Pipeline) em termos de período de clock, CPI e tempo médio de execução por instrução, destacando a vantagem de desempenho do pipeline.",
        "transcription": "Então, a gente fecha a aula passada. Cuidado, pessoal, em relação a isso. Vocês que pensam. Vamos lá. Então, o que que é o nosso laboratório... Se aqui fosse uma palestra... O que que é o nosso laboratório 5? Vamos lá. Então, vamos para o nosso laboratório 5.",
        "video_source": "OAC_2022-04-13.mp4"
    },
    {
        "id": 5,
        "timestamp_start": 1434.01,
        "timestamp_end": 2682.95,
        "slide_description": "O slide, parte de uma aula de Organização e Arquitetura de Computadores (CIC0009) da Universidade de Brasília, lecionada pelo Prof. Marcus Vinicius Lamar, apresenta um roteiro de laboratório detalhado para a implementação e análise de um processador RISC-V.\n\n**Conteúdo Textual Transcrito:**\n\n**Título e Informações da Instituição:**\n*   Universidade de Brasília\n*   Departamento de Ciência da Computação\n*   CIC0009 - Organização e Arquitetura de Computadores\n*   Prof. Marcus Vinicius Lamar\n\n**Objetivos do Projeto:**\n*   Implementar uma CPU Pipeline compatível com a ISA RV32I no Software de Simulação Deeds;\n*   Analisar o desempenho do processador construído.\n\n**Descrição Geral da Tarefa:**\nA tarefa consiste em construir, utilizando os conceitos e diagramas da aula e os blocos do Laboratório 3 (incluindo registradores de monitoramento), um processador µRISC-V compatível com a ISA RV32I no software de simulação Deeds. Este processador deve ser capaz de executar um subconjunto reduzido da ISA RV32I, que inclui as seguintes instruções: `add`, `sub`, `and`, `or`, `xor`, `slt`, `sltu`, `lw`, `sw`, `addi`, `andi`, `ori`, `xori`, `slti`, `sltiu`, `sll`, `slli`, `lui`, `auipc`, `beq`, `bne`, `bge`, `bgeu`, `blt`, `bltu`, `jal` e `jalr`.\n\n**Subseções Detalhadas da Tarefa:**\n\n**1.1 (4.0 pontos) Implementação do Caminho de Dados e Controle do Pipeline:**\nDetalha a construção do caminho de dados completo e do bloco de controle, começando com a adição de registradores de pipeline (IFID, IDEX, EXMEM, MEMWB) a um Processador Uniciclo já existente. Especifica que o sinal de reset deve inicializar os registradores do BR (Stack Pointer - SP) para `0x100103FC` e o Program Counter (PC) para `0x00400000`. Desvios condicionais devem ser tratados como \"não tomados\" e avaliados na 2ª etapa do pipeline (acrescentando um módulo de comparação). As instruções `jal` e `jalr` devem ser sempre seguidas por uma \"bolha\" (stall/nop). Outros \"hazards\" (perigos de pipeline) devem ser resolvidos via código assembly com execução fora de ordem ou inserção de `nops`.\n\n**1.2 (2.0 pontos) Teste e Verificação:**\nRequer a execução do programa `TestBench.s`, desenvolvido no Laboratório 3, para verificar a correta implementação de todas as instruções. Deve-se filmar a execução e determinar a máxima frequência de clock utilizável pelo processador construído.\n\n**1.3 (2.0 pontos) Análise de Desempenho (Programa Teste2.s):**\nSolicita a simulação e filmagem da execução do programa `Teste2.s` na maior frequência de clock possível. Pede o cálculo do CPI (Cycles Per Instruction) médio e a verificação da fórmula de tempo de execução: `t_exec = I x CPI x T` (onde `I` é o número de instruções, `CPI` é o Cycles Per Instruction e `T` é o período do clock).\n\n**1.4 (2.0 pontos) Análise Comparativa de Arquiteturas:**\nDemanda uma comparação e análise das formas de onda dos processadores `Uniciclo`, `Multiciclo` e `Pipeline`, utilizando o programa `TestBench.s`. A comparação deve ser feita nas maiores frequências de clock possíveis para cada organização. Devem ser medidos e analisados os tempos de execução, o número de instruções (`I`), o CPI médio e o período do clock (`T`) para cada arquitetura. Conclusões sobre o desempenho dos três processadores devem ser apresentadas. Uma dica é usar o zoom nas formas de onda para mostrar detalhes da execução de instruções específicas como `add`, `lw`, `beq` e `jal` nas três organizações.\n\n**Requisitos de Entrega:**\nO arquivo `GrupoX_Lab5.zip` a ser enviado no Moodle deve conter:\n*   (i) O relatório em formato PDF: `GrupoX_Lab5.pdf`;\n*   (ii) Os arquivos do processador com o programa `Teste2.s` já carregado na ROM.\n\n**Diagramas:**\nNão há diagramas visíveis no slide; o conteúdo é inteiramente textual, descrevendo as instruções do projeto/laboratório.",
        "transcription": "Então, para o Laboratório 5, o que nós vamos fazer? Aquilo que o Marcelo não queria. Nós vamos implementar o micro RISC-V Pipeline. Certo? Então, implementar o Pipeline compatível com a ISA RV32I. Essa aqui que é a mesma ISA, tanto do Multiciclo quanto do Uniciclo. Certo? Então, a partir dos conceitos e diagramas apresentados em aula e os blocos construídos no Laboratório 3, incluindo os registradores de monitoramento que vocês fizeram no Laboratório 3, construam o processador micro RISC-V com a ISA RV32I usando o software de simulação Deeds. Que seja, quer dizer, essa ISA reduzida aqui, a mesma dos outros. Por isso que eu disse: se vocês fizeram o Laboratório 3 bem, o Pipeline fica muito fácil. Então, vamos lá. Então, 1.1: Construa o caminho de dados correto e o bloco de controle apenas acrescentando os registradores de Pipeline no processador uniciclo já implementado. Certo? Então, faz o novo caminho de dados a partir daquele uniciclo e coloca os registradores de Pipeline nos processadores corretos. Então, é bom redesenhar aquele circuito de uniciclo. Calma. O sinal de reset deve resetar os valores dos registradores do Bloco de Registradores. Lembrando que o SP tem que ter, ao ser resetado, tem que ter esse valor aqui, que é o último endereço da memória. Os registradores do Pipeline também têm que ser resetados, certo? E o PC tem que ser resetado para o valor inicial da memória de programa, esse endereço aqui. Façam os desvios condicionais previstos como não tomados e avaliados na segunda etapa. Certo? Então, o que que eu estou fazendo? Agora vocês devem ter feito o circuitinho de comparação dos dois registradores, porque vocês precisavam do BEQ, BNE, BGE, BGEU, BLT, BLTU, né? Então, acrescentem isso só de na segunda etapa, daquela forma que a gente fez em aula. Né? Ah... Segunda etapa. JAL e JALR sempre seguidos de uma bolha. Quer dizer, os desvios incondicionais, só temos esses dois aqui, têm que ser seguidos sempre por uma bolha. E todos os outros hazards devem ser resolvidos no código Assembly, com execução fora de ordem e/ou colocando NOPs. Tá? Então, os outros hazards que vocês têm que cuidar no uniciclo — quer dizer, desculpe, no Pipeline — é se por acaso for um BEQ e o BEQ for verdadeiro, tem que acrescentar uma bolha. E se for JAL ou JALR, tem que acrescentar uma bolha. Quer dizer, tem que dar um flush na instrução que está no estágio IF. Ok? Entenderam isso aqui? Então, a única coisa que vocês têm que implementar é o flush do IF. Tá? No estágio IF. Que é parar o PC e colocar no registrador IFID a instrução NOP, que é ADDI X0, X0, 0. Tranquilo, pessoal? Com certeza demora um pouco, mas tem que fazer. Então, notem: todos os outros hazards não precisa implementar forwarding, não precisa implementar o hazard de load, certo? Não é necessário. ... O hazard é para fins educacionais mesmo, tá? Não é para usar para projetos. Não, esse aqui, no caso, vocês têm que atualizar, tá? Porque ele não vai ter os NOPs dos hazards, tá? Então, tem que colocar aqui os NOPs para corrigir os hazards. Então, não é exatamente o mesmo programa que vocês vão pegar lá e botar. Até pode tentar e vai dar errado, tá? Tá? Então, execute seu programa, `TestBench.s`, devidamente atualizado (entre parênteses aqui, feito no Laboratório 3), e verifique se todas as instruções foram implementadas corretamente. E filme a execução. Qual é a maior frequência utilizada nesse processador? Então, a partir daqui, vocês vão incrementando a frequência até que comece a dar as coisas erradas. Ok? 1.3. Faça a simulação de forma de onda na maior frequência possível e filme a execução do programa `Teste2.s`. Não, não significa isso, ah, Marcelo. Tá? Então, aqui eu quero que vocês façam a forma de onda do `Teste2.s` no seu processador. Qual é a CPI média? Qual é a CPI média? Não. Qual a CPI média? Desculpa. Qual é a CPI média desse workload aqui? Tá? Dado para esse `Teste2`. E verifique se o tempo de execução é realmente I vezes CPI vezes T. Tá? A CPI média e o total de instruções executadas pelo programa, né? E T o período de clock. Qual é a... Só que qual a CPI média? É, deixa eu falar. É que, espera, que é coisinha, né? Só que tem, você, no relatório, nesse PDFzinho, alguns anos passados. Como é que é? É que é engraçado. E aí o nosso relatório tem que fazer certinho. Aí nesses PDFs que você passa do laboratório, em vez de colocar você, você coloca você. Aí eu acho muito engraçado. Não, é. Mas aonde que tem você aqui? Isso aí eu tenho que corrigir. Não, no laboratório. Que conclusões você tira quanto ao desempenho dos três processadores? Ah, tá. Aqui embaixo, né? Que conclusões tu tiras quanto ao desempenho dos três processadores? Beleza? Ah, se está melhor, querido professor. Um minutinho. Então, com a máxima frequência, fazer o `Teste2` na máxima frequência possível, tirar a forma de onda e verificar a CPI média e verificar se isso aqui realmente funciona. Compare e analise as formas de onda dos processadores Uniciclo, Multiciclo e Pipeline. Então, no Laboratório 4, eu já pedi para vocês compararem a forma de onda do Uniciclo com o Multiciclo. Então, vocês já têm isso pronto. Tá? É só botar mais o Pipeline, tá? Para o seu programa `TestBench.s`. Devidamente corrigir os hazards. Ah, meu Deus. Agora eu tenho uns revisores de português aqui. Não, eu estou falando que a gente tem pronto, a gente... Temos pronto aqui. Pronto. Tá? Tá bom. Vamos tentar falar corretamente também. Morreu uma cedo. Então, vamos lá. Então, o que eu quero aqui? Esse forma de onda na maior frequência de clock possível em cada organização. Beleza? Quais os tempos de execução medidos para cada um? Certo? Então, nos registradores de monitoramento, a gente tem, né? Quando o programa é executado. Então, até o final, ele mostra qual é o tempo de execução, tá? Qual é a CPI média e o T de cada um. Ah, não. Nesse caso é CPI média. Tá? Qual é o número de instruções, CPI média que vocês vão calcular e T, período de clock de cada um. Que conclusão disso tu tiras quanto ao desempenho dos três processadores? Agora eu quero que vocês analisem, tá? Então, dica. Para comparar as formas de onda de maneira mais proveitosa para vocês, dê um zoom para mostrar os detalhes da execução dessas quatro instruções aqui: o ADD, o LOAD. Façam um LOAD aqui onde tem o Hazard, tá? BEQ e JAL, nas três organizações. Certo? Então, é pegar um ADD sendo executado no uniciclo, um ADD no multiciclo, e um ADD no Pipeline, certo? Depois, um LOAD no uniciclo, um LOAD no multiciclo e um LOAD no Pipeline. E para essas duas aqui também. Tá? Então, é um zoom da forma de onda, para a gente poder ver só aquela instrução sendo executada. Ok? Entendido, pessoal? No Pipeline, vocês vão ter que tirar cinco ciclos de clock. Do uniciclo, um ciclo de clock. E do multiciclo, esse aqui vai ser quatro ciclos de clock, esse aqui cinco ciclos de clock, esse aqui três, e esse aqui dez. Entendido isso? Deu dúvidas, pessoal? Ser o mesmo período mostrado ou são só as ondas? Não, só as ondas, porque vocês não vão conseguir colocar todas no mesmo período de tempo. Então, o que eu quero é, na execução de um ADD, do uniciclo, qual é o ciclo que executa um ADD? E dá um zoom aí. Pode ser qualquer ADD que vocês tenham lá. Depois, no multiciclo, pega, pode ser até mesmo esse mesmo ADD, pega os quatro ciclos onde esse ADD é executado. E no Pipeline, pega os cinco ciclos onde o ADD começa a ser executado até terminar. São cinco ciclos. Certo? E aí, só para vocês verem as diferenças na forma de onda para as três organizações. Beleza. Então, eu acho que era isso. Se vocês não têm dúvidas, nenhuma mais. Tem mais alguma dúvida? É só desse treino do Pipeline aí. A gente vai ter que colocar aquele infinito número de bits para cada um desses, para o IFID, IDEX, EXMEM, MEMWB. É, para os registradores de Pipeline tem que ter o número de bits correto. Tá, então, aqueles, mais ainda os do PC que a gente tem, mais ainda os de controle. Meu Deus do céu. Vocês fizeram o multiciclo? Fizemos, né, Marcelo? É, claro que fizemos. Claro. Esse já está entregue lá. Fiz, não, acabei de terminar ontem o Pipeline, na verdade, né? Tá bom. Tá, então, os registradores de Pipeline, se vocês acharem muito complicado fazer aquele registrador grandão, porque aquele registrador grandão, você vai ter que usar vários registradores pequenininhos. Tá? Fazer aquele grandão. Então, coloca, faz um bloco, que seja o registrador IFID. Tem outro bloco, que seja o IDEX. Por que que está complicado? Eu acho que ficou mais fácil do que o semestre passado. Semestre passado eu tinha pedido para implementar todos os forwardings. Aqui eu só estou pedindo uma análise um pouquinho diferente, mas nada da construção. Se a construção é mais simples. Não, professor, é que, tipo assim... Ah, tá, entendi. Sim, complicados 90 dias, é. Isso, porque o negócio é que várias datas ficam uma sobre a outra, assim, aí fica atrapalhando todo o ciclo normal. É, semestre... Oh, semestre que vem, não. Daqui duas semanas... Acaba o semestre. Ou eu passo ou não em três matérias, professor. Vai estar complicado. Eu sei. Beleza, mas não tinha como fazer isso diferente. Você podia fazer, tipo assim, tira o multiciclo e joga ele fora. Ah, isso bota só o Pipeline. Não, foi interessante para comparar isso aqui. Afinal, é Organização e Arquitetura de Computadores. Eu pensei que a gente ia montar um computador. Mas vocês montaram. Não. Vocês montaram o processador. Ah, no Deeds, faz sentido. O que não tem no computador de vocês são as interfaces. Tá? Vai usar as interfaces de teclado, de áudio e de vídeo. O Deeds não tem isso não, né? Não. Tem que aprender mais coisas no Deeds não. Parando para pensar, quem vai ensinar isso tudo o semestre que vem? Porque não tem monitor que pegou presencial. Eu tenho alguns alunos que foram monitores no presencial e têm essa experiência. Eu estou mais para frente. Mas realmente é uma boa coisa para se pensar. Realmente. Vai estar lascado, Vitor. Como é que você vai ser monitor? Você não sabe mexer numa placa de FPGA. É fácil, você vira monitor e assiste todas as aulas de novo. Eu não tenho as aulas de FPGA gravadas. Porque eram feitas diretamente no Lab. Ah, então você vai ter que assistir as aulas também. Você vira monitor e você vai trancando a matéria. Não, o negócio é o seguinte. O semestre que vem talvez seja o mais complicado. Mas no outro semestre eu vou dar a disciplina de OAC2, que é todo mundo que não fez prática com FPGA. Aí vai poder fazer essa disciplina objetiva, que vai ser justamente a implementação disso aqui no FPGA. Então, ao invés de fazer simulação, filme e a sugestão... Vai ser filme e FPGA funcionando. Entendeu? E ter que rodar, sei lá, Mario Bros, isso e tudo. É, porque teria que rodar. O teu jogo de semestre é qual mesmo? Poxa, eu não sei como é que tu não sabe. Castlevania. Não foi você que escolheu o jogo, não? Não, foi os monitores. Principalmente o Luiz, aquele... O Deeds tem uma propaganda para o Castlevania. Eu acho que ele só tinha sugerido. E que você que tinha escolhido. Tipo, ele tinha feito umas sugestões e você falou \"Ah, Castlevania\". Eles dão algumas sugestões. Eu aprovo algumas e eles aprovam algumas. Por exemplo, aquelas que têm gráfico 3D. Não, mas é um prompt. Dão um prompt e sei tudo bem. Mas, por exemplo, vai fazer um CS, um Counter Strike assim. Daí não, né? O Gustavo só ri. Eu acho que no semestre que vem a gente vai ter que fazer uma aula com os monitores onde eu vou mostrar como é que é o funcionamento da placa, como é que se faz a programação e o funcionamento na placa. Acho que uma aula vai ser o seguinte, acho que uma aula vai ser o seguinte, acho que uma aula vai ser o seguinte, acho que uma aula vai ser o seguinte, acho que uma aula vai ser o seguinte, que uma aula dá, assim, a gente se reunindo uma tarde lá no Lab, e eu mostrar tudo. Pensa assim, Vitor, é que o Lamar, ele entrou na UnB. Aí quando ele deu a primeira matéria dele, não tinha monitor para ele. Aí no outro tinha. Aí foi uma saga. O primeiro monitor foi quem colocou todo o caminho assim, fez o caminho para poder todo mundo passar na matéria. Agora acabou essa linha, a sucessão. Alguém vai ter que fazer uma nova sucessão. É tipo uma casa nova de, sei lá, de Game of Thrones, sabe? Aí você vai ter que fazer um novo reino. Tipo, o reino que antes já estava acabou. Pô, então quero ver se... Só tem um material antigo, e aí você vai ter que criar um material novo para decifrar o que tem que fazer no FPGA. É, mas está tudo bem documentado. Tem um tutorial sobre como se usa. Vocês não fizeram um LCL com FPGA, né? Então, o pessoal de LCL no semestre que vem já vai usar o FPGA. Então, quando chegam em OAC, eles já sabem usar o FPGA, coisa que vocês não sabem. Então, realmente, o semestre que vem vai ser o mais crítico, né, em termos de OAC. Tá, então, os monitores, eu vou fazer, talvez, um ou dois encontros, não vou dizer que é aula, encontros para atualizar o pessoal como é que se utiliza essa nova tecnologia. Uma reuniãozinha no pagode para poder discutir o FPGA. Ah, e lembre-se que Marcelo e Eduardo, vocês já estão convidados para serem monitores no semestre que vem. Ah, para vocês conseguirem passar aqui agora assim, de boa. Todo mundo que passa é convidado a ser monitor. Ok, temos ainda muito tempo, né? Então eu vou fazer o seguinte, aqui nosso cronograma está bem apertado, eu vou começar a aula que vem. Ok, então, deixa eu dar uma olhada aqui. Então, hoje a gente terminou o Pipeline com o laboratório. Então eu vou começar essa aula de Exceção e Interrupção. Tá, e depois vem Memória Cache e acabou. Tá, são as coisas que a gente precisa para ter um processador completo. Tá, Exceção e Interrupção para ligar os dispositivos externos, tá? E para ter memória para a gente agilizar o acesso à memória. Tentar reduzir o tempo de acesso à memória. Então, vamos ver aqui.",
        "video_source": "OAC_2022-04-13.mp4"
    },
    {
        "id": 6,
        "timestamp_start": 2684.07,
        "timestamp_end": 2710.45,
        "slide_description": "Como Engenheiro de Computação Sênior, realizei uma análise detalhada do slide apresentado, que se trata de uma tela de uma aula online de Arquitetura de Computadores. O conteúdo principal visível é um documento de texto, provavelmente um plano de curso ou cronograma, exibido dentro de um editor de texto (Microsoft Word).\n\n**Conteúdo do Documento (Plano de Curso):**\n\nO documento possui o nome de arquivo \"OAC_A_Plano_2021-2_v0.docx\", indicando ser um plano para a disciplina de Organização e Arquitetura de Computadores (OAC) referente ao segundo semestre de 2021.\nEle está formatado como uma tabela com múltiplas colunas, descrevendo tópicos, atividades práticas (laboratórios) e avaliações. As colunas visíveis incluem um número de índice, duas colunas de datas (possivelmente início e fim de semana ou período de estudo/laboratório) e duas colunas para descrição do conteúdo programático.\n\n**Transcrição Detalhada da Tabela de Conteúdo:**\n\nA tabela descreve os seguintes itens, com datas e identificadores (C.x para capítulos, L.x para laboratórios, T.x para tópicos teóricos):\n\n*   **1ª Prova (P1)**\n    *   **Datas:** 14/3 - 16/3\n*   **Linha 9:**\n    *   **Datas:** 21/3 - 23/3\n    *   **Tópico Esquerdo:** 13) Processador Uniciclo: Unidade de Controle (C.4) (L1)\n    *   **Tópico Direito:** Lab 3: Processador Uniciclo(T9) (L2)\n*   **Linha 10:**\n    *   **Datas:** 28/3 - 30/3\n    *   **Tópico Esquerdo:** 14) Processador Multiciclo: Unidade Operativa (C.4)\n    *   **Tópico Direito:** 15) Processador Multiciclo: Unidade de Controle (C.4) (T10)\n*   **Linha 11:**\n    *   **Datas:** 4/4 - 6/4\n    *   **Tópico Esquerdo:** Lab 4: Processador Multiciclo\n    *   **Tópico Direito:** 16) Processador Pipeline: Conceitos (C.4) (T11)\n*   **Linha 12:**\n    *   **Datas:** 11/4 - 13/4\n    *   **Tópico Esquerdo:** 17) Pipeline: Unidade Operativa e Controle (C.4)\n    *   **Tópico Direito:** Lab 5: Processador Pipeline(T12) (L3)\n*   **Linha 13:**\n    *   **Datas:** 18/4 - 20/4\n    *   **Tópico Esquerdo:** 18) Exceção e Interrupção (C.4)\n    *   **Tópico Direito:** 19) Memória: Hierarquia (C.5) (T13) (L4)\n*   **Linha 14:**\n    *   **Datas:** 25/4 - 27/4\n    *   **Tópico Esquerdo:** 19.1) Memória: Cache (C.5)\n    *   **Tópico Direito:** 2ª Prova (P2) (T14) (L5)\n*   **Linha 15:**\n    *   **Datas:** 2/5 - 4/5\n    *   **Tópico Esquerdo:** Prova Substitutiva\n    *   **Tópico Direito:** Apresentação dos Projetos (PR)(T15)\n\n**Seção \"Avaliação\":**\n\nA seção \"Avaliação\" detalha as datas das provas e a natureza da prova substitutiva:\n*   `P_1: 1ª Prova: 14/03/2022`\n*   `P_2: 2ª Prova: 27/04/2022`\n*   `Prova Substitutiva: 02/05/2022`\n*   `É optativa e pode substituir qualquer uma das notas` (texto parcialmente visível, mas inferível).\n*   Há uma menção parcial a \"Média dos Testes Semanais\" e uma fórmula \"M - 1 (S15 )\", indicando a composição da nota final.\n\n**Contexto Adicional (Comentário no Documento):**\n\nUm balão de comentário no canto superior direito do documento revela informações importantes sobre o curso:\n*   \"Universidade de Brasília\"\n*   \"CIC0099 - Organização e Arquitetura de Computadores\"\n*   \"Prof. Marcus Vinicius Lamar\"\n\n**Análise Técnica para Sistema de Busca Semântica (RAG):**\n\n1.  **Tópicos Centrais de Arquitetura de Computadores:** O slide descreve um currículo típico para uma disciplina de Arquitetura de Computadores, cobrindo sequencialmente:\n    *   **Processadores Uniciclo:** Foco na Unidade de Controle, com atividades de laboratório.\n    *   **Processadores Multiciclo:** Abordando Unidade Operativa e Unidade de Controle, também com laboratórios.\n    *   **Processadores Pipeline:** Introdução aos conceitos, seguido por Unidade Operativa e Controle em pipeline, com laboratórios específicos. Estes tópicos indicam a progressão do ensino sobre a complexidade e otimização da execução de instruções (ISA) em CPUs.\n    *   **Exceção e Interrupção:** Mecanismos cruciais para o tratamento de eventos assíncronos e erros no processador.\n    *   **Hierarquia de Memória e Cache:** Temas fundamentais para o desempenho do sistema, cobrindo os diferentes níveis de memória e a operação da memória cache.\n2.  **Identificadores de Recurso:** A presença de (C.x), (L.x) e (T.x) é valiosa. `C.4` e `C.5` sugerem capítulos de um livro didático padrão (ex: Patterson & Hennessy), `L1` a `L5` indicam atividades práticas de laboratório, e `T9` a `T15` referem-se a tópicos teóricos ou sessões de aula.\n3.  **Avaliação e Cronograma:** As datas das provas (14/03/2022, 27/04/2022) e da prova substitutiva (02/05/2022) fornecem um cronograma concreto para o curso. A flexibilidade da prova substitutiva é um detalhe relevante para políticas acadêmicas.\n4.  **Ausência de Diagramas Visíveis:** O slide não contém diagramas explícitos de Datapath, Pipeline ou Hierarquia de Memória. No entanto, os tópicos listados (\"Processador Uniciclo\", \"Processador Multiciclo\", \"Pipeline\", \"Memória: Hierarquia\", \"Memória: Cache\") são intrinsecamente visuais na sua representação didática, implicando que diagramas (como o datapath de um processador MIPS, estágios de pipeline, ou a estrutura de uma cache) seriam apresentados em outros materiais da aula ou durante a discussão desses tópicos.\n5.  **Contexto Institucional:** \"Universidade de Brasília\", \"CIC0099 - Organização e Arquitetura de Computadores\", e \"Prof. Marcus Vinicius Lamar\" fornecem o contexto acadêmico completo para a recuperação semântica, permitindo associar o conteúdo a uma instituição, disciplina e instrutor específicos.\n\nEm suma, o slide fornece uma visão clara do plano de ensino de uma disciplina de Arquitetura de Computadores, detalhando os módulos de estudo sobre projeto de processadores (uniciclo, multiciclo, pipeline), tratamento de exceções e a hierarquia de memória, juntamente com o cronograma de avaliações. A ausência de diagramas gráficos no slide atual não diminui a relevância dos tópicos, que são frequentemente ilustrados com diagramas em aulas dessa natureza.",
        "transcription": "Eu não tinha",
        "video_source": "OAC_2022-04-13.mp4"
    },
    {
        "id": 7,
        "timestamp_start": 2710.45,
        "timestamp_end": 2739.76,
        "slide_description": "O slide de Arquitetura de Computadores apresentado é da \"Universidade de Brasília\", especificamente do \"Departamento de Ciência da Computação\". O título principal da aula é \"Aula 18: Exceções e Interrupções\". No canto superior direito, há uma identificação mais detalhada do curso: \"CIC0009 - Organização e Arquitetura de Computadores\" e o nome do docente, \"Prof. Marcus Vinicius Lamar\".\n\nO design do slide apresenta um fundo azul escuro com um padrão geométrico de blocos em tons de azul mais claro, formando uma espécie de escada ou diagonal, contra o qual os títulos da aula são exibidos em branco.\n\nNa seção inferior do slide, há duas ilustrações principais:\n1.  **À esquerda**, uma imagem humorística retratando um personagem que lembra Phoenix Wright (do jogo \"Ace Attorney\"), vestido com um terno e gravata, apontando enfaticamente para um conjunto de racks de servidores de data center. Acima da mão do personagem, há um balão de fala ou gráfico em estilo de história em quadrinhos com a expressão \"HOLD IT!\" ou \"OBJECTION!\" em vermelho, embora ligeiramente cortada. Em um dos monitores dos servidores no rack, é possível vislumbrar um diagrama técnico em miniatura, que, devido ao tamanho reduzido, não permite a identificação de elementos específicos como um datapath ou hierarquia de memória. Parece ser um diagrama de blocos generalista.\n2.  **À direita**, é exibida a imagem do professor, presumivelmente Marcus Vinicius Lamar, capturada por uma webcam. Ele aparece sorrindo, usando óculos e uma camiseta escura, com a mão no queixo, denotando interação direta com a audiência.\n\nNão há código Assembly, C ou Verilog visível, nem diagramas técnicos detalhados (Datapath, Pipeline, Hierarquia de Memória) que permitam uma descrição estrutural ou de fluxo de dados específica. A informação principal do slide é o tópico da aula e a identificação da instituição e do professor.",
        "transcription": "Me lembrado, pessoal, do semestre passado, me deu essa figurinha aqui. Não lembrava. Vocês não sabem quantas figurinhas que tem de tu, principalmente no Discord. É tipo um acervo, engraçado, dá para você passar sempre, tipo um Louvre. Não, me passa, então eu coloco no início das aulas. Beleza. Então, vamos lá. Exceções e interrupções.",
        "video_source": "OAC_2022-04-13.mp4"
    },
    {
        "id": 8,
        "timestamp_start": 2740.7,
        "timestamp_end": 4215.11,
        "slide_description": "Este slide de uma aula de Arquitetura de Computadores, intitulado \"Tratamento de Interrupções e Exceções\", detalha o mecanismo fundamental de como um processador lida com eventos anômalos ou externos que interrompem o fluxo normal de execução. O contexto acadêmico é da Universidade de Brasília (UnB), Departamento de Ciência da Computação, para a disciplina CIC0099 – Organização e Arquitetura de Computadores, lecionada pelo Prof. Marcus Vinicius Lamar.\n\n**Conteúdo Textual Transcrito:**\n\n*   **Título Principal:** Tratamento de Interrupções e Exceções\n*   **Seções e Subtítulos:**\n    *   Ex.: Registrador de Causa\n    *   \\# Programa\n    *   \\# Rotina de tratamento de exceção\n    *   ExceptionHandler: ....\n*   **Linhas de Código/Instruções e Eventos Associados:**\n    *   LABEL1: add\n    *   sub\n    *   LABEL2: add\n    *   ... (representa mais instruções do programa)\n    *   overflow: Cause=12 / EPC=PC\n    *   interrupção 3: Cause=0 / EPC=PC\n*   **Lógica da Rotina de Tratamento de Exceção:**\n    *   se cause=0 então vá para xxxx\n    *   se cause=12 então vá para yyyy\n    *   ... (representa mais lógica ou branches para outras causas)\n    *   xxxx:....\n    *   retorna\n    *   yyyy:....\n    *   retorna\n*   **Informações de Rodapé/Cabeçalho da Aula:**\n    *   UnB – CIC0099 – Organização e Arquitetura de Computadores\n    *   Universidade de Brasília\n    *   Departamento de Ciência da Computação\n    *   CIC0099 – Organização e Arquitetura de Computadores\n    *   Prof. Marcus Vinicius Lamar\n\n**Descrição do Diagrama e Fluxo de Dados:**\n\nO slide apresenta um diagrama conceitual que ilustra o fluxo de controle durante o tratamento de interrupções e exceções, focando no uso dos registradores `Cause` (Causa) e `EPC` (Exception Program Counter).\n\n1.  **Programa em Execução:** O fluxo começa com um programa de usuário, representado pelas instruções `LABEL1: add`, `sub`, `LABEL2: add`, e `...`.\n\n2.  **Detecção de Evento (Exceção/Interrupção):**\n    *   **Evento 1 (Overflow):** A instrução `LABEL1: add` é associada a um evento de *overflow* aritmético. Uma seta indica que, quando este evento ocorre, o sistema operacional ou hardware:\n        *   Atribui `12` ao registrador `Cause` (código específico para overflow).\n        *   Salva o valor do `Program Counter (PC)` atual (endereço da instrução que causou o overflow) no registrador `EPC`.\n    *   **Evento 2 (Interrupção 3):** A instrução `LABEL2: add` é associada a uma \"interrupção 3\" (que pode ser uma interrupção externa de E/S, timer, etc.). Uma seta similar indica que, ao ocorrer este evento:\n        *   Atribui `0` ao registrador `Cause` (código específico para interrupção 3).\n        *   Salva o valor do `PC` atual (endereço da instrução interrompida) no registrador `EPC`.\n\n3.  **Transferência de Controle para o Handler:** Ambas as setas (originadas dos eventos de overflow e interrupção 3) convergem para a seção \"# Rotina de tratamento de exceção\", especificamente para o ponto de entrada `ExceptionHandler: ....`. Isso demonstra que, independentemente da causa, o controle é transferido para uma rotina de software pré-definida para lidar com esses eventos.\n\n4.  **Despacho (Dispatch) no Handler:** Dentro do `ExceptionHandler`, há uma lógica condicional baseada no valor do registrador `Cause`:\n    *   \"se cause=0 então vá para xxxx\": Se a causa for `0` (interrupção 3), o controle é transferido para uma sub-rotina específica identificada como `xxxx`.\n    *   \"se cause=12 então vá para yyyy\": Se a causa for `12` (overflow), o controle é transferido para uma sub-rotina específica identificada como `yyyy`.\n    *   `...` indica que pode haver outras condições e sub-rotinas para diferentes valores de `Cause`.\n\n5.  **Execução da Rotina Específica e Retorno:**\n    *   As rotinas `xxxx` e `yyyy` (e outras implícitas) realizam o tratamento específico para cada tipo de exceção/interrupção.\n    *   Após o tratamento, cada rotina termina com uma instrução \"retorna\". Uma seta curva unifica os pontos de retorno de `xxxx` e `yyyy` e os direciona de volta ao fluxo principal do programa original (à esquerda). Este retorno tipicamente envolve uma instrução especial (e.g., `eret` ou `rfe` em algumas arquiteturas) que restaura o `PC` a partir do `EPC` e retorna ao modo de execução anterior ao evento.\n\nEm resumo, o slide descreve o ciclo de vida de uma interrupção/exceção, desde sua detecção no programa principal, passando pelo registro da causa e do ponto de retorno, a transferência de controle para uma rotina de tratamento genérica, o despacho para uma rotina específica baseada na causa, e finalmente o retorno ao ponto de interrupção no programa original. O foco está nos registradores `Cause` e `EPC` como componentes cruciais para essa funcionalidade.",
        "transcription": "Então, exceções e interrupções são coisas que a gente precisa que o processador pare a execução devido a alguma chamada ou algum problema que aconteceu, certo? Alguma chamada do dispositivo externo ou algum problema que aconteceu durante a chamada do dispositivo externo ou mesmo interno. A Intel chama essas duas coisas aqui de interrupção. Então, a Intel sempre usa o termo interrupção. Então, se você consultar os manuais, quando fala da `INT 21H`, pode ser exceção ou pode ser interrupção. Mas nós vamos separar. Então, o que é exceção e o que é interrupção? Exceção, então, são mudanças do fluxo da execução devido a eventos gerados internamente pelo processador. Quer dizer, vocês estão executando o programa de vocês e, de repente, uma instrução causa problema. Certo? Então, que problema poderiam ser esses? Primeiro, instrução inválida. Ele leu a instrução, mas ele não reconheceu aquele opcode, aqueles operandos. Ele tratou aquilo como instrução inválida. O que ele vai fazer? Certo? Nesse caso. Vai parar tudo, dar break, fazer tela azul. Outras exceções são overflow nas operações aritméticas. Aqui, no caso do RISC-V, nas operações de soma, não é detectado overflow, mas poderia ser detectado. E as singularidades matemáticas na unidade de ponto flutuante. Aqui, a gente não criou essa unidade de ponto flutuante. Aqui, são apenas sinalizadas pelo RISC-V. Quer dizer, tirou a raiz quadrada de menos um. O que o processador vai fazer com isso? Pode dar um `NaN` (Not-a-Number), mas isso precisa ser avisado para o usuário. Então, o RISC-V apenas sinaliza o que aconteceu para o usuário. Ele não vai tentar corrigir. E outras duas exceções, mas daí são exceções que foram planejadas, é exatamente isso que eu vou explicar agora. Marcelo, como que se faz uma chamada ao sistema para o usuário? Essas duas instruções aqui, o `ECALL`, vocês já conhecem, e tem também o `EBREAK`. São duas instruções que, na realidade, o que elas fazem é causar uma exceção. Então, o `ECALL`, quando você chama o `ECALL`, na realidade, ele vai causar uma exceção que faz com que o processador comece a executar alguma rotina do sistema. Certo? Então, no caso, posso ler o teclado, posso escrever no vídeo, posso fazer essas coisas. `EBREAK`, ele chama uma rotina de debug. É como se fosse um `breakpoint`, quando vocês estão depurando, passo a passo, vocês querem que ele pare em uma determinada posição do programa de vocês, daí vocês põem um `EBREAK` ali. Esse `EBREAK` vai lá para um programinha que é de debug. E aí vocês podem ver o que está acontecendo. `EBREAK`, não. Exception Break. Certo? E aqui é Environment Call. Certo? Então, são instruções que, na realidade, são exceções. Ok. Vamos supor que ele detectou uma instrução inválida. O que ele tem que fazer quando ele detectou uma instrução inválida? O que o Windows fazia antigamente? Ele chamava uma rotina do sistema. Opa, não detectei o que era a instrução. Então, ao invés de executar, eu vou para uma rotina do sistema que vai preencher a tela toda de azul e escrever aqueles códigos para depuração do erro. E vai mandar o computador ficar em um laço infinito. Certo? Indo para ele mesmo. Entendeu? Então, quem escreve aquela tela azul com aquelas informações é uma dessas chamadas de sistema. A rotina de tratamento de exceções. Mais especificamente. Entendido, Marcelo? Não. Porque se foi o registrador errado, é porque o programador errou. Certo? Então, não acontece isso. O programador tem que ter plena consciência do que ele está fazendo. Ok. Então, isso aqui são eventos inesperados gerados internamente ao processador. Outros exemplos: instrução inválida, endereço inválido, erro de leitura da memória. Tudo é esse problema aqui. Com interrupções. As interrupções são mudanças no fluxo. Então, também, o programa está sendo executado. E tem que parar devido a um evento externo. Certo? Tipicamente, acesso a dispositivos de entrada e saída. Então, através de `DMA` (Direct Memory Access), que a gente vai falar um pouquinho. Acesso ao barramento, porque um dispositivo está solicitando a atenção. E solicitação de dispositivos. Por exemplo, quando vocês clicam em uma tecla, certo? Do PC de vocês, o processador, ele vai verificar, não vai verificar, ele vai ver em um dos pinos dele, que surgiu uma determinada interrupção. E isso, ele sente isso e vai parar o programa e executar a rotina de tratamento de interrupção daquele dispositivo. No caso, ler a tecla. E continua a execução. Ele não fica o tempo todo perguntando, ó, Teclado, quer mandar alguma coisa? Teclado, quer mandar alguma coisa? O teclado quer mandar alguma coisa? E vocês, provavelmente, estão fazendo o jogo de vocês. Né? Que é por... Certo? Aqui, não. Aqui, a gente tem interrupções em eventos externos ao computador. Tá? Então, esse `INT 21h`, aqui, da Intel, chama 108 chamadas de sistema. Que é similar ao `ECALL`. Tá? Então, no nosso... Aqui, a gente tem poucas chamadas de sistema, que o `RARS` implementou em sistema operacional mínimo, tá? A Intel já tem... É profissional e já faz bem as coisas aqui. Ok. Então, o tratamento de interrupções e exceções. Como é que nós vamos fazer isso? Então, pra tratar interrupção e exceção, quem faz isso é o sistema operacional, tá? Que tá rodando por baixo, tá? Se vocês estão rodando o programa de vocês sem sistema operacional, aí isso aqui fica um pouco mais complicado. Porque daí o teu programa vai ter que verificar que aconteceu uma interrupção e chamar a rotina de tratamento de exceção. Tá? Então, geralmente, quem faz isso é o sistema operacional. Então, duas, três coisas que tem que fazer. Primeiro, tem que conhecer o fato que gerou a exceção e interrupção. Eu preciso saber o que que gerou aqui, qual foi o erro, qual foi o dispositivo que pediu. Então, aqui nós vamos ver duas possibilidades. Uma é o uso de um registrador de causa, o registrador `Cause`, que tem que ser um registrador especial, que é usado pra codificar o motivo da exceção e interrupção. Então, por exemplo, ah, ele achou uma instrução inválida, ele vai escrever no registrador `Cause` um código, por exemplo, 37. Tô chutando aqui, tá? Daí ali, o registrador `Cause` tá dizendo que aconteceu uma instrução inválida. Outra forma é o uso de uma interrupção vetorizada. Nós vamos ver isso aqui agora no próximo slide. O outro requerimento que a gente precisa pra fazer esse tratamento é conhecer o endereço da instrução onde ocorreu a exceção e interrupção. Quer dizer, o programa tava rodando e de repente parou. Ele parou, pode ter sido por um overflow, pode ter acontecido uma instrução inválida ou, por exemplo, um dispositivo ter solicitado a atenção do processador. Então, ele precisa saber qual aquele endereço que ele parou, certo? Então, a gente vai salvar esse endereço em um registrador específico chamado `EPC`. Já que ele vai gravar um endereço, o `EPC`, então Exception Program Counter, certo? Então, é um endereço onde aconteceu a exceção e interrupção. Por que isso? Ah, porque depois que eu fizer o tratamento da exceção e interrupção, pode ser que eu queira continuar executando o meu programa. Certo? Que é o caso, por exemplo, de `ECALL`. Vocês chamam o `ECALL`, ele faz um monte de coisa, e depois ele volta a executar o programa de vocês. Ele tem que saber em qual endereço tava sendo executado o programa de vocês pra ele poder voltar. E, ele tá numa rotina capaz de acessar os recursos que pode não estar disponíveis ao usuário. Tá aqui a rotina de tratamento de exceção. Ou chamado `exception handler`. Que é uma rotina do sistema operacional que faz esse tratamento de todas essas exceções ou interrupções. Ou um conjunto de rotinas. Certo? Então, eu preciso saber essas três coisas aqui. Ok? Preciso conhecer a origem, preciso conhecer onde tava o programa sendo executado, e eu preciso ter uma rotina de tratamento de exceção. Até aí tudo bem? Ok. Então, vamos aprofundar um pouquinho mais. Então, tá aqui. Tratamento de exceção ou interrupção. Aqui tá o programa de vocês sendo executado. E, de repente, apareceu uma exceção ou interrupção aqui. Então, o que vai acontecer? O sistema operacional vai chamar uma rotina de tratamento de exceção. Que é isso aqui. Então, primeira coisa que essa rotina vai ter que fazer é salvar o conteúdo dos registradores na pilha. Salvar o conteúdo de todos os registradores na pilha. Por quê? Porque agora a rotina de tratamento de exceção vai precisar usar esses registradores. Então, depois de salvar tudo na pilha. Identifica a origem do evento. O que é que aconteceu aqui. Obter o endereço da rotina de tratamento de exceção. Dependendo da origem do evento. E executa a rotina de tratamento de exceção. Acabou de executar essa rotina. Restaura o conteúdo dos registradores. E volta a executar o programa de vocês. Fazendo log do erro. Mas essa rotina de tratamento faz mais do que isso. Se por acaso o processador não tiver condições de continuar. Por exemplo, uma instrução inválida. Essa rotina de tratamento de exceção que vai ter que dizer. Olha, não tem condições de continuar. Escreve a tela azul. Certo? Entendido? Tem que fazer isso aqui tudo. Para tratar essa exceção. Ou essa interrupção que aconteceu aqui. Ok. As duas coisas que a gente pode usar para conhecer o fato que gerou a exceção. Seria usar o registrador de `Cause`. Ou a interrupção vetorizada. Vamos ver o que seria o registrador de `Cause`. O registrador de `Cause`. O programa sendo executado. Blá blá blá. E aqui esse `ADD`. Por exemplo, causou o overflow. Por isso que faz. Isso não acontece. Nos outros processadores acontece. Ele causou o overflow. Causou o overflow. Então ele vai colocar, por exemplo, o `Cause` igual a 12. Seria o código do overflow. O registrador `Cause` recebe 12. Vai fazer o `EPC` igual ao `PC`. Para a gente saber qual é o endereço que aconteceu isso. Ele pula para cá. E pula para uma rotina de tratamento de exceção. O `exception handler`. Ele vai executar a rotina de tratamento de exceção. Nessa rotina de tratamento de exceção. Ele vai salvar os registradores. E vai verificar. Com a causa. O que ele deve fazer. Então aconteceu aqui um overflow. Ele vai vir. Se `Cause` igual a 12. Então vai para o `yyyy`. Ele vai executar essa rotina. Que é específico do caso de overflow. E retorna. Ou não. Certo? Quer dizer. Volta lá para cima. Ou não. Vamos supor que ele voltou. Vamos supor que não tinha nada a fazer com o overflow. Tipo o RISC-V. Que não faz nada com o overflow. Ele vai ver. Não precisa fazer nada. É o RISC-V. Nessa rotina `yyyy`. Então. Aconteceu uma interrupção. Um dispositivo externo. Chamou a atenção do processador. Então o que ele vai fazer. Vai colocar o `Cause`. De acordo com o código. Com esses dispositivos externos. A gente tem vários pinos de interrupção. Externos ao processador. E salvar então. `Cause = 0`. Por exemplo, esse código. Fazer o `EPC` igual ao `PC`. E executa essa mesma rotina aqui. Nesse caso. Ele vai chegar nessa linha aqui. Vai verificar se `Cause` é 0. E executa o `xxxx`. Que é esse aqui. Certo? Executou o `xxxx`. Volta. Se precisar voltar. Volta para a próxima instrução. Certo? Entendido isso? Sim. Ótimo. Então esse registrador aqui. Foi a exceção. Qual foi a interrupção. E usa uma só rotina. De tratamento de exceção. Esse é o `exception handler`. Então, dentro do `exception handler`. Ele vai verificar. O que aconteceu. E tomar as atitudes adequadas. Fazer o tratamento. Daquilo que aconteceu. Outra possibilidade. É o uso de interrupção vetorizada. Interrupção vetorizada é o seguinte. A gente tem. Em uma porçãozinha da memória. O que a gente chama de. Vetor de interrupções. Então esse vetor de interrupções. Ele contém diversos endereços. Endereços. De rotinas de tratamento de exceção. Então, nesse vetor aqui. Eu posso ter. Um, dois, três, quatro. Quantas rotinas de tratamento de exceção forem necessárias. Então o que acontece. Eu estou executando meu programa. E nesse `add` aconteceu o overflow. Bom, quando acontece um overflow. O hardware. Ele vai executar. Ok. É overflow. Ele vai executar então o endereço zero. Por exemplo. O que tem nesse primeiro endereço desse vetor. Certo. Então ele vai executar. Essa rotina aqui. Ele vai aqui para o endereço. `0x80000000`. Ele executa a rotina de tratamento do primeiro. Acabou. Retorna. Porque ele tem o `EPC` gravado para retornar. Já. E de repente aqui aconteceu uma interrupção. Interrupção três. Então a interrupção três. Está mapeada para esse endereço aqui. Vamos supor que esse aqui seja overflow. Esse aqui interrupção um. Esse aqui interrupção dois. E esse aqui interrupção três. Está mapeado neste endereço do nosso vetor. Certo. Então o que ele vai fazer. Salvar o `PC`. E executar a rotina que tiver naquele endereço. Depois retorna. Então notem que aqui. Eu faço a escolha. De qual rotina de tratamento eu vou fazer. Indexando este vetor de interrupções. Quer dizer. O hardware tem que fazer isso. Se aconteceu o overflow. Ele tem que vir para esse endereço. Se aconteceu a interrupção três. Aqui. Não. Era a rotina de tratamento de exceção. Que descobriu o que ela tem que fazer. Então se deu `Cause = 0`. Então executa esse aqui. Se deu `Cause = 12`. Então executa esse aqui. Certo. Mas aqui são as mesmas rotinas. Aqui `xxxx`, `yyyy`. O que deveria ter aqui. A `xxxx` deveria ser equivalente a essa. E o `yyyy` deveria ser equivalente a essa. Tipo um `JAL`. Mas através da indexação. De um vetor. Certo. Esse vetor de interrupções. Tem que estar. Inicializado junto com o sistema operacional. Certo. É ele que vai controlar isso aqui. É ele que vai executar essas rotinas. Entendido pessoal. É tipo um `JAL`. Porque salva o `PC`. Então notem ele salva o `PC`. Não o `PC+4`. Se quiser retornar. Para a rotina seguinte ao `ADD`. Tu tem que fazer. Retornar para o endereço. `EPC+4`. Aí sim segue a execução. Se, caso contrário. Tu volta para o mesmo `PC`. E vai dar overflow de novo. Exato. Porque são proibidos. Porque são do sistema operacional. O usuário não pode mexer aqui. A menos que vocês. Estão no sistema operacional. Mas são vocês que vão determinar isso aqui. Certo. Então o que eu quero que vocês tenham claro. Qual é a diferença do uso do registrador de `Cause`. Ao uso de interrupção vetorizada. Tá. Vocês entendendo. Essas diferenças. Tranquilo. O que o RISC-V usa. O RISC-V permite que vocês usem. Qualquer um dos dois. E a gente vai ver depois na implementação. Ok. Em relação a isso aqui. Alguma pergunta. Em relação a interrupção vetorizada. E o registrador de `Cause`. Que a gente está fazendo: conhecer a origem e ter essa rotina aqui. Ficou claro pessoal. Ok. Então vamos entrar um pouquinho. Mais no RISC-V. Quando a gente viu. O ARM. Quando a gente viu o Intel. A gente viu que o ARM tinha (vários) modos de operação: modos de usuário, modos de supervisor. Um monte de modos de operação. Quando era tratada uma interrupção. Chamava determinado modo de interrupção. E tinha aqui todos aqueles 9 modos. De interrupção. No RISC-V. No ARM. O ARM que tem 9 modos de interrupção. Dei uma olhadinha lá. Em outras arquiteturas. No caso do RISC-V. A gente tem somente 3 modos. Modo de usuário. User mode. Que é um modo não privilegiado. Não pode acessar certos endereços de memória. Algumas instruções. Não são permitidas. Certo. Por exemplo. O `RET` e o `EBREAK`. Não. É esse aqui. Quando a gente tem um sistema operacional. Então não é um modo de segurança. Vamos lá. O próximo. Modo supervisor. Quando a gente tem um sistema operacional. Ele pode acessar todas as instruções. Pode acessar todas as instruções. Então por exemplo. O `RET` e o `EBREAK`. E a gente tem o modo de máquina. Ou `Machine Mode`. Que é você programando diretamente. O processador. Sem ter um sistema operacional por baixo. Nesses dois aqui. Eu tenho um sistema operacional por baixo. Esse aqui é o modo de sistema operacional. Que está rodando. E esse aqui é o `Machine Mode`. É aquele que tem acesso a qualquer coisa. Sem nenhuma limitação de acesso. Então vocês podem escrever o seu programinha. Que não vai ter sistema operacional. Para rodar diretamente no processador. Certo. Que é o que a gente faz. Quando a gente executa no `RARS`. Embora o `RARS` tenha um microsistema operacional. Embora o `RARS` tenha um microsistema operacional. Embora o `RARS` tenha um microsistema operacional. A gente permite usar todas as instruções. A gente permite usar todas as instruções. Então a gente tem instruções específicas. Nesse caso. É `WFI`. `WFI` é para colocar. Wait for Interrupt. Não é `Wi-Fi`. Wait for Interrupt. Ele vai colocar o processador em modo de espera. Ele vai colocar o processador em modo de espera. Com baixo consumo de energia. Com baixo consumo de energia. E o processador só acorda. E começa a executar o programa novamente. E começa a executar o programa novamente. Ele recebe uma interrupção. Isso aqui é muito bom para sistemas embarcados. Que tem que controlar alguma coisa. Só com um sensor acionado. É que o programinha vai ser executado. E fazer o que deve fazer. Economizando então bateria. Certo. Esse aqui é o `WFI`. É dentro desse aqui. Eu chamo de `WFI`. Mas é `WFI`. Mas é `WFI`. Então. E para cada um dos modos. Eu também tenho os seus próprios registradores. Eu também tenho os seus próprios registradores. De estado. Então para o modo usuário. Tem o `UCAUSE`. User Cause. `USTATUS`. User `EPC`. User `UIP`. User `USCRATCH`. E todos os registradores. A gente tem todos os outros aqui. Só que começando com S. Certo. E temos também no modo de máquina. Só que começando com M. Vocês estão. Sim. Mas não tem essas instruções aqui no `RARS`. Isso aqui não existe no `RARS`. O `RARS` é um simulador. Então no `RARS`. A gente está sempre utilizando esse modo aqui. A gente não tem. Isso aqui está por baixo do programa de vocês. Para permitir o uso dos registradores de modo usuário (como `UCAUSE`). Ok. Então o que seria cada um desses registradores. Deixa eu fazer uma coisinha rápida aqui.",
        "video_source": "OAC_2022-04-13.mp4"
    },
    {
        "id": 9,
        "timestamp_start": 4215.11,
        "timestamp_end": 4220.5,
        "slide_description": "O slide analisado, parte de uma aula de Arquitetura de Computadores (UnB – CIC0099 – Organização e Arquitetura de Computadores, ministrada pelo Prof. Marcus Vinícius Lamar, do Departamento de Ciência da Computação da Universidade de Brasília), descreve os \"Modos de Operação no RISC-V\". Não há diagramas visíveis (Datapath, Pipeline, Hierarquia de Memória) nesta apresentação. O conteúdo principal do slide é dividido em três modos de operação, cada um detalhando seu nível de privilégio, restrições ou permissões, instruções associadas e registradores de controle e status (CSRs) relevantes:\n\n1.  **Modo Usuário (user mode)**:\n    *   **Descrição**: É o modo menos privilegiado. Aplica restrições significativas de acesso, impedindo o acesso a certos endereços de memória e limitando o uso de algumas instruções. Este modo é tipicamente utilizado por aplicações de usuário em execução sob um Sistema Operacional.\n    *   **Instruções Associadas**: `uret`, `ubreak`.\n    *   **Registradores de Controle e Status (CSRs) Relevantes**: `UCAUSE`, `USTATUS`, `UTVEC`, `UEPC`, `UIP`, `UIE`, `UTVAL`, `USCRATCH`.\n\n2.  **Modo Supervisor (supervisor mode)**:\n    *   **Descrição**: É um modo privilegiado, com mais permissões que o modo usuário. Permite acesso a toda a memória e a um conjunto específico de instruções privilegiadas. Este modo é fundamental para a operação de um Sistema Operacional, que gerencia recursos e processos.\n    *   **Instruções Associadas**: `sret`, `sbreak`.\n    *   **Registradores de Controle e Status (CSRs) Relevantes**: `SCAUSE`, `SSTATUS`, `STVEC`, `SEPC`, `SIP`, `SIE`, `STVAL`, `SSCRATCH`.\n\n3.  **Modo Máquina (machine mode)**:\n    *   **Descrição**: É o modo de operação de maior privilégio no RISC-V, sem nenhuma limitação de acesso a recursos. É o modo fundamental para a inicialização do processador e para o tratamento de interrupções e exceções de baixo nível, frequentemente operando sem a necessidade de um Sistema Operacional completo (ou sendo o ambiente onde o *firmware* inicial e o *bootloader* residem).\n    *   **Instruções Associadas**: `mret`, `mbreak`, `wfi`.\n    *   **Registradores de Controle e Status (CSRs) Relevantes**: `MCAUSE`, `MSTATUS`, `MTVEC`, `MEPC`, `MIP`, `MIE`, `MTVAL`, `MSCRATCH`.\n\nO ambiente geral da imagem sugere uma aula online, com um painel de chat visível à esquerda, onde participantes interagem com mensagens como \"modo de segurança hardcoded?\" e \"machine mode é o que aparece na tela se você liga com um hd formatado?\". O professor está visivelmente presente na parte inferior direita da tela.",
        "transcription": "Deixa eu fazer uma coisinha rápida aqui.",
        "video_source": "OAC_2022-04-13.mp4"
    },
    {
        "id": 10,
        "timestamp_start": 4220.5,
        "timestamp_end": 4241.76,
        "slide_description": "Como Engenheiro de Computação Sênior, analisei o slide e o conteúdo anotado fornecido. A imagem representa uma interface de uma plataforma de webconferência, presumivelmente utilizada para uma aula de Arquitetura de Computadores, dado o título \"Sala de Aula de OAC\".\n\n**1. Transcrição de Texto e Títulos:**\n\n*   **Título Principal da Aula:** \"Sala de Aula de OAC\" (Organização e Arquitetura de Computadores).\n*   **Temporizador da Sessão:** \"70:33\".\n*   **Barra Lateral de Navegação (Menu):**\n    *   \"MENSAGENS\"\n        *   \"Perguntas\"\n        *   \"Bate-papo público\"\n    *   \"NOTAS\"\n        *   \"Notas compartilh...\" (Notas compartilhadas)\n    *   \"USUÁRIOS (10)\"\n*   **Título do Chat:** \"Bate-papo público\".\n*   **Participantes/Membros Visíveis na Lista de Usuários e Chat:**\n    *   Marcus Vinicius Lam... (mencionado no cabeçalho do painel de vídeo e na lista de usuários)\n    *   Eduardo Ferreira Marq...\n    *   Marcello Brandao Scar...\n    *   Gustavo Lopes\n    *   João Alberto Tra\n    *   Maycon Vinnicy...\n    *   Michel Luis Du...\n    *   Victor Hugo Da...\n*   **Conteúdo do Chat (em ordem cronológica):**\n    *   Eduardo Ferreira Marq... (15:05): \"certo\"\n    *   Marcello Brandao Scar... (15:05): \"ok\"\n    *   Marcello Brandao Scar... (15:06): \"acho q tá tranquilo\"\n    *   Marcello Brandao Scar... (15:07): \"modo de segurança hardcoded?\"\n    *   Marcello Brandao Scar... (15:08): \"machine mode é o que aparece na tela se você liga com um hd formatado?\"\n    *   Marcello Brandao Scar... (15:09): \"wifi bom esse\"\n    *   Eduardo Ferreira Marq... (15:10): \"uai fai\" (possível erro de digitação para \"uai, foi\" ou \"uai, vai\")\n    *   Marcello Brandao Scar... (15:10): \"eu posso usar essas instruções de machine mode no rars?\"\n    *   Marcello Brandao Scar... (15:10): \"ok\"\n\n**2. Descrição de Diagramas e Fluxo de Dados:**\n\nA área principal de exibição do conteúdo da aula (o \"slide\") está completamente preta, sem qualquer imagem, diagrama, texto de slide, código (Assembly, C, Verilog), ou outra representação visual. Portanto, não é possível descrever a estrutura ou o fluxo de dados de nenhum diagrama (Datapath, Pipeline, Hierarquia de Memória) com base na imagem fornecida. O foco principal da informação extraível reside nas interações do chat.\n\n**Contexto Técnico Implícito nas Mensagens do Chat:**\n\nEmbora não haja conteúdo visual na área do slide, as mensagens do chat oferecem pistas sobre os tópicos que estão sendo discutidos na aula de Arquitetura de Computadores:\n\n*   **\"modo de segurança hardcoded?\"**: Sugere uma discussão sobre segurança de sistemas, possivelmente no contexto de firmware, BIOS, ou modos de operação de processadores, onde configurações de segurança são gravadas de forma persistente.\n*   **\"machine mode é o que aparece na tela se você liga com um hd formatado?\"**: Esta questão é altamente relevante para Arquitetura de Computadores, especificamente sobre os diferentes modos de operação de um processador (como o \"machine mode\" presente em RISC-V, que é o modo de maior privilégio), o processo de boot (inicialização do sistema), e a interação com dispositivos de armazenamento como HDs formatados. A pergunta implica em uma tentativa de entender o comportamento do sistema em cenários específicos de inicialização e privilégio.\n*   **\"eu posso usar essas instruções de machine mode no rars?\"**: \"RARS\" (RISC-V Assembler and Runtime Simulator) é um simulador popular para arquitetura RISC-V. Esta pergunta indica que a aula está abordando a arquitetura RISC-V e as instruções associadas ao seu \"machine mode\" (que lida com interrupções, exceções, e outras operações privilegiadas), e o aluno busca saber se essas instruções podem ser simuladas ou testadas na ferramenta RARS.\n\nEm suma, a imagem, embora carente de conteúdo visual no \"slide\", revela um ambiente de ensino ativo, com discussões textuais no chat que abordam aspectos avançados e práticos da Arquitetura de Computadores, especificamente relacionados a modos de operação de processadores (provavelmente RISC-V), segurança e simulação de sistemas.",
        "transcription": "É, então. Saí da tela de vocês. Espera aí.",
        "video_source": "OAC_2022-04-13.mp4"
    },
    {
        "id": 11,
        "timestamp_start": 4241.76,
        "timestamp_end": 4243.76,
        "slide_description": "Como um Engenheiro de Computação Sênior, analiso o slide e o contexto da aula de Arquitetura de Computadores.\n\n**Contexto Geral:** A imagem apresenta uma tela de transmissão de uma aula online (\"ConferênciaWeb\") identificada como \"Sala de Aula de OAC\" (Organização e Arquitetura de Computadores), ministrada pelo Departamento de Ciência da Computação da Universidade de Brasília. O professor está visível em vídeo no canto inferior direito.\n\n**Conteúdo Principal (Simulador RARS):**\nO foco principal da tela é o software \"RARS 1.5 Custom 2\", que é um simulador de arquitetura MIPS (MIPS Assembly and Runtime Simulator). A interface do simulador é visível, incluindo:\n1.  **Barra de Menus:** Contém as opções padrão para um ambiente de desenvolvimento ou simulação: \"File\", \"Edit\", \"Run\", \"Settings\", \"Tools\", \"Help\".\n2.  **Barra de Ferramentas:** Uma série de ícones que representam ações comuns (salvar, abrir, copiar, colar, desfazer, refazer, compilar, executar, etc.), com um campo de controle de velocidade de execução marcado como \"Run speed at max (no interaction)\".\n3.  **Área do Editor/Código:** Embora presente, a área principal para edição de código MIPS Assembly está aparentemente vazia ou não visível no detalhe, sugerindo que o foco atual da aula pode estar na visualização do estado da máquina ou de registradores.\n4.  **Painel de Registradores:** No lado direito da tela, está o painel \"Registers\", que exibe o estado dos registradores do processador MIPS. Este painel possui três abas: \"Registers\" (ativa), \"Floating Point\" e \"Control and Status\".\n    *   A aba \"Registers\" exibe os registradores de propósito geral e especiais do MIPS, com as colunas \"Name\", \"Number\" e \"Value\".\n    *   Registradores visíveis e seus valores atuais:\n        *   `zero` (0): 0\n        *   `ra` (1): 2147479548 (Endereço de retorno)\n        *   `sp` (2): 268440224 (Ponteiro de pilha)\n        *   `gp` (3): 0 (Ponteiro global)\n        *   `tp` (4): 0 (Ponteiro de thread)\n        *   `t0` (5): 0 (Registrador temporário)\n        *   `t1` (6): 0 (Registrador temporário)\n        *   `t2` (7): 0 (Registrador temporário)\n        *   `s0` (8): 0 (Registrador salvo)\n        *   `s1` (9): 0 (Registrador salvo)\n        *   `a0` (10): 0 (Registrador de argumento)\n        *   ... (outros registradores `a1` a `a7`, `t3` a `t7`, `s2` a `s7`, `t8`, `t9`, `k0`, `k1`, `gp`, `sp`, `fp`, `ra` seguem listados, a maioria com valor 0, indicando um estado inicial ou pós-reset)\n        *   `pc` (Programa Counter): 4194204 (Contador de programa, indicando o endereço da próxima instrução a ser executada)\n    *   Os valores de `ra`, `sp` e `pc` sendo não-zero sugerem que um programa pode ter sido carregado ou iniciado, estabelecendo um contexto de execução e inicializando a pilha e o fluxo de controle.\n5.  **Painel de Mensagens/I/O:** Na parte inferior, há um painel com abas \"Messages\" e \"Run I/O\", atualmente vazio e com um botão \"Clear\". Este painel seria usado para exibir a saída do programa simulado ou mensagens de erro.\n\n**Conteúdo do Bate-Papo Público:**\nÀ esquerda, há um painel de chat com a seção \"Bate-papo público\", onde alunos e o professor podem interagir. As mensagens relevantes para o conteúdo técnico incluem perguntas do usuário \"Marcello Brandao Scar...\":\n*   \"modo de segurança hardcoded?\" (15:07)\n*   \"machine mode é o que aparece na tela se você liga com um hd formatado?\" (15:08)\n*   \"eu posso usar essas instruções de machine mode no rars?\" (15:10)\n\nEssas perguntas indicam uma discussão sobre conceitos de baixo nível, possivelmente relacionados a modos de operação do processador (e.g., user mode vs. kernel/machine mode, modos privilegiados), inicialização de sistemas, ou instruções específicas que só podem ser executadas em certos modos de operação, com uma clara conexão com o uso do simulador RARS para explorar tais instruções.",
        "transcription": "Ponto.",
        "video_source": "OAC_2022-04-13.mp4"
    },
    {
        "id": 12,
        "timestamp_start": 4243.76,
        "timestamp_end": 4298.76,
        "slide_description": "A tela exibe o slide principal de uma aula de Arquitetura de Computadores, cujo título é \"Modos de Operação no RISC-V\". Este slide é contextualizado como parte da disciplina \"UnB – CIC0099 – Organização e Arquitetura de Computadores\", ministrada pela \"Universidade de Brasília, Departamento de Ciência da Computação\", pelo \"Prof. Marcus Vinicius Lamar\".\n\nEm primeiro plano, sobreposto ao slide, está a interface gráfica do software \"RARS 1.5 Custom 2\", que é um simulador ou ambiente de desenvolvimento para a arquitetura RISC-V. A interface do RARS apresenta:\n1.  **Barra de Menus Superior:** Contém as opções \"File\", \"Edit\", \"Run\", \"Settings\", \"Tools\", e \"Help\".\n2.  **Barra de Ferramentas:** Inclui uma série de ícones para operações comuns como criação, abertura e salvamento de arquivos, ações de edição (desfazer, refazer, recortar, copiar, colar), e controle de execução do simulador (montar, rodar, passo a passo, parar, reiniciar). Há também uma opção \"Run speed at max (no interaction)\".\n3.  **Painel Esquerdo Principal:** Destinado à edição e visualização de código, com abas \"Edit\" e \"Execute\". No momento, esta área está vazia, sem código assembly RISC-V visível.\n4.  **Painel Direito:** Exibe informações de estado do processador simulado, organizado em abas: \"Registers\", \"Floating Point\" e \"Control and Status\". A aba \"Control and Status\" está selecionada e visível.\n\nDentro da aba \"Control and Status\", é apresentada uma tabela listando os Control and Status Registers (CSRs) do RISC-V, com colunas para \"Name\" (Nome), \"Number\" (Número do registrador) e \"Value\" (Valor atual). Os registradores e seus valores visíveis são:\n*   `ustatus` (Número 0): Valor 0\n*   `uflags` (Número 1): Valor 0\n*   `frsp` (Número 2): Valor 0\n*   `fcsr` (Número 3): Valor 0\n*   `uie` (Número 4): Valor 0\n*   `uit` (Número 5): Valor 0\n*   `uscratch` (Número 64): Valor 0\n*   `uepc` (Número 65): Valor 0\n*   `ucause` (Número 66): Valor 0\n*   `utval` (Número 67): Valor 0\n*   `uip` (Número 68): Valor 0\n*   `misa` (Número 769): Valor 1073746216 (representando as extensões da ISA ativas)\n*   `cycle` (Número 3072): Valor 0\n*   `time` (Número 3073): Valor 0\n*   `instret` (Número 3074): Valor 0\n*   `cycleh` (Número 3200): Valor 0\n*   `timeh` (Número 3201): Valor 0\n*   `instreth` (Número 3202): Valor 0\n\nEstes CSRs são fundamentais para gerenciar interrupções, exceções, contadores de desempenho e o estado geral de operação em diferentes níveis de privilégio (especialmente o modo de usuário 'U' e, por inferência do `misa`, o modo de máquina 'M').\n\nO painel de chat lateral da conferência online inclui perguntas relevantes que contextualizam o foco da aula nos modos de operação, tais como: \"modo de segurança hardcoded?\", \"machine mode é o que aparece na tela se você liga com um hd formatado?\" e \"eu posso usar essas instruções de machine mode no rars?\". Essas questões demonstram um interesse dos alunos nas características do \"machine mode\" do RISC-V e na capacidade do simulador RARS de emular e permitir a execução de instruções e cenários associados a esse modo de maior privilégio.",
        "transcription": "É isso aí. Então, o que são esses registradores que eu acabei de falar? Esses aqui: o `uip`, o `uepc`, o `uie`, o `utval` e o `uscratch`. São esses registradores aqui de controle e status. Então aqui a gente tem o `ustatus`, o `uie`, o `uip`, o `uscratch`, o `uepc`, o `ucause` e o `utval`. Certo. Então, agora a gente vai apresentar esses outros registradores aqui de controle e status que estavam faltando.",
        "video_source": "OAC_2022-04-13.mp4"
    },
    {
        "id": 13,
        "timestamp_start": 4298.76,
        "timestamp_end": 4310.76,
        "slide_description": "Como Engenheiro de Computação Sênior, procedo à análise do slide apresentado, extraindo as informações técnicas para um sistema de busca semântica (RAG).\n\nO slide intitula-se \"Exceções e Interrupções no RISC-V\", inserido no contexto da disciplina \"Organização e Arquitetura de Computadores\" (código CIC0099) da Universidade de Brasília (UnB), Departamento de Ciência da Computação, ministrada pelo Prof. Marcus Vinicius Lamar.\n\nO conteúdo principal do slide foca nos **Control and Status Registers (CSR)** do RISC-V, que são registradores especiais usados para gerenciar exceções, interrupções, memória, virtualização e outras funcionalidades essenciais nos três modos de operação (User, Supervisor, Machine). É explicitado que existe um espaço de 2^12, totalizando 4096 registradores CSR dedicados a essas funções.\n\nPara o contexto prático da aula, é mencionado que no simulador Rars, onde há um sistema operacional mínimo, o modo User será empregado. Similarmente, em ambientes de laboratório sem um sistema operacional completo (como no Lab), o modo User também será utilizado para manter compatibilidade com o Rars.\n\nO slide apresenta uma tabela detalhada intitulada \"Table 2.1: Allocation of RISC-V CSR address ranges.\" Esta tabela descreve a alocação de endereços e a acessibilidade dos CSRs, categorizados pelos modos de operação:\n\n1.  **CSR Address:** Dividido em bits [11:10], [9:8], e [7:6] para formar o endereço.\n2.  **Hex:** O intervalo de endereços em formato hexadecimal.\n3.  **Use and Accessibility:** Descreve a finalidade e as permissões de acesso (leitura/escrita, somente leitura, padrão, não-padrão, modo debug).\n\n**Conteúdo da Tabela:**\n\n*   **User CSRs:**\n    *   **00 [11:10], 00 [9:8], XX [7:6]:** Endereços de `0x000` a `0x0FF`, com acesso \"Standard read/write\".\n    *   **00 [11:10], 01 [9:8], XX [7:6]:** Endereços de `0x400` a `0x4FF`, com acesso \"Standard read/write\".\n    *   **00 [11:10], 10 [9:8], XX [7:6]:** Endereços de `0x800` a `0x8FF`, com acesso \"Non-standard read/write\".\n    *   **00 [11:10], 11 [9:8], 00-10 [7:6]:** Endereços de `0xC00` a `0xCBF`, com acesso \"Standard read-only\".\n    *   **00 [11:10], 11 [9:8], 00-11 [7:6]:** Endereços de `0xC00` a `0xCFF`, com acesso \"Non-standard read-only\".\n\n*   **Supervisor CSRs:**\n    *   **01 [11:10], 00 [9:8], XX [7:6]:** Endereços de `0x100` a `0x1FF`, com acesso \"Standard read/write\".\n    *   **01 [11:10], 01 [9:8], 00-10 [7:6]:** Endereços de `0x500` a `0x5BF`, com acesso \"Standard read/write\".\n    *   **01 [11:10], 01 [9:8], 11 [7:6]:** Endereços de `0x500` a `0x5FF`, com acesso \"Non-standard read/write\".\n    *   **01 [11:10], 10 [9:8], 01 [7:6]:** Endereços de `0x900` a `0x9BF`, com acesso \"Standard read/write\".\n    *   **01 [11:10], 10 [9:8], 10 [7:6]:** Endereços de `0x900` a `0x9FF`, com acesso \"Non-standard read/write\".\n    *   **01 [11:10], 11 [9:8], 01 [7:6]:** Endereços de `0xD00` a `0xDBF`, com acesso \"Standard read-only\".\n    *   **01 [11:10], 11 [9:8], 11 [7:6]:** Endereços de `0xD00` a `0xDFF`, com acesso \"Non-standard read-only\".\n\n*   **Reserved:** (Uma linha indica um espaço reservado com XX, 10, XX, sem especificar o range Hex visível completamente na imagem cortada para Supervisor CSRs)\n\n*   **Machine CSRs:**\n    *   **00 [11:10], 11 [9:8], XX [7:6]:** Endereços de `0x300` a `0x3FF`, com acesso \"Standard read/write\".\n    *   **01 [11:10], 11 [9:8], 00-10 [7:6]:** Endereços de `0x700` a `0x79F`, com acesso \"Standard read/write\".\n    *   **01 [11:10], 11 [9:8], 10 [7:6]:** Endereços de `0x7A0` a `0x7AF`, com acesso \"Debug-mode read/write\".\n    *   **01 [11:10], 11 [9:8], 11 [7:6]:** Endereços de `0x7B0` a `0x7BF`, com acesso \"Debug-mode only CSRs\".\n    *   **10 [11:10], 11 [9:8], XX [7:6]:** Endereços de `0x7C0` a `0x7FF`, com acesso \"Non-standard read/write\".\n    *   **10 [11:10], 11 [9:8], 00-10 [7:6]:** Endereços de `0xB00` a `0xBBF`, com acesso \"Standard read/write\".\n    *   **10 [11:10], 11 [9:8], 00-11 [7:6]:** Endereços de `0xB00` a `0xBFF`, com acesso \"Non-standard read/write\".\n    *   **11 [11:10], 11 [9:8], 00-10 [7:6]:** Endereços de `0xF00` a `0xFBF`, com acesso \"Standard read-only\".\n    *   **11 [11:10], 11 [9:8], 00-11 [7:6]:** Endereços de `0xF00` a `0xFFF`, com acesso \"Non-standard read-only\".\n\nEsta descrição abrange o conteúdo técnico do slide, fornecendo uma base sólida para indexação em um sistema de busca semântica focado em arquitetura RISC-V e gerenciamento de exceções/interrupções.",
        "transcription": "Bom. Então, esses registradores compõem o banco de registradores de controle e status, os Control and Status Registers (CSRs). Essa coisinha que eu acabei de mostrar para vocês aqui.",
        "video_source": "OAC_2022-04-13.mp4"
    },
    {
        "id": 14,
        "timestamp_start": 4310.76,
        "timestamp_end": 4332.76,
        "slide_description": "Atuando como um Engenheiro de Computação Sênior, procedo à análise do slide apresentado, extraindo e descrevendo seu conteúdo para um sistema de busca semântica (RAG).\n\nO slide é intitulado **\"Exceções e Interrupções no RISC-V\"**. No canto superior direito, são visíveis informações institucionais: **\"UnB - CIC0099 - Organização e Arquitetura de Computadores\"**, com um subtítulo mencionando **\"Universidade de Brasília\", \"Departamento de Ciência da Computação\"** e o nome do professor **\"Prof. Marcus Vinicius Lamar\"**.\n\nO conteúdo textual principal do slide foca nos **\"Control and Status Registers (CSR)\"**. É descrito que os CSRs compreendem um **\"Espaço de 2^12 = 4096 registradores dedicados às funções gerenciamento de exceções/interrupções, gerenciamento da memória, virtualização e outras atividades nos 3 modos de operação.\"**\nComplementarmente, são fornecidas duas notas contextuais sobre a utilização desses modos:\n1.  **\"No Rars há um sistema operacional mínimo logo usaremos o modo User.\"**\n2.  **\"No Lab não há um sistema operacional, mas continuaremos usando o modo User para fins de compatibilidade com o Rars\"**\n\nAo lado, há uma tabela detalhada com o título **\"Table 2.1: Allocation of RISC-V CSR address ranges.\"** Esta tabela descreve a alocação de registradores CSR, segmentando-os por modos de operação e suas características de acesso. As colunas da tabela são:\n*   **\"CSR Address\"**, subdividido em bits `[11:10]`, `[9:8]` e `[7:6]`.\n*   **\"Hex\"**, indicando o range de endereços hexadecimais.\n*   **\"Use and Accessibility\"**, descrevendo a finalidade e permissões de acesso.\n\nA tabela é estruturada em seções para diferentes tipos de CSRs:\n\n**1. User CSRs:**\n*   `[11:10]`=00, `[9:8]`=00, `[7:6]`=XX: Endereço Hex: `0x000-0x0FF`, Uso: Standard read/write\n*   `[11:10]`=00, `[9:8]`=01, `[7:6]`=XX: Endereço Hex: `0x400-0x4FF`, Uso: Standard read/write\n*   `[11:10]`=00, `[9:8]`=10, `[7:6]`=XX: Endereço Hex: `0x800-0x8FF`, Uso: Non-standard read/write\n*   `[11:10]`=00, `[9:8]`=11, `[7:6]`=00-10: Endereço Hex: `0xC00-0xCBF`, Uso: Standard read-only\n*   `[11:10]`=00, `[9:8]`=11, `[7:6]`=11: Endereço Hex: `0xC00-0xCFF`, Uso: Non-standard read-only\n\n**2. Supervisor CSRs:**\n*   `[11:10]`=00, `[9:8]`=01, `[7:6]`=XX: Endereço Hex: `0x100-0x1FF`, Uso: Standard read/write\n*   `[11:10]`=00, `[9:8]`=11, `[7:6]`=00-10: Endereço Hex: `0x500-0x5BF`, Uso: Standard read/write\n*   `[11:10]`=01, `[9:8]`=01, `[7:6]`=11: Endereço Hex: `0x600-0x6FF`, Uso: Non-standard read/write\n*   `[11:10]`=10, `[9:8]`=01, `[7:6]`=00-10: Endereço Hex: `0x900-0x9BF`, Uso: Standard read/write\n*   `[11:10]`=10, `[9:8]`=01, `[7:6]`=11: Endereço Hex: `0x9C0-0x9FF`, Uso: Non-standard read-only\n*   `[11:10]`=11, `[9:8]`=01, `[7:6]`=00-10: Endereço Hex: `0xD00-0xDBF`, Uso: Standard read-only\n*   `[11:10]`=11, `[9:8]`=01, `[7:6]`=11: Endereço Hex: `0xDC0-0xDFF`, Uso: Non-standard read-only\n\n**3. Reserved** (Esta seção indica um bloco de endereços reservados, sem entradas específicas listadas além do cabeçalho).\n\n**4. Machine CSRs:**\n*   `[11:10]`=00, `[9:8]`=11, `[7:6]`=XX: Endereço Hex: `0x300-0x3FF`, Uso: Standard read/write\n*   `[11:10]`=01, `[9:8]`=01, `[7:6]`=11: Endereço Hex: `0x700-0x79F`, Uso: Standard read/write\n*   `[11:10]`=01, `[9:8]`=10, `[7:6]`=00: Endereço Hex: `0x7A0-0x7AF`, Uso: Standard read/write debug CSRs\n*   `[11:10]`=01, `[9:8]`=10, `[7:6]`=11: Endereço Hex: `0x7B0-0x7BF`, Uso: Debug-mode-only CSRs\n*   `[11:10]`=01, `[9:8]`=11, `[7:6]`=XX: Endereço Hex: `0x7C0-0x7FF`, Uso: Non-standard read/write\n*   `[11:10]`=10, `[9:8]`=11, `[7:6]`=00-10: Endereço Hex: `0xB00-0xBBF`, Uso: Standard read/write\n*   `[11:10]`=10, `[9:8]`=11, `[7:6]`=11: Endereço Hex: `0xBC0-0xBFF`, Uso: Non-standard read/write\n*   `[11:10]`=11, `[9:8]`=11, `[7:6]`=00-10: Endereço Hex: `0xF00-0xFBF`, Uso: Standard read-only\n*   `[11:10]`=11, `[9:8]`=11, `[7:6]`=11: Endereço Hex: `0xFC0-0xFFF`, Uso: Non-standard read-only\n\nEsta descrição abrange o título do slide, os dados do curso, a definição e o escopo dos Control and Status Registers (CSRs) no contexto RISC-V, e uma transcrição detalhada da tabela de alocação de endereços dos CSRs, incluindo seus ranges hexadecimais e características de acesso para os modos User, Supervisor e Machine.",
        "transcription": "Essa numeração que eu acabei de mostrar para vocês aqui. Esse é o endereço do registrador. De cara, vocês veem que esses registradores aqui têm um endereço que é um número bem maior do que os 32 que geralmente a gente usa. Por quê? Porque no RISC-V, as instruções... Deixa eu pegar aqui o nosso diagrama de instruções.",
        "video_source": "OAC_2022-04-13.mp4"
    },
    {
        "id": 15,
        "timestamp_start": 4343.17,
        "timestamp_end": 4492.34,
        "slide_description": "O slide principal exibe um documento PDF intitulado \"RISC-V Reference-Guide_v23.pdf\", exibido na página 1 de 2, com zoom de 200%. Este documento apresenta uma tabela detalhada de instruções do conjunto RISC-V, com colunas para \"Instruction\", \"Type\", \"Description\", \"Operands\", \"Functional Description\", campos de opcode/funct e referências de página.\n\nAs instruções RISC-V visíveis na tabela incluem:\n\n1.  **Instruções de Branch:**\n    *   `bge` (B-type): \"Branch Greater or Equal\". Descrição funcional: `if(R[rs1] >= R[rs2]) PC=PC+(imm,1'b0)`. Opcode: `1100011`, Funct3: `101`. Página: `63/5`.\n    *   `bgeu` (B-type): \"Branch Greater or Equal Unsigned\". Descrição funcional: `if(R[rs1] >= R[rs2]) PC=PC+(imm,1'b0)`. Opcode: `1100011`, Funct3: `111`. Página: `63/6`.\n\n2.  **Instruções de Salto:**\n    *   `jalr` (I-type): \"Jump & Link Register\". Descrição funcional: `R[rd]=PC+4; PC=(R[rs1]+imm)&(!1)`. Opcode: `1100111`, Funct3: `000`. Página: `67/0`.\n\n3.  **Instruções de Sistema/Controle:**\n    *   `ecall` (I-type): \"Environment CALL\". Descrição: \"Transfer control to environment system\". Opcode: `1110011`, Funct3: `000`, Funct7/CSR: `000000 000000`. Página: `73/0`.\n    *   `csrrw` (I-type): \"CSR Read & Write\". Descrição funcional: `R[rd]=C[CSR]; C[CSR]=R[rs1]`. Opcode: `1110011`, Funct3: `001`. Página: `73/1`.\n    *   `csrrs` (I-type): \"CSR Read & Set\". Descrição funcional: `R[rd]=C[CSR]; C[CSR]=C[CSR]|R[rs1]`. Opcode: `1110011`, Funct3: `010`. Página: `73/2`.\n    *   `csrrc` (I-type): \"CSR Read & Clear\". Descrição funcional: `R[rd]=C[CSR]; C[CSR]=C[CSR]&!R[rs1]`. Opcode: `1110011`, Funct3: `011`. Página: `73/3`.\n    *   `csrrwi` (I-type): \"CSR Read & Write Immediate\". Descrição funcional: `R[rd]=C[CSR]; C[CSR]=imm`. Opcode: `1110011`, Funct3: `101`. Página: `73/5`.\n    *   `csrrsi` (I-type): \"CSR Read & Set Immediate\". Descrição funcional: `R[rd]=C[CSR]; C[CSR]=C[CSR]|imm`. Opcode: `1110011`, Funct3: `110`. Página: `73/6`.\n    *   `csrrci` (I-type): \"CSR Read & Clear Immediate\". Descrição funcional: `R[rd]=C[CSR]; C[CSR]=C[CSR]&!imm`. Opcode: `1110011`, Funct3: `111`. Página: `73/7`.\n\n4.  **Instruções de Multiplicação (Extensão M):**\n    *   `mul` (R-type): \"Multiply\". Descrição funcional: `R[rd]=R[rs1]*R[rs2](31:0)`. Opcode: `0110011`, Funct3: `000`, Funct7: `0000001`. Página: `33/0/01`.\n    *   `mulh` (R-type): \"Multiply upper Half\". Descrição funcional: `R[rd]=R[rs1]*R[rs2](63:32)`. Opcode: `0110011`, Funct3: `001`, Funct7: `0000001`. Página: `33/1/01`.\n    *   `mulhsu` (R-type): \"Multiply upper Half Signed/Unsigned\". Descrição funcional: `R[rd]=R[rs1]*R[rs2](63:32)`. Opcode: `0110011`, Funct3: `010`, Funct7: `0000001`. Página: `33/2/01`.\n    *   `mulhu` (R-type): \"Multiply upper Half Unsigned\". Descrição funcional: `R[rd]=R[rs1]*R[rs2](63:32)`. Opcode: `0110011`, Funct3: `011`, Funct7: `0000001`. Página: `33/3/01`.\n\n5.  **Instruções de Divisão (Extensão M):**\n    *   `div` (R-type): \"Divide\". Descrição funcional: `R[rd]=R[rs1]/R[rs2]`. Opcode: `0110011`, Funct3: `100`, Funct7: `0000001`. Página: `33/4/01`.\n    *   `divu` (R-type): \"Divide Unsigned\". Descrição funcional: `R[rd]=R[rs1]/R[rs2]`. Opcode: `0110011`, Funct3: `101`, Funct7: `0000001`. Página: `33/5/01`.\n\n6.  **Instruções de Resto (Extensão M):**\n    *   `rem` (R-type): \"Remainder\". Descrição funcional: `R[rd]=R[rs1]%R[rs2]`. Opcode: `0110011`, Funct3: `110`, Funct7: `0000001`. Página: `33/6/01`.\n    *   `remu` (R-type): \"Remainder Unsigned\". Descrição funcional: `R[rd]=R[rs1]%R[rs2]`. Opcode: `0110011`, Funct3: `111`, Funct7: `0000001`. Página: `33/7/01`.\n\n7.  **Instruções de Ponto Flutuante (Extensão F - Single-Precision):**\n    *   `fadd.s` (R-type): \"Float Point Add\". Descrição funcional: `F[rd]=F[rs1]+F[rs2]`. Opcode: `1010011`, Funct3: `000`, Funct7: `0000000`. Página: `53/RM/00`.\n    *   `fclass.s` (R-type): \"Classify type\". Descrição funcional: `R[rd]=class(F[rs1])`. Opcode: `1010011`, Funct3: `001`, Funct7: `0000000`. Página: `53/E0/00`.\n    *   `fcvt.s.w` (R-type): \"Convert from Integer\". Descrição funcional: `F[rd]=float(R[rs1])`. Opcode: `1010011`, Funct3: `000`. Página: `53/RM/D0`.\n    *   `fcvt.s.wu` (R-type): \"Convert from Unsigned Integer\". Descrição funcional: `F[rd]=float(R[rs1])`. Opcode: `1010011`, Funct3: `001`. Página: `53/RM/D0`.\n    *   `fcvt.w.s` (R-type): \"Convert to Integer\". Descrição funcional: `R[rd]=integer(F[rs1])`. Opcode: `1010011`, Funct3: `000`. Página: `53/RM/C0`.\n    *   `fcvt.wu.s` (R-type): \"Convert to Unsigned Integer\". Descrição funcional: `R[rd]=integer(F[rs1])`. Opcode: `1010011`, Funct3: `001`. Página: `53/RM/C0`.\n    *   `fdiv.s` (R-type): \"Float Point Divide\". Descrição funcional: `F[rd]=F[rs1]/F[rs2]`. Opcode: `1010011`, Funct3: `010`. Página: `53/RM/0C`.\n    *   `feq.s` (R-type): \"Compare Float Equal\". Descrição funcional: `R[rd]=(F[rs1]==F[rs2])?1:0`. Opcode: `1010011`, Funct3: `000`. Página: `53/RM/A0`.\n\nO contexto da aula é \"Arquitetura de Computadores\", conforme indicado pelo título \"Sala de Aula de OAC\" (Organização e Arquitetura de Computadores) e o professor \"Prof. Marcus Vinicius Lamar\", da Universidade de Brasília, Departamento de Ciência da Computação. Um contador de tempo \"73:40\" sugere a duração da aula ou o tempo restante.\n\nHá um painel lateral de chat com mensagens de alunos. Perguntas relevantes para o conteúdo incluem:\n*   \"modo de segurança hardcoded?\" (Marcello Brandao Scar...)\n*   \"machine mode é o que aparece na tela se você liga com um hd formatado?\" (Marcello Brandao Scar...)\n*   \"eu posso usar essas instruções de machine mode no rars?\" (Marcello Brandao Scar...)\nEssas perguntas indicam que o professor pode estar discutindo tópicos relacionados a modos de operação da CPU (como \"machine mode\" em RISC-V, que é o modo de maior privilégio) e a emuladores ou simuladores de RISC-V (como RARS, RISC-V Assembler and Runtime Simulator). As instruções `ecall` e as operações `CSR` (Control and Status Register) na tabela são diretamente relacionadas ao controle de ambiente e aos modos de privilégio, o que alinha-se com as perguntas dos alunos sobre \"machine mode\" e \"segurança hardcoded\". O professor aparece gesticulando em direção à tela, presumivelmente explicando o conteúdo da tabela.",
        "transcription": "As instruções de controle de status, certo, elas sempre vão ter esse imediato. Certo. Eu posso usar como esse número imediato ou eu posso usar o próprio registrador. Mas o CSR aqui é um registrador de controle de status. E esse CSR é um registrador, é um campo de 12 bits na minha instrução, certo? Então, através dessas instruções aqui é que eu vou ler os registradores de controle. Então, o `CSRRW` o que ele vai fazer — tá pequeno isso aí, vocês não estão conseguindo ver? Melhorou? Então, o `CSRRW` ele vai ler o conteúdo do registrador de controle do número que eu coloquei aqui de CSR e vai ler isso para o registrador de destino, para esse registrador de destino, e vai escrever no registrador CSR o que eu tiver em `RS1`. Então, ele lê o valor do registrador e escreve o conteúdo desse registrador no CSR, OK? Então, `CSRRW` (Read Write), `CSRRS` (Read Set), `CSRRC` (Read Clear), `CSRRWI` (Read Write Immediate), `CSRRSI` (Read Set Immediate), `CSRRCI` (Read Clear Immediate). Certo? Então, essas aqui são as nossas instruções de registradores CSR. Isso aqui é um campo de 12 bits. Então, se o campo de seleção do registrador é de 12 bits, quantos registradores eu posso ter? Se esse campo aqui CSR é de 12 bits. Por que de 12 bits? Porque todas elas são do tipo I e o imediato do tipo I é de 12 bits. Certo? Então, ele pode ler do endereço do registrador 0 até o registrador 4095. Então, eu tenho 4 KB de registradores. Certo? 4095 registradores. Certo?",
        "video_source": "OAC_2022-04-13.mp4"
    },
    {
        "id": 16,
        "timestamp_start": 4492.34,
        "timestamp_end": 7032.28,
        "slide_description": "O slide apresenta o tema \"Exceções e Interrupções no RISC-V\", enquadrado no contexto da disciplina \"UnB – CIC0099 – Organização e Arquitetura de Computadores\", ministrada pelo Prof. Marcus Vinicius Lamar do Departamento de Ciência da Computação da Universidade de Brasília.\n\nO conteúdo principal do slide é dividido em duas seções: uma descrição textual à esquerda e uma tabela detalhada à direita, ambas focando na codificação do registrador de causa de armadilhas (traps).\n\n**Seção Esquerda - Codificação do Registrador de Causa:**\nEsta seção descreve a interpretação do bit mais significativo (bit 31) do registrador `ucause` (ou `mcause` no modo máquina, inferindo pelo título da tabela).\n*   É explicitado que \"Se bit ucause[31]=1 é uma interrupção\", indicando que o conjunto de eventos de interrupção é distinguido por este bit.\n*   Similarmente, \"Se bit ucause[31]=0 é uma exceção\", definindo que o conjunto de eventos de exceção é caracterizado por este bit ser zero.\n\n**Seção Direita - Tabela \"Table 3.6: Machine cause register (mcause) values after trap.\":**\nEsta tabela cataloga os valores possíveis para o campo `Exception Code` (também conhecido como `mcause[30:0]` quando `mcause[31]` é considerado) e a correspondente descrição do evento que causou a armadilha. A coluna \"Interrupt\" da tabela indica se o bit 31 do registrador `mcause` está setado (1 para interrupções) ou não (0 para exceções).\n\n**Eventos de Interrupção (`mcause[31]=1`, coluna \"Interrupt\" = 1):**\n*   **0:** User software interrupt (Interrupção de software de usuário)\n*   **1:** Supervisor software interrupt (Interrupção de software de supervisor)\n*   **2:** Reserved (Reservado)\n*   **3:** Machine software interrupt (Interrupção de software de máquina)\n*   **4:** User timer interrupt (Interrupção de temporizador de usuário)\n*   **5:** Supervisor timer interrupt (Interrupção de temporizador de supervisor)\n*   **6:** Reserved (Reservado)\n*   **7:** Machine timer interrupt (Interrupção de temporizador de máquina)\n*   **8:** User external interrupt (Interrupção externa de usuário)\n*   **9:** Supervisor external interrupt (Interrupção externa de supervisor)\n*   **10:** Reserved (Reservado)\n*   **11:** Machine external interrupt (Interrupção externa de máquina)\n*   **≥12:** Reserved (Reservado para códigos de interrupção maiores ou iguais a 12)\n\n**Eventos de Exceção (`mcause[31]=0`, coluna \"Interrupt\" = 0):**\n*   **0:** Instruction address misaligned (Endereço de instrução desalinhado)\n*   **1:** Instruction access fault (Falha de acesso à instrução)\n*   **2:** Illegal instruction (Instrução ilegal)\n*   **3:** Breakpoint (Ponto de interrupção)\n*   **4:** Load address misaligned (Endereço de carga desalinhado)\n*   **5:** Load access fault (Falha de acesso de carga)\n*   **6:** Store/AMO address misaligned (Endereço de armazenamento/AMO desalinhado)\n*   **7:** Store/AMO access fault (Falha de acesso de armazenamento/AMO)\n*   **8:** Environment call from U-mode (Chamada de ambiente do modo U)\n*   **9:** Environment call from S-mode (Chamada de ambiente do modo S)\n*   **10:** Reserved (Reservado)\n*   **11:** Environment call from M-mode (Chamada de ambiente do modo M)\n*   **12:** Instruction page fault (Falha de página de instrução)\n*   **13:** Load page fault (Falha de página de carga)\n*   **14:** Reserved (Reservado)\n*   **15:** Store/AMO page fault (Falha de página de armazenamento/AMO)\n*   **≥16:** Reserved (Reservado para códigos de exceção maiores ou iguais a 16)\n\nO slide não contém diagramas de fluxo de dados, pipelines ou hierarquia de memória, focando exclusivamente na taxonomia e codificação dos eventos que disparam armadilhas (traps) no processador RISC-V, distinguindo entre interrupções assíncronas e exceções síncronas.",
        "transcription": "Então, o espaço 202 da 4096. Registradores dedicados à função de gerenciamento. Gerenciamento da memória, virtualização e outras atividades. Nos três modos de operação. Então, são aqueles registradores que a gente quer acessar. Então, esse aqui é o endereço do CSR. Quantos bits? Quantos bits tem aqui? E aqui. Tá, então. Eu tenho aqui seis bits. Certo? Então, com isso, eu consigo. Isso aqui é User CSR, Supervisor CSR, Reservado, Machine. Aí, que eu tô. Tem uma coisa aqui. Eu tenho 12, 4312. Então, do endereço 000 até o 00FF. Tá? Vai ser também nessa parte aqui, Standard. Certo? Para coisas mais avançadas. Nesse aqui é o read-only, não standard. Para que eles estão usando isso? Tá. Então, eu tenho uma área para os registradores de usuário. Outra área para os registradores de supervisor. Uma área reservada para futuros usos. E uma área para os registradores no modo Machine. Ok. Então, tem um sistema operacional mínimo. Então, todos eles vão usar o modo User para ser utilizado. No caso, vocês que construíram o processador RISC-V. Não tem sistema operacional. Então, nesse caso, vocês iriam utilizar as instruções no modo User. Ok. Para ficar compatível com o RARS. Por que eu ponho isso aqui? Porque quando for em FPGA, está tudo implementado. Então, o nosso processador em FPGA está tudo implementado. E quem implementou foram os alunos. Ok. Então, vamos abrir esse nosso modo. Certo? Vamos abrir ele. Então, está aqui. Então, o modo User. Eu tenho aqui meus registradores. O número dos registradores. Aqui, qual é o privilégio. Vou escrever, somente ler. E aqui estão os nossos registradores. Então, o `ustatus`, o `uie`, o `utvec`, o `uscratch`, o `uepc` e o `ucause`. E o `utvec` e o `uip`. E aqui os de ponto flutuante. Certo? Estes são os contadores. E aqui o `cycle`, que é o que vocês implementaram. Estes registradores de 32 bits. Aqui não é só o `cycle`. Certo? Ótimo. Porque é só isso aqui que a gente vai precisar só ler. A gente nunca vai precisar escrever nele. Então, isso serve só para monitoramento. Para o nosso monitoramento. Para o usuário externo. Por isso que eu... Não dá para eu trazer esses três aí? Porque o `cycle`... Não. Não. Não. Não. É que... É que o Marcelo falou só os três primeiros. Achei que tinha mais para fazer. Não. É só esses aqui. Pelo menos no `cycle` é fácil aqui. O `instret` é o mesmo que o do `cycle`. É. Mas no multiciclo não vai bugar em mim, não. Então, tem que cuidar disso. É. Ok. Certo? Então, todos os registradores que a gente precisa estão mapeados aqui. No caso do RARS a gente vai usar só esses aqui. Tá. Tam tam tam. E aqui estão as instruções. `CSRRC` (Read Clear). `CSRRCI` (Read Clear Imediato). `CSRRS` (Read Set). `CSRRSI` (Read Set Imediato). `CSRRW` (Read Write). `CSRRWI` (Read Write Imediato). Beleza? Então, como a gente não criou essas instruções no processador de vocês, então, a gente não tem como ler esses registradores que vocês colocaram a mais. Certo? O `cycle` e o `instret`. Certo? A gente não implementou isso aqui. Então, é só para a gente monitorar mesmo. Ver lá qual é o resultado que dá. Ok. Codificação dos registradores de causa. Codificação dos registradores de causa. Então, o RISC-V permite a gente utilizar os registradores de causa. Então, o RISC-V permite a gente utilizar os registradores de causa e as interrupções. E as interrupções. No caso, se o bit `mcause[31]` for 1, é porque são interrupções. E se o bit `mcause[31]` for 0, é porque é usado nos registradores de causa. Certo? Então, no nosso caso aqui, a gente vai usar esses nove códigos de... A gente vai usar esses nove códigos de... De... De exceções e interrupções. Então, se o bit `mcause[31]` for 1, é uma interrupção. Se o bit `mcause[31]` for 0, é uma exceção. Então, se o bit `mcause[31]` for 1, é uma interrupção. Esse aqui é o conteúdo do registrador de causa. Esse aqui é o conteúdo do registrador de causa. Que é esse aqui. Que é esse aqui. Certo? Então, os códigos que a gente tem, é 0. É 0. Uma interrupção. Instruction address misaligned. Quer dizer, o usuário está tentando ler uma instrução de um endereço da memória que está desalinhado. Quer dizer, os dois últimos bits não são 0. Então, isso causa um problema. Certo? Aciona essa causa aqui. Instruction access fault. Que significa isso? Que eu optei de ler da memória de instruções uma instrução e deu problema. Eu não consegui ler da memória. Pode acontecer? Pode. A memória pode ter sido danificada, por exemplo, ou o barramento, e não consegui ler para gerar essa causa 1. Ah, eu li a instrução, mas eu não reconheço ela. Eu não conheço esse opcode 43, 47. Então, eu vou dar uma instrução ilegal. Que é o código 2. Breakpoint. É aquela instrução `ebreak`. Código 3. Load address misaligned. Quer dizer, eu tentei acessar a memória de dados com um endereço que não estava alinhado, que não terminava com 2, que não era múltiplo de 4. E aí vai dar, então, esse aqui. Posso ter o Store desalinhado. E daí dá esse erro aqui. Eu posso ter um Load fault, que significa o quê? Eu tentei ler um dado e não consegui, devido a algum problema técnico, por exemplo. Certo? Então, ele vai dar esse código no registrador de causa. Ah, eu tentei gravar na memória e não consegui. A memória disse que não conseguiu gravar nisso aqui. Então, eu tenho esse código 7. E esse aqui, Environment Call, significa o `ecall`, né? Então, a instrução `ecall` é, precisamente, eu gerar uma exceção de código. Certo? Então, aqui está codificado as exceções e interrupções que o... Não, só as exceções. As interrupções estão aqui em cima. Tá? Que o RISC-V detecta. Qual o erro não previsto? Exatamente. Ele não foi previsto. Olha, eu não queria ver. Eu tentava ver tudo, tá? O que seria um erro não previsto? Ah, sei lá. Do nada, o registrador A1 troca com A0. Daí, o processador nunca vai saber disso, tá? Porque eu não verifico essa condição, tá? Do banco de registradores. O RISC-V não verifica o banco de registradores. Então, não tem como ele detectar esse problema. Entendeu? Então, se der problema, assim que eu digo, né? Vai dar um erro não previsto, né? Porque você está fazendo cálculo e aparece uma coisa errada. Aí, se não há um erro que... Como é que tu sabe que deu uma coisa errada? É, você testa. Desculpa falar. Você está testando e dá uma... Que não está nessas expressões. Aí, ele só vai ignorar, né? Não. Não vai, tá? Porque ele não vai detectar. Se o processador não é capaz... O processador, não o programador. O processador não é capaz de detectar. Não entra aqui. O processador, por si só, tem que ser capaz de detectar isso. Entendeu? Então, se... Ah, eu escrevi no banco de registradores, no registrador 1, eu escrevi 10. E depois eu fui ler logo em seguida do registrador 1 e deu 100. Opa, tem um erro aí. Mas quem detecta esse erro é o programador. Aí, o projetista do processador tem que ver o que é a origem desse erro e tem que encerrar. Porque, a princípio, isso não deveria ser erro. O processador... O processador, por si, não é capaz de detectar. Entendeu? Ah, sim, é. Eu sei um exemplo aqui que daria pra dar. Tipo, aquele negócio do bug do milênio, né? Quando o pessoal fez essa parada toda, não estava nem aí que ia estourar o tempo limite em 2030 e poucos. E aí... E agora que começou a ter essa preocupação. Então, tipo, se chega nesse tempo, o processador só... Ah, tá tudo bem. Não tem problema, não. O tempo zerou aqui, não aconteceu nada. Exatamente. Se o processador não tivesse sido projetado para detectar esse problema, se o processador não tivesse sido projetado para detectar esse problema, ele vai passar batido. Ele não vai saber que isso é um problema. Por exemplo, ah, o meu contador de instruções... Não, não, o timer. O meu timer aqui, né? Deu maior... Eu contei um tempo maior que 2 na 64 milissegundos. Faço uma montagenzinha aí. Quanto é que é 2 na 64? Vezes 10 elevado a menos três. Não, dividir. Não, 2 na 64 dividido por 10 elevado a menos três. 10... Então é vezes 10. Não, é isso aqui. Elevado a 3. É isso aí. 2 elevado a 64 dividido por 10 elevado a menos três. Vezes 10 na 3. Agora, pega isso aí e divide por 60. Impossível, Marcelo. Aquele número grandão dividido por 60 não dá esse número pequenininho aí. Mas tu não fez na calculadora. É só pegar o resultado e dividir por 60. É, porque se a tua calculadora não gostou do número, tá? É porque a tua calculadora não é capaz de trabalhar com o número de 64 bits. Tudo bem. Pega esse aí. Esse aí é aquele número lá dividido por 60. Não é só isso. Que maravilha. Isso. Esse número aí é dividido por 60. Divide novamente por 60. Vocês não estão fazendo isso na calculadora? Divide agora por 24. Divide agora por 365. Ah, não. Parece que eu tô no jardim de infância mexendo na calculadora. Divide aí por 30. Pois é. Divide por 365. Porque eu não estou na calculadora aqui. Vê isso aí? Divide por 100. Então, se eles fizerem as contas certas, tá? Vai dar para fazer a contagem de... Conta isso aqui. Milhão. Bilhão. Trilhão. Quatrilhão. Quíntilhão. Cinco ponto oito quíntilhões de séculos. Se vocês fizerem as contas certas. Ok? Quer dizer. O problema que aconteceu no ano 2000, tá? Era muito mais problema de software, tá? Do que de hardware. Certo? Então, a gente tem que colocar só 32 bits para... Bom, vamos fazer as contas com 32 bits. Faz aí. 2 elevado a 32. Vezes mil. Ah, eu vou fazer aqui. Tô vendo que eu vou ter que fazer isso aí. Ah, vamos lá. Vamos fazer juntos aqui, então. 2 elevado a 32. Vezes mil. Então, isso aqui te dá o total de segundos. Divide por 60. Te dá em minutos. Divide por 60. Te dá em horas. Divide por 24. Te dá em dias. Divide por 365. Te dá em anos. Então, nota que se eu usar só 32 bits, ele já iria durar 136 mil anos. Então, o problema não era hardware. O problema era software. Que estava pegando só os dois últimos dígitos do ano. Entendeu? Ao invés de pegar 1900 e tanto, ele estava pegando só o 1900 e o 86. Pegou só o 86. E aí que deu problema. Entenderam? Então, não era o processador que estava com problema. Era o software que estava com problema. Captaram a ideia? É. Porque eu lembro que eu li que o negócio é que o erro é porque eles começaram a contar o ano a partir de 1900. E aí, como ele guarda na memória a data, o mês, o ano, a hora, o minuto, o segundo, o milissegundo. Quem que guarda isso aí? É a memória. Memória? Não. Sim, a memória. É, a memória, não é não? Ele que está guardando o número. É, a memória para saber qual que é a data do arquivo, por exemplo. Ok. Data do arquivo. É, por exemplo, assim, né. Tipo, tem uma planilha lá, né. De 2021. Aí vai a data, né. Tudo assim, né. O dia, mês, ano, hora, segundo, blá, blá, blá. E aí, por conta disso, que isso aí que estourava o limite de... Eu não sei se era 32, 64 bits. Que é por isso que ele vai dar problema em 2030 e qualquer coisa. Porque acabou o limite quando o início é 1900. Tipo, primeiro de janeiro de 1900. Aí chega no limite em 2030 e qualquer coisa. Vamos fazer uma técnica aqui. Será que isso aí é 2016? 2016 vezes mil. Dividido por 60. Dividido por 60. Dividido por 24. Dividido por 365. Não, não. Que aí você perderia dois anos só. É uma outra contagem que eles usaram. Não era contar de milissegundos. Porque tem o relógio de tempo real da máquina. Que é mantida pela bateria. Que, por acaso, de vez em quando a gente tem que ficar ressincronizando com a internet. Certo? Que pode ser problema isso aí. Se confiar num relógio de uma máquina. Então, não teria que ver direitinho. Mas não é problema do processador. Certo? Esse fim de semestre está interessante. É não, mas é só para... Que era tipo isso que eu estava pensando, entendeu? Que tipo assim... Quando as pessoas fizeram, estavam... Ah, né? Só que em 1900 nunca vai dar problema. Aí chega... Ah, espera. Vai acabar. Vê direitinho isso. Pesquisa direitinho isso. Porque o problema não é desde 1900. Mas desde 1970. É verdade. É, deve ser alguma coisa assim. Vou olhar depois direitinho. Mas eu lembro que era um negócio assim. Que o problema era justamente a memória que guarda a data com as coisas. A data. Aham. Mas daí tem que ver direitinho como que isso era gravado. Porque quem lê, quem grava isso... É... Quem tem acesso nisso é a BIOS. Tá? Que tem acesso, então, ao relógio do sistema. Então, só uma dúvida. Essa bateria acaba em algum momento? Ou a própria carga, quando a gente usa, recarrega ela? Olha. Hoje em dia, eu acho que nem tem mais bateria. Tá? Lá dentro. Se vocês abrirem o computador de vocês, acho difícil vocês encontrarem uma bateria. Não. Antigamente tinha. Não tem porque... Não tem, né? É. Acho que tem alguma coisa a ver com... Ok. Não é se cair um raio. Mas se tiver algum... Algum circuito, simplesmente... Sim. Exato. Como é que faz para guardar o... O horário? Tá? O sistema operacional, tá? Pode guardar e depois ressincronizar quando estiver na internet. Se tu não tiver o teu computador ligado na internet, tu não consegue achar qual é a... A data certa. O dia certo. Mas o processador, ele conta o número de ciclos da hora que ele liga, né? Não tipo o número de ciclos infinitos dele. Isso. Não. Da hora que ele liga. Tá? Nesse contador específico, né? Exatamente. Exatamente. Exatamente. Exatamente. Exatamente. Exatamente. Exatamente. Exatamente. Exatamente. Exatamente. Exatamente. Exatamente. Exatamente. Exatamente. Exatamente. Com `mtimecmp`, tá? Nesse contador específico aqui, tá? Então, esse contador de minutos e segundos que a gente tem aqui. Para guardar em queda. Ok. Eu só queria o Bug do Milênio na minha época de 20 anos. Eu recebi... Foi uma pandemia. Não, mas vai passar por essa tal crise que eles estão falando de... De \"terrorismo\" anos 2030 e quantos? Eu sei que tem mais de... Eu acho que é 2034, mas não tenho certeza, não. Tem que olhar direitinho. Eu tenho que ver direitinho isso aí, mas vai ter o terrorismo em cima de 2034. Mas vamos lá. Então, essas aqui são as instruções que a gente viu. Essas aqui são os códigos que tem que estar no registrador de causa para identificar cada uma dessas exceções. E a gente teria aqui os códigos para cada uma dessas interrupções. Então, no caso do modo usuário, são essas aqui. User Interrupt, que seria no caso do modo usuário, seria o 0, certo? Software Interrupt. Seria o Timer Interrupt, quer dizer, o processador ser interrompido de tempos em tempos. E interrupção externa. Então, o usuário `epc`. As outras aqui seriam dos dois modos. Modo Supervisor e o Timer Interrupt. Ok, como é que se faz, então, que é assim, vetorizada no RISC-V? Isso aqui foi uma coisa que eles inventaram. Eu não sei se você acha genial ou se critica, mas vamos lá. Então, o RISC-V, ele aceita tanto o tratamento do registrador `mcause` quanto `mtvec` vetorizado. E como é que eles fizeram para poder fazer as duas coisas? Então, se o endereço... O `mtvec` seria o endereço do vetor de interrupções. O endereço do vetor de interrupções, certo? Então, vamos pensar no primeiro endereço do vetor de interrupções. No primeiro elemento do vetor de interrupções. Isso aqui para o modo usuário, para o modo Supervisor e para o modo Machine. Então, se esse endereço tem `mtvec[1:0]` igual a 0, 0... Quer dizer, ele for múltiplo de quatro... Trata-se de uma única rotina de tratamento de exceção localizada nesse endereço aqui. Quer dizer, se o meu vetor de interrupções for armazenado a partir de um endereço alinhado, então, eu tenho uma única rotina de tratamento localizado nesse endereço aqui. Então, é o endereço dos bits... De 31 a 2 e com os dois últimos bits 0. Certo? Então, o endereço da rotina de tratamento de interrupções vai ser o conteúdo desse registrador, né? Com dois endereços 0. Na princípio, não precisaria, mas a gente vai entender por que ele está fazendo isso. Ah, por que ele não pegou de 31 a 0 aqui? Calma que a gente vai ver o básico, tá? Então, ele vai pular desse endereço aqui. Entendeu isso? Que é o primeiro endereço lá da rotina de tratamento de exceção. Quer dizer, o primeiro endereço do vetor. Se, no caso, o endereço que está no `mtvec` terminar em 0, 1, quer dizer, eu colocar o vetor de interrupções no endereço que termine com os dois últimos bits 0, 1, trata-se de tratamento vetorizado, tá? Então, nesse tratamento vetorizado, o endereço de cada rotina, a rotina de tratamento, eu estava lembrando aqui, eu tenho aqui diversos endereços, e cada um desses endereços leva para uma rotina de tratamento, certo? Então, se esse primeiro endereço estiver alinhado, se o primeiro bit for 0, esse endereço é o terceiro endereço aqui, de exception handler, que eu só tenho uma rotina de tratamento de exceção. Então, se esse endereço aqui estiver localizado no endereço onde os dois últimos bits são 0, 1, quer dizer, não está alinhado, então, onde vão estar localizadas essas rotinas aqui? Então, as rotinas vão estar localizadas no endereço base, que é esse número aqui, mais 4, opa, base, mais 4 vezes o número de causa. Quer dizer, eu pego a causa, multiplico por 4, que essa aqui é a causa, multiplico por 4, e somo a esse endereço base. Agora a gente entende por que isso aqui tem que ser 0, 0. Então, isso aqui vai ser o endereço de cada causa. Entenderam, pessoal? Então, para a causa 0, vai ser o próprio endereço de base. Para a causa 1, vai ser o endereço de base mais 4. Para a causa 2, endereço de base mais 8. E assim vai. Entendido, pessoal? Então, cada exceção é duplicada. Como assim cada exceção é duplicada? Tipo, se tem a vetorizada, que já dá o endereço da exceção, e você tem a exception handler, que tem o endereço da exceção, não está duas vezes no RISC-V guardado? Nesse aqui, eu tenho uma única rotina de tratamento de exceção, o exception handler. E ele vai me dizer onde que estão as outras rotinas. O tratamento de cada exceção, a única opção. Nesse caso aqui, dependendo da causa, eu vou ter um endereço diferente. Entendeu? Então, tu pode usar tanto esse modo, quanto esse modo. Por isso que o RISC-V, ele diz, olha, se a gente aceita os dois, quer usar registrador de causa, usa esse modo aqui, que ele vai te mandar sempre com o mesmo endereço. Se tu quiser usar a interrupção vetorizada, esse método vetorizado, então, essa é a forma de vocês acharem qual é o endereço que vai estar o endereço que eu tenho que pular. Entenderam? Qual é o endereço que vai estar o endereço para onde eu tenho que pular. Que é justamente isso aqui, né? Entenderam? É isso aqui, eu coloco um endereço aqui, outro endereço aqui, outro endereço aqui, e a diferença entre eles é de 4, né? Então, isso aqui é para a causa 0, esse aqui é para a causa 1, esse aqui é para a causa 2, esse aqui é para a causa 3. Entenderam? Esse modo, ele traduz automaticamente de causa para endereço de onde que está o tratamento. Só referências diferentes? É. Tá? Aqui as rotinas vão estar em determinados endereços, nesse aqui não. O endereço que eu posso botar aqui é qualquer. Então, não dá para usar os dois modos ao mesmo tempo. Ou se usa um modo ou se usa outro. Entenderam isso, pessoal? Isso aqui é só... A gente não vai implementar interrupção vetorizada aqui, né? Então, deixa assim. Então, a opção de entrada e saída, esse aqui a gente já viu, né? Por pooling, é quando o processador fica testando se um determinado dispositivo quer mandar dado, né? Então, é o que vocês estão fazendo no jogo de vocês, certo? E o outro é por interrupção. Então, o dispositivo avisa o processador, né? E o processador, então, vai processar essa interrupção externa. O problema é que aqui o hardware é mais complicado. Aqui ficou muito tempo do processador. Tá? Ok. Então, por exemplo, no uniciclo, isso é fácil, tá? Porque cada instrução é feita em um ciclo de clock. Quer dizer, se eu estou executando uma instrução e vem uma interrupção, essa instrução acaba o ciclo de clock e na próxima instrução, eu atendo a interrupção. No multiciclo, onde são vários ciclos de clock para fazer uma instrução, então, o processador vai ter que esperar essa instrução ser completada para, então, quando ele passar à próxima instrução, ele atender a interrupção. Para o pipeline, aí ele vai ter que parar o pipeline. Ele para o pipeline e atende a interrupção. Entendido, pessoal? Tá, ok. Então, só uma coisinha. Então, o pooling e interrupção. O software do pooling hardware. Só para completar a aula de hoje, DMA. O que é DMA? Direct Memory Access. Ou acesso direto à memória. Acesso direto à memória por quem? Por um dispositivo externo. Por um dispositivo externo. Então, o que aconteceria se, por exemplo, o meu processador, eu quero, por exemplo, pegar os dados que estão nesse dispositivo. Por exemplo, aqui, vamos chutar aí um... Maligno. Vamos supor aqui um dispositivo aqui de... Um pendrive, por exemplo. Eu quero transferir o conteúdo de determinado dispositivo que está no pendrive para a memória. Certo? Então, o que a CPU vai ter que fazer? Vai ter que acessar o pendrive, ler uma determinada quantidade de... Informação. Por exemplo, byte ou word. Ler uma word e escreve aqui. Vai para o próximo, lê a próxima word, escreve no próximo endereço de memória. Lê a próxima word e escreve no próximo endereço de memória. Entenderam? Quando isso vai ocupar a CPU? Se a CPU tem que... Tem que gerenciar tudo isso. Ler o valor daqui e escrever aqui. Depois, ler o valor daqui e escrever aqui. Entenderam o problema? Não, pode ser qualquer dispositivo. Pode ser até mesmo um buffer de teclado. Para o usuário ter que mover as teclas e depois ele vai processar, por exemplo. Pode ser um HD. Pode ser qualquer outra coisa. Então, isso ocupa muito da CPU. Então, o que é o DMA? O DMA é esse carinha aqui. Aqui é o DMA Controller. Esse aqui é o controlador desse dispositivo. Então, aqui está o dispositivo e aqui é o controlador dele que se comunica com o barramento. Mais peças. Então, o que o DMA Controller faz? Quando a CPU precisa transferir, por exemplo, um bloco que está aqui no dispositivo, para cá, a CPU vai programar esse DMA Controller dizendo, olha, eu quero que tu pegue do endereço tal, vamos citar aí 1024 words a partir daqui. Então, o endereço tal e a quantidade de dados. E vai dizer também aqui qual é o endereço que eu quero na memória que esses dados vão. Então, a CPU só precisa dizer qual é o endereço de origem, o tamanho dos dados que eu quero transferir e o endereço de destino. Só isso. E aí a CPU fica livre para fazer outras coisas quando o DMA fica fazendo essa cópia daqui para cá. Certo? Então, é o DMA que assume essa tarefa de ficar lendo os dados daqui e escrevendo aqui, lendo aqui e escrevendo aqui. Depois que ele acaba, ele avisa a CPU. Olha, CPU, acabei. Certo? Através de uma interrupção. Entendido, pessoal? O que é DMA? Entendido. Calma, eu estou digerindo a informação tanto quanto a comida do almoço. Mouse e teclado usam DMA? Eu acho que não, porque os dados que eles enviam são muito curtos. Tá? Então, não creio que ele utiliza DMA. Eles usam interrupção direto para a CPU. HDMI é, é, tu pegar da tua memória de vídeo, passar isso por um driver e apresentar em um monitor. Certo, Eduardo? Então, não confunda. Eu não quero pegar os dados do HDMI e botar na memória. Tá? Isso aqui, se fosse um HDMI, o que que tu tens aqui ligado? Não é pegar esses dados aqui e receber na memória. Não, é tu pegar a tua memória de vídeo, a memória de vídeo que está aqui também, passar por um driver e aí sim tu vai ter o teu sinal HDMI, que pode ser unidirecional. Certo? Mas tem esse controlador aqui. Tá vendo? Por favor, que não tem laboratório. A gente tem que aplicar isso aí tudo. Não, não tem. A gente tem um laboratório do pipeline. Mas nós vamos implementar isso nos três processadores na aula que vem. Ok. Como é que é? DMA é parte do processador ou é elemento externo da CPU? Geralmente, hoje em dia, como o acesso da memória já é feito diretamente pelo chip, nós temos o controlador de memória dentro do chip, o controlador de DMA também está dentro do chip. Certo? Não fica na placa-mãe. Fica dentro do chip do processador. Ok? Então, não é um dentro da CPU. Está dentro do chip do processador. Onde isso aqui, esse barramento está. Entendido, Marcelo? Por quê? Porque os nossos processadores se comunicam agora diretamente com a memória. Eles não precisam mais ter o controlador de memória separado. Já está pronto aqui. Tá, pessoal. Mais alguma dúvida, algum comentário? Alguma observação? Ah, é, pessoal. Lembrem que hoje estou em casting e respondam a chamada pelo Fátima. Vocês receberam por e-mail o convite para a apresentação do Fátima? Não. Sério? Sim. Sim ou não, pessoal? Ele foi mandado por e-mail na segunda-feira. Entendi. Você me perguntou. Respondeu. Eu pedi para a secretaria mandar listas segunda-feira. E ela mandou para todas as listas. Mas, pelo visto, vocês não receberam. Por quê? Você diz aquela lista de tipo da Mecatrônica que tem? Deixa eu ver se está lendo. Eu acho que não. A lista da Mecatrônica. Os alunos da Mecatrônica, os alunos do Bacharelado, os alunos da Engenharia de Software, os alunos da Engenharia de Software, os alunos da Engenharia de Software, os alunos da Computação, que é a Licenciatura. A gente tem uma lista para cada um desses. Não, eu não recebi nenhum e-mail dessa lista, nem do SIGA, nem do Fátima. Se eu pesquisar Fátima, a última e-mail que aparece é do erro que eu te mandei lá, o bug que tinha. Acho que eu passei. Eu vou verificar. Eu vou mandar esse convite aqui pelo Aprender para vocês. É para todos os alunos estarem sabendo. Mas eu acho que ou a lista está desatualizada, ou a secretaria, ou a secretaria mandou para a lista errada. Que também, não é muito remota. Ela tem errado os nomes de todas as listas. Mas é que vai ter a apresentação do Fátima na segunda-feira às quatro horas. Vocês têm aula depois dessa aqui? Na segunda-feira? Na segunda vocês têm aula depois dessa? Porque como vocês foram usuários ferrenhos, espero que todo mundo, toda a aula que vocês tenham utilizado, vocês foram usar ferrenhos da ferramenta e nos ajudaram com os planos. Então, é interessante que vocês vejam o que tem por trás daquela tela laranja e preta que vocês estão tirando a fotinho de vocês. Como é que o sistema foi feito? É isso que a gente vai fazer a apresentação para a comunidade do DF. Então, a gente vai convidar diversos órgãos do DF para assistir a nossa apresentação. Então, a presença de vocês lá não é obrigatória, mas é desejável. Até que ganha certificado de extensão. Juntando os certificados de extensão, vocês depois saem em créditos. Um crédito? Não é um crédito, é menos de um crédito. Um crédito são 15 horas de aula. A gente vai dar uma palestra de duas horas. Nem é crédito, não. Então, está mais para 2,5? Não. 15? 3? Não, seria o equivalente a 2 horas de aula. Um crédito são 15 horas de aula. 12? Então, é isso. Então, não é muito, mas é certificado para vocês colocarem no currículo, etc. Assistir o lançamento dessa ferramenta que hoje em dia está dominando o mundo. O quê? Apple TV? Não, é a TV Azul. Está certo. Pois é, Thelma, todos eles foram dessas testes. Beta testers do Fátima. Coloca lá no meu e-mail. Coloca lá no meu e-mail. Ok, pessoal. Então, ficamos por aqui hoje. Todo mundo fez o testinho e assinou a presença também no Fátima. E esse Fátima aí já... Nossa, o negócio já bugou todo ali que eu já desisti, pessoal. Eu tentei fazer um negócio de testes aí e tal, eu tentei mandar e-mail, o e-mail não foi. Mas deixa, eu também esqueci de fazer várias testes. É isso que eu quero que vocês reportem. Exatamente esses problemas que vocês tiveram, certo? É isso que a gente, tendo feedback, a gente consegue corrigir, ver onde é que está faltando coisa, o que está acontecendo. Eu não queria que vocês utilizassem ele 100% sempre legalzinho. Não, onde é que estão os problemas? Para isso servem os beta-tests. Ok, pessoal. Então, ficamos por aqui hoje. Vou parar as gravações.",
        "video_source": "OAC_2022-04-13.mp4"
    },
    {
        "id": 17,
        "timestamp_start": 7033.3,
        "timestamp_end": 7033.66,
        "slide_description": "Atuando como um Engenheiro de Computação Sênior, procedo à análise do conteúdo visual do slide fornecido, visando a extração de informações para um sistema de busca semântica (RAG).\n\nO slide, parte de uma aula de Arquitetura de Computadores (UnB - CIC0099 - Organização e Arquitetura de Computadores, ministrada pelo Prof. Marcus Vinícius Lamas do Departamento de Ciência da Computação da Universidade de Brasília), foca no tema **\"Operações de Entrada e Saída\"**, com destaque para a abordagem **\"Por DMA (Direct Memory Access)\"**.\n\nO conteúdo textual visível na apresentação é o seguinte:\n*   **Título Principal:** \"Operações de Entrada e Saída\"\n*   **Subtítulo:** \"Por DMA (Direct Memory Access)\"\n*   **Fragmento de texto explicativo:** \"dispositivo que gerencia a\" (incompleto)\n*   **Fragmento de texto explicativo em inglês:** \"CPU sends a starting address, direction, and length count issues \"start\".\"\n*   **Texto descritivo de funcionalidade:** \"DMAC provides handshake signals for Peripheral Controller, and Memory Addresses and handshake signals for Memory.\"\n\nUm diagrama de blocos esquemático (parcialmente visível e com anotações manuais) ilustra a arquitetura de comunicação em um sistema com DMA. No topo, há um bloco rotulado **\"CPU\"**. Abaixo, conectado à CPU, observa-se o bloco **\"MAC\"** (provavelmente um Memory Access Controller ou Media Access Controller, dado o contexto de E/S e memória) e um bloco **\"IOC\"** (I/O Controller). Estes controladores interagem com um **\"device\"** (dispositivo). Anotações manuais em vermelho sobre o diagrama indicam:\n*   Um rabisco sobre o \"device\" que parece incluir a palavra \"copy\", sugerindo a operação de cópia de dados.\n*   A sigla **\"HDMI\"** abaixo do \"device\", especificando um tipo de dispositivo de saída/interface.\nO diagrama representa a interação entre a CPU, controladores de acesso a memória e E/S, e um dispositivo periférico, enfatizando o papel do DMAC (DMA Controller, inferido do texto \"DMAC provides...\") na coordenação da transferência de dados sem a intervenção contínua da CPU, através de sinais de handshake e endereçamento de memória.\n\nSobreposto à apresentação, há uma janela de diálogo do sistema de conferência com o título **\"Pausar gravação\"**. O texto dentro desta janela é: \"Tem certeza de que deseja pausar a gravação? Você pode retomar a qualquer momento pressionando o botão de gravação novamente.\" e apresenta as opções de interação \"Sim\" e \"Não\".\n\nNa barra lateral esquerda, observa-se a interface de uma plataforma de conferência online (\"ConferênciaWeb\"), que exibe seções como \"MENSAGENS\" (com subseções \"Perguntas\" e \"Bate-papo público\"), \"NOTAS\" e \"USUÁRIOS (9)\". Um histórico de mensagens do \"Bate-papo público\" é visível, contendo interações entre participantes como \"Gustavo Lopes Dezan\", \"Marcello Brandao Scar...\", e \"Victor Hugo Franca Lis...\", com timestamps e conteúdos diversos, como \"vou checar aqui\", \"tbm não recebi\", \"tenho mas n preciso assistir\", \"opa pera como que é?\", e discussões sobre quantidades (\"1/2\", \"1/12\", \"2/15\") e testes (\"beta tester do faciem\").\n\nEm suma, o slide detalha o conceito de DMA em Arquitetura de Computadores, mostrando como a CPU delega a transferência de dados para um DMAC, que coordena com controladores periféricos e de memória para mover dados de/para dispositivos (exemplificado por HDMI) de forma eficiente.",
        "transcription": "Aqui.",
        "video_source": "OAC_2022-04-13.mp4"
    },
    {
        "id": 18,
        "timestamp_start": 7035.5,
        "timestamp_end": 7036.4,
        "slide_description": "Como um Engenheiro de Computação Sênior, analiso o slide da aula de Arquitetura de Computadores para extrair e descrever seu conteúdo técnico.\n\nO slide é intitulado \"Operações de Entrada e Saída\" e foca especificamente no conceito de \"Por DMA (Direct Memory Access)\". No canto superior direito, há metadados do curso: \"UnB - CIC0099 - Organização e Arquitetura de Computadores\", \"Universidade de Brasília\", \"Departamento de Ciência da Computação\", e o nome do professor \"Prof. Marcus Vinicius Lamar\".\n\nO conteúdo textual principal, localizado no lado esquerdo da tela, detalha as características do DMA:\n*   \"dispositivo que gerencia a transferência de blocos de dados de forma independente da CPU\"\n*   \"atua como mestre do barramento\"\n*   \"é programado pela CPU para realizar as transferências\"\n\nNo lado direito, um diagrama de blocos ilustra a arquitetura e o fluxo de dados para operações de E/S via DMA. Os componentes centrais conectados por um barramento comum são:\n*   **CPU**: A Unidade Central de Processamento.\n*   **Memory**: A memória principal do sistema.\n*   **DMAC**: O Controlador de Acesso Direto à Memória.\n*   **IOC**: O Controlador de Entrada/Saída, que por sua vez se conecta a um \"device\" (dispositivo periférico).\n\nAs setas bidirecionais entre a CPU, Memory, DMAC e IOC indicam que todos estão conectados ao barramento do sistema, permitindo troca de dados e controle.\n\nAcima do diagrama, há uma descrição textual do processo inicial de DMA: \"CPU sends a starting address, direction, and length count to DMAC. Then issues 'start'.\" Isso descreve a fase de programação do DMAC pela CPU.\n\nAbaixo do diagrama, há outra descrição que detalha as funções do DMAC durante a transferência: \"DMAC provides handshake signals for Peripheral Controller, and Memory Addresses and handshake signals for Memory.\" Isso sublinha o papel do DMAC em coordenar a transferência de dados entre o periférico (via IOC) e a memória, independentemente da CPU, utilizando sinais de *handshake* e fornecendo endereços de memória.\n\nHá anotações visuais em vermelho feitas à mão sobre o diagrama. Próximo à \"Memory\" e ao fluxo de dados, a palavra \"write\" está parcialmente visível, sugerindo uma operação de escrita na memória. Próximo ao \"device\" e ao \"IOC\", a sigla \"HDMI\" está claramente escrita, indicando um exemplo de dispositivo periférico que pode se beneficiar do DMA. Outros rabiscos ilegíveis podem representar outras interações ou exemplos.\n\nEm resumo, o slide aborda o conceito de Direct Memory Access (DMA) como um mecanismo para transferências de dados eficientes entre periféricos e memória, aliviando a CPU dessa carga. Ele descreve as funções do DMAC, seu papel como mestre do barramento e como é programado pela CPU para gerenciar transferências autônomas. O diagrama complementa a explicação, mostrando a interconexão da CPU, memória, DMAC e controladores de E/S no barramento do sistema.",
        "transcription": "E aqui.",
        "video_source": "OAC_2022-04-13.mp4"
    }
]